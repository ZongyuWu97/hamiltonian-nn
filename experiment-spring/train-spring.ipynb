{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ZongyuWu/hamiltonian-nn/experiment-spring\n",
      "/Users/ZongyuWu/hamiltonian-nn\n"
     ]
    }
   ],
   "source": [
    "import torch, argparse\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "THIS_DIR = os.path.abspath(os.path.join('.'))\n",
    "PARENT_DIR = os.path.dirname(THIS_DIR)\n",
    "sys.path.append(PARENT_DIR)\n",
    "\n",
    "from nn_models import MLP\n",
    "from hnn import HNN\n",
    "from utils import L2_loss, rk4\n",
    "from data import get_dataset\n",
    "\n",
    "print(THIS_DIR)\n",
    "print(PARENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print squared loss at specific steps for comparison with HNN\n",
    "print_every = 200\n",
    "def print_results(results, print_every=200):\n",
    "    for step in range(0, len(results[\"train_loss\"]), print_every):\n",
    "        print(\n",
    "            \"step {}, train_loss {:.4e}, test_loss {:.4e}\".format(\n",
    "                step,\n",
    "                results[\"train_loss\"][step],\n",
    "                results[\"test_loss\"][step],\n",
    "            )\n",
    "        )\n",
    "    # print('Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}'\n",
    "    #     .format(results[\"train_loss\"][-1], results[\"train_std\"][-1],\n",
    "    #             results[\"test_loss\"][-1], results[\"test_std\"][-1]))\n",
    "\n",
    "def print_best(results):\n",
    "    curr_min = 0\n",
    "\n",
    "    for step in range(0, len(results[\"train_loss\"])):\n",
    "        if results[\"test_loss\"][step] < results[\"test_loss\"][curr_min]:\n",
    "            curr_min = step\n",
    "    print(\n",
    "        \"best test loss at step {}, train_loss {:.4e}, test_loss {:.4e}\".format(\n",
    "            curr_min,\n",
    "            results[\"train_loss\"][curr_min],\n",
    "            results[\"test_loss\"][curr_min],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=None)\n",
    "    parser.add_argument(\n",
    "        \"--input_dim\", default=2, type=int, help=\"dimensionality of input tensor\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--hidden_dim\", default=200, type=int, help=\"hidden dimension of mlp\"\n",
    "    )\n",
    "    parser.add_argument(\"--learn_rate\", default=1e-3, type=float, help=\"learning rate\")\n",
    "    parser.add_argument(\n",
    "        \"--nonlinearity\", default=\"tanh\", type=str, help=\"neural net nonlinearity\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--total_steps\", default=2000, type=int, help=\"number of gradient steps\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--print_every\",\n",
    "        default=200,\n",
    "        type=int,\n",
    "        help=\"number of gradient steps between prints\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--name\", default=\"spring\", type=str, help=\"only one option right now\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--baseline\",\n",
    "        dest=\"baseline\",\n",
    "        action=\"store_true\",\n",
    "        help=\"run baseline or experiment?\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_rk4\",\n",
    "        dest=\"use_rk4\",\n",
    "        action=\"store_true\",\n",
    "        help=\"integrate derivative with RK4\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verbose\", dest=\"verbose\", action=\"store_true\", help=\"verbose?\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--kan\", dest=\"kan\", action=\"store_true\", help=\"use kan instead of mlp?\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--field_type\",\n",
    "        default=\"solenoidal\",\n",
    "        type=str,\n",
    "        help=\"type of vector field to learn\",\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", default=0, type=int, help=\"random seed\")\n",
    "    parser.add_argument(\n",
    "        \"--save_dir\", default=THIS_DIR, type=str, help=\"where to save the trained model\"\n",
    "    )\n",
    "    parser.set_defaults(feature=True)\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # set random seed\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    # init model and optimizer\n",
    "    if args.verbose:\n",
    "        print(\"Training baseline model:\" if args.baseline else \"Training HNN model:\")\n",
    "\n",
    "    output_dim = args.input_dim if args.baseline else 2\n",
    "    nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)\n",
    "    model = HNN(\n",
    "        args.input_dim,\n",
    "        differentiable_model=nn_model,\n",
    "        field_type=args.field_type,\n",
    "        baseline=args.baseline,\n",
    "    )\n",
    "    optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=1e-4)\n",
    "\n",
    "    # arrange data\n",
    "    data = get_dataset(seed=args.seed)\n",
    "    x = torch.tensor(data[\"x\"], requires_grad=True, dtype=torch.float32)\n",
    "    test_x = torch.tensor(data[\"test_x\"], requires_grad=True, dtype=torch.float32)\n",
    "    dxdt = torch.Tensor(data[\"dx\"])\n",
    "    test_dxdt = torch.Tensor(data[\"test_dx\"])\n",
    "\n",
    "    # vanilla train loop\n",
    "    stats = {\"train_loss\": [], \"test_loss\": []}\n",
    "    for step in range(args.total_steps + 1):\n",
    "\n",
    "        # train step\n",
    "        dxdt_hat = (\n",
    "            model.rk4_time_derivative(x) if args.use_rk4 else model.time_derivative(x)\n",
    "        )\n",
    "        loss = L2_loss(dxdt, dxdt_hat)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # run test data\n",
    "        test_dxdt_hat = (\n",
    "            model.rk4_time_derivative(test_x)\n",
    "            if args.use_rk4\n",
    "            else model.time_derivative(test_x)\n",
    "        )\n",
    "        test_loss = L2_loss(test_dxdt, test_dxdt_hat)\n",
    "\n",
    "        # logging\n",
    "        stats[\"train_loss\"].append(loss.item())\n",
    "        stats[\"test_loss\"].append(test_loss.item())\n",
    "        if args.verbose and step % args.print_every == 0:\n",
    "            print(\n",
    "                \"step {}, train_loss {:.4e}, test_loss {:.4e}\".format(\n",
    "                    step, loss.item(), test_loss.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "    train_dxdt_hat = model.time_derivative(x)\n",
    "    train_dist = (dxdt - train_dxdt_hat) ** 2\n",
    "    test_dxdt_hat = model.time_derivative(test_x)\n",
    "    test_dist = (test_dxdt - test_dxdt_hat) ** 2\n",
    "    print(\n",
    "        \"Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}\".format(\n",
    "            train_dist.mean().item(),\n",
    "            train_dist.std().item() / np.sqrt(train_dist.shape[0]),\n",
    "            test_dist.mean().item(),\n",
    "            test_dist.std().item() / np.sqrt(test_dist.shape[0]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "data = get_dataset(seed=0, mode=3, noise_std=0.05, keep_frequencies=10)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.tensor(data[\"x\"], requires_grad=True, dtype=torch.float32).to(device)\n",
    "test_x = torch.tensor(data[\"test_x\"], requires_grad=True, dtype=torch.float32).to(device)\n",
    "dxdt = torch.Tensor(data[\"dx\"]).to(device)\n",
    "test_dxdt = torch.Tensor(data[\"test_dx\"]).to(device)\n",
    "\n",
    "# dataset['train_input'], dataset['train_label'],dataset['test_input'], dataset['test_label']\n",
    "dataset = {\n",
    "    \"train_input\": x,\n",
    "    \"train_label\": dxdt,\n",
    "    \"test_input\": test_x,\n",
    "    \"test_label\": test_dxdt,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7500, 2]), torch.Size([50, 2, 300]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train_input\"].shape, dataset[\"train_label\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HNN model:\n",
      "step 0, train_loss 8.3700e-01, test_loss 8.4779e-01\n",
      "step 200, train_loss 4.1400e-04, test_loss 4.9047e-04\n",
      "step 400, train_loss 1.7449e-04, test_loss 2.0220e-04\n",
      "step 600, train_loss 1.0028e-04, test_loss 1.1732e-04\n",
      "step 800, train_loss 8.1844e-05, test_loss 9.4788e-05\n",
      "step 1000, train_loss 8.5017e-05, test_loss 8.8129e-05\n",
      "step 1200, train_loss 6.8045e-05, test_loss 7.9083e-05\n",
      "step 1400, train_loss 6.1737e-05, test_loss 6.9726e-05\n",
      "step 1600, train_loss 5.7677e-05, test_loss 6.6365e-05\n",
      "step 1800, train_loss 5.4834e-05, test_loss 6.2784e-05\n",
      "step 2000, train_loss 1.4473e-04, test_loss 2.3001e-04\n",
      "Final train loss 2.2422e-04 +/- 2.9853e-06\n",
      "Final test loss 2.3001e-04 +/- 3.1967e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = get_args()\n",
    "# args.total_steps = 2000\n",
    "args.verbose = True\n",
    "model_hnn, stats_hnn = train(args)\n",
    "\n",
    "# save\n",
    "os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n",
    "label = '-hnn'\n",
    "path = \"{}/{}{}.tar\".format(args.save_dir, args.name, label)\n",
    "torch.save(model_hnn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train_loss 8.3700e-01, test_loss 8.4779e-01\n",
      "step 1, train_loss 8.2794e-01, test_loss 8.4367e-01\n",
      "step 2, train_loss 8.2402e-01, test_loss 8.3460e-01\n",
      "step 3, train_loss 8.1504e-01, test_loss 8.2635e-01\n",
      "step 4, train_loss 8.0684e-01, test_loss 8.2051e-01\n",
      "step 5, train_loss 8.0107e-01, test_loss 8.1471e-01\n",
      "step 6, train_loss 7.9539e-01, test_loss 8.0737e-01\n",
      "step 7, train_loss 7.8823e-01, test_loss 7.9926e-01\n",
      "step 8, train_loss 7.8032e-01, test_loss 7.9160e-01\n",
      "step 9, train_loss 7.7287e-01, test_loss 7.8451e-01\n",
      "step 10, train_loss 7.6600e-01, test_loss 7.7711e-01\n",
      "step 11, train_loss 7.5881e-01, test_loss 7.6874e-01\n",
      "step 12, train_loss 7.5062e-01, test_loss 7.5950e-01\n",
      "step 13, train_loss 7.4156e-01, test_loss 7.4987e-01\n",
      "step 14, train_loss 7.3211e-01, test_loss 7.3994e-01\n",
      "step 15, train_loss 7.2239e-01, test_loss 7.2925e-01\n",
      "step 16, train_loss 7.1195e-01, test_loss 7.1728e-01\n",
      "step 17, train_loss 7.0026e-01, test_loss 7.0394e-01\n",
      "step 18, train_loss 6.8723e-01, test_loss 6.8946e-01\n",
      "step 19, train_loss 6.7311e-01, test_loss 6.7394e-01\n",
      "step 20, train_loss 6.5797e-01, test_loss 6.5710e-01\n",
      "step 21, train_loss 6.4152e-01, test_loss 6.3854e-01\n",
      "step 22, train_loss 6.2337e-01, test_loss 6.1821e-01\n",
      "step 23, train_loss 6.0346e-01, test_loss 5.9625e-01\n",
      "step 24, train_loss 5.8196e-01, test_loss 5.7268e-01\n",
      "step 25, train_loss 5.5887e-01, test_loss 5.4717e-01\n",
      "step 26, train_loss 5.3389e-01, test_loss 5.1954e-01\n",
      "step 27, train_loss 5.0683e-01, test_loss 4.8998e-01\n",
      "step 28, train_loss 4.7787e-01, test_loss 4.5869e-01\n",
      "step 29, train_loss 4.4720e-01, test_loss 4.2557e-01\n",
      "step 30, train_loss 4.1472e-01, test_loss 3.9062e-01\n",
      "step 31, train_loss 3.8042e-01, test_loss 3.5425e-01\n",
      "step 32, train_loss 3.4471e-01, test_loss 3.1677e-01\n",
      "step 33, train_loss 3.0792e-01, test_loss 2.7833e-01\n",
      "step 34, train_loss 2.7018e-01, test_loss 2.3954e-01\n",
      "step 35, train_loss 2.3212e-01, test_loss 2.0119e-01\n",
      "step 36, train_loss 1.9449e-01, test_loss 1.6378e-01\n",
      "step 37, train_loss 1.5781e-01, test_loss 1.2831e-01\n",
      "step 38, train_loss 1.2306e-01, test_loss 9.5735e-02\n",
      "step 39, train_loss 9.1225e-02, test_loss 6.6845e-02\n",
      "step 40, train_loss 6.3098e-02, test_loss 4.2827e-02\n",
      "step 41, train_loss 3.9866e-02, test_loss 2.4317e-02\n",
      "step 42, train_loss 2.2157e-02, test_loss 1.2108e-02\n",
      "step 43, train_loss 1.0771e-02, test_loss 6.2951e-03\n",
      "step 44, train_loss 5.8015e-03, test_loss 6.8011e-03\n",
      "step 45, train_loss 7.1469e-03, test_loss 1.2519e-02\n",
      "step 46, train_loss 1.3643e-02, test_loss 2.1797e-02\n",
      "step 47, train_loss 2.3602e-02, test_loss 3.1897e-02\n",
      "step 48, train_loss 3.4229e-02, test_loss 3.9946e-02\n",
      "step 49, train_loss 4.2584e-02, test_loss 4.3781e-02\n",
      "step 50, train_loss 4.6492e-02, test_loss 4.2506e-02\n",
      "step 51, train_loss 4.5077e-02, test_loss 3.6857e-02\n",
      "step 52, train_loss 3.9113e-02, test_loss 2.8375e-02\n",
      "step 53, train_loss 3.0194e-02, test_loss 1.9052e-02\n",
      "step 54, train_loss 2.0378e-02, test_loss 1.0724e-02\n",
      "step 55, train_loss 1.1547e-02, test_loss 4.8301e-03\n",
      "step 56, train_loss 5.1723e-03, test_loss 2.1149e-03\n",
      "step 57, train_loss 2.0208e-03, test_loss 2.5234e-03\n",
      "step 58, train_loss 2.0499e-03, test_loss 5.2150e-03\n",
      "step 59, train_loss 4.4263e-03, test_loss 8.8343e-03\n",
      "step 60, train_loss 7.8030e-03, test_loss 1.2033e-02\n",
      "step 61, train_loss 1.0838e-02, test_loss 1.3874e-02\n",
      "step 62, train_loss 1.2597e-02, test_loss 1.4061e-02\n",
      "step 63, train_loss 1.2779e-02, test_loss 1.2793e-02\n",
      "step 64, train_loss 1.1572e-02, test_loss 1.0592e-02\n",
      "step 65, train_loss 9.4846e-03, test_loss 8.0431e-03\n",
      "step 66, train_loss 7.0859e-03, test_loss 5.6615e-03\n",
      "step 67, train_loss 4.8768e-03, test_loss 3.7759e-03\n",
      "step 68, train_loss 3.1725e-03, test_loss 2.5414e-03\n",
      "step 69, train_loss 2.1170e-03, test_loss 1.9350e-03\n",
      "step 70, train_loss 1.6781e-03, test_loss 1.8446e-03\n",
      "step 71, train_loss 1.7358e-03, test_loss 2.0891e-03\n",
      "step 72, train_loss 2.1028e-03, test_loss 2.4921e-03\n",
      "step 73, train_loss 2.5991e-03, test_loss 2.8865e-03\n",
      "step 74, train_loss 3.0553e-03, test_loss 3.1575e-03\n",
      "step 75, train_loss 3.3563e-03, test_loss 3.2377e-03\n",
      "step 76, train_loss 3.4363e-03, test_loss 3.1182e-03\n",
      "step 77, train_loss 3.2894e-03, test_loss 2.8408e-03\n",
      "step 78, train_loss 2.9625e-03, test_loss 2.4777e-03\n",
      "step 79, train_loss 2.5322e-03, test_loss 2.1179e-03\n",
      "step 80, train_loss 2.0933e-03, test_loss 1.8333e-03\n",
      "step 81, train_loss 1.7245e-03, test_loss 1.6772e-03\n",
      "step 82, train_loss 1.4837e-03, test_loss 1.6619e-03\n",
      "step 83, train_loss 1.3882e-03, test_loss 1.7670e-03\n",
      "step 84, train_loss 1.4229e-03, test_loss 1.9464e-03\n",
      "step 85, train_loss 1.5444e-03, test_loss 2.1410e-03\n",
      "step 86, train_loss 1.6958e-03, test_loss 2.2969e-03\n",
      "step 87, train_loss 1.8245e-03, test_loss 2.3735e-03\n",
      "step 88, train_loss 1.8901e-03, test_loss 2.3567e-03\n",
      "step 89, train_loss 1.8774e-03, test_loss 2.2533e-03\n",
      "step 90, train_loss 1.7911e-03, test_loss 2.0884e-03\n",
      "step 91, train_loss 1.6542e-03, test_loss 1.8952e-03\n",
      "step 92, train_loss 1.4977e-03, test_loss 1.7073e-03\n",
      "step 93, train_loss 1.3518e-03, test_loss 1.5505e-03\n",
      "step 94, train_loss 1.2396e-03, test_loss 1.4371e-03\n",
      "step 95, train_loss 1.1714e-03, test_loss 1.3698e-03\n",
      "step 96, train_loss 1.1467e-03, test_loss 1.3392e-03\n",
      "step 97, train_loss 1.1544e-03, test_loss 1.3310e-03\n",
      "step 98, train_loss 1.1782e-03, test_loss 1.3300e-03\n",
      "step 99, train_loss 1.2018e-03, test_loss 1.3238e-03\n",
      "step 100, train_loss 1.2117e-03, test_loss 1.3061e-03\n",
      "step 101, train_loss 1.2016e-03, test_loss 1.2759e-03\n",
      "step 102, train_loss 1.1711e-03, test_loss 1.2382e-03\n",
      "step 103, train_loss 1.1259e-03, test_loss 1.2005e-03\n",
      "step 104, train_loss 1.0748e-03, test_loss 1.1696e-03\n",
      "step 105, train_loss 1.0265e-03, test_loss 1.1517e-03\n",
      "step 106, train_loss 9.8865e-04, test_loss 1.1483e-03\n",
      "step 107, train_loss 9.6461e-04, test_loss 1.1572e-03\n",
      "step 108, train_loss 9.5409e-04, test_loss 1.1737e-03\n",
      "step 109, train_loss 9.5362e-04, test_loss 1.1909e-03\n",
      "step 110, train_loss 9.5751e-04, test_loss 1.2023e-03\n",
      "step 111, train_loss 9.6008e-04, test_loss 1.2028e-03\n",
      "step 112, train_loss 9.5691e-04, test_loss 1.1905e-03\n",
      "step 113, train_loss 9.4582e-04, test_loss 1.1660e-03\n",
      "step 114, train_loss 9.2735e-04, test_loss 1.1324e-03\n",
      "step 115, train_loss 9.0395e-04, test_loss 1.0943e-03\n",
      "step 116, train_loss 8.7918e-04, test_loss 1.0563e-03\n",
      "step 117, train_loss 8.5655e-04, test_loss 1.0218e-03\n",
      "step 118, train_loss 8.3838e-04, test_loss 9.9307e-04\n",
      "step 119, train_loss 8.2550e-04, test_loss 9.7047e-04\n",
      "step 120, train_loss 8.1717e-04, test_loss 9.5283e-04\n",
      "step 121, train_loss 8.1152e-04, test_loss 9.3881e-04\n",
      "step 122, train_loss 8.0639e-04, test_loss 9.2688e-04\n",
      "step 123, train_loss 7.9996e-04, test_loss 9.1591e-04\n",
      "step 124, train_loss 7.9123e-04, test_loss 9.0582e-04\n",
      "step 125, train_loss 7.8029e-04, test_loss 8.9686e-04\n",
      "step 126, train_loss 7.6797e-04, test_loss 8.8955e-04\n",
      "step 127, train_loss 7.5554e-04, test_loss 8.8427e-04\n",
      "step 128, train_loss 7.4419e-04, test_loss 8.8109e-04\n",
      "step 129, train_loss 7.3466e-04, test_loss 8.7910e-04\n",
      "step 130, train_loss 7.2702e-04, test_loss 8.7751e-04\n",
      "step 131, train_loss 7.2084e-04, test_loss 8.7487e-04\n",
      "step 132, train_loss 7.1531e-04, test_loss 8.7033e-04\n",
      "step 133, train_loss 7.0964e-04, test_loss 8.6301e-04\n",
      "step 134, train_loss 7.0325e-04, test_loss 8.5327e-04\n",
      "step 135, train_loss 6.9596e-04, test_loss 8.4098e-04\n",
      "step 136, train_loss 6.8791e-04, test_loss 8.2774e-04\n",
      "step 137, train_loss 6.7958e-04, test_loss 8.1361e-04\n",
      "step 138, train_loss 6.7147e-04, test_loss 8.0083e-04\n",
      "step 139, train_loss 6.6415e-04, test_loss 7.8852e-04\n",
      "step 140, train_loss 6.5808e-04, test_loss 7.8049e-04\n",
      "step 141, train_loss 6.5408e-04, test_loss 7.7458e-04\n",
      "step 142, train_loss 6.5365e-04, test_loss 7.8130e-04\n",
      "step 143, train_loss 6.6133e-04, test_loss 8.0187e-04\n",
      "step 144, train_loss 6.8711e-04, test_loss 8.7145e-04\n",
      "step 145, train_loss 7.5293e-04, test_loss 9.9418e-04\n",
      "step 146, train_loss 8.8321e-04, test_loss 1.1765e-03\n",
      "step 147, train_loss 1.0557e-03, test_loss 1.2149e-03\n",
      "step 148, train_loss 1.1042e-03, test_loss 1.0091e-03\n",
      "step 149, train_loss 8.8641e-04, test_loss 7.4449e-04\n",
      "step 150, train_loss 6.2529e-04, test_loss 7.6974e-04\n",
      "step 151, train_loss 6.5032e-04, test_loss 9.6023e-04\n",
      "step 152, train_loss 8.3495e-04, test_loss 9.4466e-04\n",
      "step 153, train_loss 8.2724e-04, test_loss 7.5970e-04\n",
      "step 154, train_loss 6.3666e-04, test_loss 7.0961e-04\n",
      "step 155, train_loss 5.8855e-04, test_loss 8.2678e-04\n",
      "step 156, train_loss 7.1165e-04, test_loss 8.4883e-04\n",
      "step 157, train_loss 7.2984e-04, test_loss 7.1418e-04\n",
      "step 158, train_loss 6.0186e-04, test_loss 6.7434e-04\n",
      "step 159, train_loss 5.6352e-04, test_loss 7.5716e-04\n",
      "step 160, train_loss 6.4602e-04, test_loss 7.5869e-04\n",
      "step 161, train_loss 6.5470e-04, test_loss 6.7347e-04\n",
      "step 162, train_loss 5.6757e-04, test_loss 6.4810e-04\n",
      "step 163, train_loss 5.4446e-04, test_loss 6.9892e-04\n",
      "step 164, train_loss 5.9930e-04, test_loss 7.0409e-04\n",
      "step 165, train_loss 6.0152e-04, test_loss 6.4050e-04\n",
      "step 166, train_loss 5.4131e-04, test_loss 6.2538e-04\n",
      "step 167, train_loss 5.2600e-04, test_loss 6.6295e-04\n",
      "step 168, train_loss 5.6168e-04, test_loss 6.6001e-04\n",
      "step 169, train_loss 5.6188e-04, test_loss 6.2174e-04\n",
      "step 170, train_loss 5.2100e-04, test_loss 6.0854e-04\n",
      "step 171, train_loss 5.0816e-04, test_loss 6.2892e-04\n",
      "step 172, train_loss 5.3034e-04, test_loss 6.3313e-04\n",
      "step 173, train_loss 5.3232e-04, test_loss 6.0298e-04\n",
      "step 174, train_loss 5.0471e-04, test_loss 5.8951e-04\n",
      "step 175, train_loss 4.9147e-04, test_loss 6.0182e-04\n",
      "step 176, train_loss 5.0372e-04, test_loss 6.0264e-04\n",
      "step 177, train_loss 5.0776e-04, test_loss 5.8596e-04\n",
      "step 178, train_loss 4.9053e-04, test_loss 5.6984e-04\n",
      "step 179, train_loss 4.7645e-04, test_loss 5.7190e-04\n",
      "step 180, train_loss 4.8043e-04, test_loss 5.7757e-04\n",
      "step 181, train_loss 4.8588e-04, test_loss 5.6630e-04\n",
      "step 182, train_loss 4.7728e-04, test_loss 5.5335e-04\n",
      "step 183, train_loss 4.6427e-04, test_loss 5.4967e-04\n",
      "step 184, train_loss 4.6131e-04, test_loss 5.5197e-04\n",
      "step 185, train_loss 4.6513e-04, test_loss 5.5105e-04\n",
      "step 186, train_loss 4.6334e-04, test_loss 5.4043e-04\n",
      "step 187, train_loss 4.5414e-04, test_loss 5.3339e-04\n",
      "step 188, train_loss 4.4691e-04, test_loss 5.3290e-04\n",
      "step 189, train_loss 4.4639e-04, test_loss 5.3259e-04\n",
      "step 190, train_loss 4.4728e-04, test_loss 5.2961e-04\n",
      "step 191, train_loss 4.4362e-04, test_loss 5.2137e-04\n",
      "step 192, train_loss 4.3664e-04, test_loss 5.1623e-04\n",
      "step 193, train_loss 4.3180e-04, test_loss 5.1476e-04\n",
      "step 194, train_loss 4.3071e-04, test_loss 5.1267e-04\n",
      "step 195, train_loss 4.3007e-04, test_loss 5.0948e-04\n",
      "step 196, train_loss 4.2685e-04, test_loss 5.0279e-04\n",
      "step 197, train_loss 4.2163e-04, test_loss 4.9799e-04\n",
      "step 198, train_loss 4.1736e-04, test_loss 4.9526e-04\n",
      "step 199, train_loss 4.1527e-04, test_loss 4.9278e-04\n",
      "step 200, train_loss 4.1400e-04, test_loss 4.9047e-04\n",
      "step 201, train_loss 4.1170e-04, test_loss 4.8553e-04\n",
      "step 202, train_loss 4.0796e-04, test_loss 4.8146e-04\n",
      "step 203, train_loss 4.0401e-04, test_loss 4.7792e-04\n",
      "step 204, train_loss 4.0103e-04, test_loss 4.7530e-04\n",
      "step 205, train_loss 3.9905e-04, test_loss 4.7350e-04\n",
      "step 206, train_loss 3.9724e-04, test_loss 4.7014e-04\n",
      "step 207, train_loss 3.9478e-04, test_loss 4.6708e-04\n",
      "step 208, train_loss 3.9168e-04, test_loss 4.6311e-04\n",
      "step 209, train_loss 3.8845e-04, test_loss 4.5996e-04\n",
      "step 210, train_loss 3.8566e-04, test_loss 4.5730e-04\n",
      "step 211, train_loss 3.8340e-04, test_loss 4.5450e-04\n",
      "step 212, train_loss 3.8137e-04, test_loss 4.5216e-04\n",
      "step 213, train_loss 3.7923e-04, test_loss 4.4874e-04\n",
      "step 214, train_loss 3.7675e-04, test_loss 4.4581e-04\n",
      "step 215, train_loss 3.7405e-04, test_loss 4.4231e-04\n",
      "step 216, train_loss 3.7134e-04, test_loss 4.3935e-04\n",
      "step 217, train_loss 3.6882e-04, test_loss 4.3655e-04\n",
      "step 218, train_loss 3.6653e-04, test_loss 4.3379e-04\n",
      "step 219, train_loss 3.6440e-04, test_loss 4.3146e-04\n",
      "step 220, train_loss 3.6233e-04, test_loss 4.2860e-04\n",
      "step 221, train_loss 3.6018e-04, test_loss 4.2622e-04\n",
      "step 222, train_loss 3.5796e-04, test_loss 4.2323e-04\n",
      "step 223, train_loss 3.5564e-04, test_loss 4.2073e-04\n",
      "step 224, train_loss 3.5332e-04, test_loss 4.1787e-04\n",
      "step 225, train_loss 3.5102e-04, test_loss 4.1535e-04\n",
      "step 226, train_loss 3.4878e-04, test_loss 4.1274e-04\n",
      "step 227, train_loss 3.4662e-04, test_loss 4.1022e-04\n",
      "step 228, train_loss 3.4453e-04, test_loss 4.0784e-04\n",
      "step 229, train_loss 3.4249e-04, test_loss 4.0528e-04\n",
      "step 230, train_loss 3.4049e-04, test_loss 4.0302e-04\n",
      "step 231, train_loss 3.3851e-04, test_loss 4.0042e-04\n",
      "step 232, train_loss 3.3653e-04, test_loss 3.9823e-04\n",
      "step 233, train_loss 3.3458e-04, test_loss 3.9562e-04\n",
      "step 234, train_loss 3.3263e-04, test_loss 3.9352e-04\n",
      "step 235, train_loss 3.3072e-04, test_loss 3.9095e-04\n",
      "step 236, train_loss 3.2882e-04, test_loss 3.8898e-04\n",
      "step 237, train_loss 3.2698e-04, test_loss 3.8648e-04\n",
      "step 238, train_loss 3.2518e-04, test_loss 3.8475e-04\n",
      "step 239, train_loss 3.2348e-04, test_loss 3.8239e-04\n",
      "step 240, train_loss 3.2188e-04, test_loss 3.8110e-04\n",
      "step 241, train_loss 3.2049e-04, test_loss 3.7908e-04\n",
      "step 242, train_loss 3.1937e-04, test_loss 3.7878e-04\n",
      "step 243, train_loss 3.1877e-04, test_loss 3.7781e-04\n",
      "step 244, train_loss 3.1897e-04, test_loss 3.8018e-04\n",
      "step 245, train_loss 3.2067e-04, test_loss 3.8272e-04\n",
      "step 246, train_loss 3.2489e-04, test_loss 3.9298e-04\n",
      "step 247, train_loss 3.3384e-04, test_loss 4.0753e-04\n",
      "step 248, train_loss 3.5100e-04, test_loss 4.4215e-04\n",
      "step 249, train_loss 3.8313e-04, test_loss 4.9463e-04\n",
      "step 250, train_loss 4.3992e-04, test_loss 5.9422e-04\n",
      "step 251, train_loss 5.3498e-04, test_loss 7.2484e-04\n",
      "step 252, train_loss 6.7260e-04, test_loss 8.8641e-04\n",
      "step 253, train_loss 8.2680e-04, test_loss 9.5119e-04\n",
      "step 254, train_loss 9.0051e-04, test_loss 8.4740e-04\n",
      "step 255, train_loss 7.8771e-04, test_loss 5.6977e-04\n",
      "step 256, train_loss 5.1601e-04, test_loss 3.6792e-04\n",
      "step 257, train_loss 3.1033e-04, test_loss 3.8865e-04\n",
      "step 258, train_loss 3.3105e-04, test_loss 5.4533e-04\n",
      "step 259, train_loss 4.9274e-04, test_loss 6.3970e-04\n",
      "step 260, train_loss 5.8236e-04, test_loss 5.4055e-04\n",
      "step 261, train_loss 4.8940e-04, test_loss 3.8467e-04\n",
      "step 262, train_loss 3.3017e-04, test_loss 3.4039e-04\n",
      "step 263, train_loss 2.8710e-04, test_loss 4.2463e-04\n",
      "step 264, train_loss 3.7457e-04, test_loss 5.0199e-04\n",
      "step 265, train_loss 4.4844e-04, test_loss 4.5505e-04\n",
      "step 266, train_loss 4.0606e-04, test_loss 3.6034e-04\n",
      "step 267, train_loss 3.0838e-04, test_loss 3.2830e-04\n",
      "step 268, train_loss 2.7689e-04, test_loss 3.7790e-04\n",
      "step 269, train_loss 3.2856e-04, test_loss 4.2581e-04\n",
      "step 270, train_loss 3.7339e-04, test_loss 3.9594e-04\n",
      "step 271, train_loss 3.4690e-04, test_loss 3.3899e-04\n",
      "step 272, train_loss 2.8772e-04, test_loss 3.2008e-04\n",
      "step 273, train_loss 2.6925e-04, test_loss 3.4923e-04\n",
      "step 274, train_loss 3.0027e-04, test_loss 3.7772e-04\n",
      "step 275, train_loss 3.2654e-04, test_loss 3.5853e-04\n",
      "step 276, train_loss 3.1033e-04, test_loss 3.2401e-04\n",
      "step 277, train_loss 2.7436e-04, test_loss 3.1047e-04\n",
      "step 278, train_loss 2.6146e-04, test_loss 3.2580e-04\n",
      "step 279, train_loss 2.7840e-04, test_loss 3.4405e-04\n",
      "step 280, train_loss 2.9503e-04, test_loss 3.3416e-04\n",
      "step 281, train_loss 2.8763e-04, test_loss 3.1367e-04\n",
      "step 282, train_loss 2.6587e-04, test_loss 3.0143e-04\n",
      "step 283, train_loss 2.5430e-04, test_loss 3.0730e-04\n",
      "step 284, train_loss 2.6114e-04, test_loss 3.1973e-04\n",
      "step 285, train_loss 2.7228e-04, test_loss 3.1718e-04\n",
      "step 286, train_loss 2.7169e-04, test_loss 3.0656e-04\n",
      "step 287, train_loss 2.5974e-04, test_loss 2.9502e-04\n",
      "step 288, train_loss 2.4904e-04, test_loss 2.9417e-04\n",
      "step 289, train_loss 2.4855e-04, test_loss 3.0109e-04\n",
      "step 290, train_loss 2.5473e-04, test_loss 3.0271e-04\n",
      "step 291, train_loss 2.5795e-04, test_loss 2.9959e-04\n",
      "step 292, train_loss 2.5369e-04, test_loss 2.9043e-04\n",
      "step 293, train_loss 2.4576e-04, test_loss 2.8570e-04\n",
      "step 294, train_loss 2.4093e-04, test_loss 2.8637e-04\n",
      "step 295, train_loss 2.4161e-04, test_loss 2.8826e-04\n",
      "step 296, train_loss 2.4462e-04, test_loss 2.8981e-04\n",
      "step 297, train_loss 2.4538e-04, test_loss 2.8537e-04\n",
      "step 298, train_loss 2.4226e-04, test_loss 2.8116e-04\n",
      "step 299, train_loss 2.3749e-04, test_loss 2.7729e-04\n",
      "step 300, train_loss 2.3419e-04, test_loss 2.7648e-04\n",
      "step 301, train_loss 2.3368e-04, test_loss 2.7786e-04\n",
      "step 302, train_loss 2.3474e-04, test_loss 2.7738e-04\n",
      "step 303, train_loss 2.3519e-04, test_loss 2.7670e-04\n",
      "step 304, train_loss 2.3384e-04, test_loss 2.7306e-04\n",
      "step 305, train_loss 2.3110e-04, test_loss 2.7062e-04\n",
      "step 306, train_loss 2.2834e-04, test_loss 2.6853e-04\n",
      "step 307, train_loss 2.2664e-04, test_loss 2.6772e-04\n",
      "step 308, train_loss 2.2615e-04, test_loss 2.6788e-04\n",
      "step 309, train_loss 2.2618e-04, test_loss 2.6681e-04\n",
      "step 310, train_loss 2.2587e-04, test_loss 2.6609e-04\n",
      "step 311, train_loss 2.2480e-04, test_loss 2.6361e-04\n",
      "step 312, train_loss 2.2308e-04, test_loss 2.6195e-04\n",
      "step 313, train_loss 2.2122e-04, test_loss 2.5992e-04\n",
      "step 314, train_loss 2.1965e-04, test_loss 2.5874e-04\n",
      "step 315, train_loss 2.1860e-04, test_loss 2.5801e-04\n",
      "step 316, train_loss 2.1796e-04, test_loss 2.5709e-04\n",
      "step 317, train_loss 2.1745e-04, test_loss 2.5662e-04\n",
      "step 318, train_loss 2.1683e-04, test_loss 2.5519e-04\n",
      "step 319, train_loss 2.1593e-04, test_loss 2.5424e-04\n",
      "step 320, train_loss 2.1479e-04, test_loss 2.5248e-04\n",
      "step 321, train_loss 2.1351e-04, test_loss 2.5126e-04\n",
      "step 322, train_loss 2.1224e-04, test_loss 2.4977e-04\n",
      "step 323, train_loss 2.1107e-04, test_loss 2.4862e-04\n",
      "step 324, train_loss 2.1005e-04, test_loss 2.4760e-04\n",
      "step 325, train_loss 2.0918e-04, test_loss 2.4651e-04\n",
      "step 326, train_loss 2.0841e-04, test_loss 2.4578e-04\n",
      "step 327, train_loss 2.0767e-04, test_loss 2.4460e-04\n",
      "step 328, train_loss 2.0692e-04, test_loss 2.4392e-04\n",
      "step 329, train_loss 2.0614e-04, test_loss 2.4261e-04\n",
      "step 330, train_loss 2.0531e-04, test_loss 2.4187e-04\n",
      "step 331, train_loss 2.0444e-04, test_loss 2.4050e-04\n",
      "step 332, train_loss 2.0353e-04, test_loss 2.3971e-04\n",
      "step 333, train_loss 2.0262e-04, test_loss 2.3836e-04\n",
      "step 334, train_loss 2.0170e-04, test_loss 2.3754e-04\n",
      "step 335, train_loss 2.0079e-04, test_loss 2.3625e-04\n",
      "step 336, train_loss 1.9989e-04, test_loss 2.3544e-04\n",
      "step 337, train_loss 1.9902e-04, test_loss 2.3421e-04\n",
      "step 338, train_loss 1.9816e-04, test_loss 2.3342e-04\n",
      "step 339, train_loss 1.9732e-04, test_loss 2.3223e-04\n",
      "step 340, train_loss 1.9650e-04, test_loss 2.3151e-04\n",
      "step 341, train_loss 1.9572e-04, test_loss 2.3033e-04\n",
      "step 342, train_loss 1.9496e-04, test_loss 2.2978e-04\n",
      "step 343, train_loss 1.9426e-04, test_loss 2.2864e-04\n",
      "step 344, train_loss 1.9365e-04, test_loss 2.2848e-04\n",
      "step 345, train_loss 1.9319e-04, test_loss 2.2757e-04\n",
      "step 346, train_loss 1.9302e-04, test_loss 2.2857e-04\n",
      "step 347, train_loss 1.9341e-04, test_loss 2.2892e-04\n",
      "step 348, train_loss 1.9494e-04, test_loss 2.3396e-04\n",
      "step 349, train_loss 1.9874e-04, test_loss 2.4046e-04\n",
      "step 350, train_loss 2.0731e-04, test_loss 2.6134e-04\n",
      "step 351, train_loss 2.2572e-04, test_loss 2.9605e-04\n",
      "step 352, train_loss 2.6434e-04, test_loss 3.7909e-04\n",
      "step 353, train_loss 3.4246e-04, test_loss 5.1690e-04\n",
      "step 354, train_loss 4.8781e-04, test_loss 7.5431e-04\n",
      "step 355, train_loss 7.1616e-04, test_loss 9.7692e-04\n",
      "step 356, train_loss 9.5081e-04, test_loss 1.0169e-03\n",
      "step 357, train_loss 9.7790e-04, test_loss 6.7659e-04\n",
      "step 358, train_loss 6.4724e-04, test_loss 2.9924e-04\n",
      "step 359, train_loss 2.6295e-04, test_loss 2.8329e-04\n",
      "step 360, train_loss 2.4655e-04, test_loss 5.4665e-04\n",
      "step 361, train_loss 5.1810e-04, test_loss 6.7051e-04\n",
      "step 362, train_loss 6.3275e-04, test_loss 4.4265e-04\n",
      "step 363, train_loss 4.1451e-04, test_loss 2.4719e-04\n",
      "step 364, train_loss 2.1381e-04, test_loss 3.3993e-04\n",
      "step 365, train_loss 3.0673e-04, test_loss 4.8874e-04\n",
      "step 366, train_loss 4.6081e-04, test_loss 4.1534e-04\n",
      "step 367, train_loss 3.8162e-04, test_loss 2.3808e-04\n",
      "step 368, train_loss 2.0705e-04, test_loss 2.4823e-04\n",
      "step 369, train_loss 2.1832e-04, test_loss 3.6835e-04\n",
      "step 370, train_loss 3.3382e-04, test_loss 3.3972e-04\n",
      "step 371, train_loss 3.1102e-04, test_loss 2.2746e-04\n",
      "step 372, train_loss 1.9473e-04, test_loss 2.2199e-04\n",
      "step 373, train_loss 1.8947e-04, test_loss 2.9933e-04\n",
      "step 374, train_loss 2.7081e-04, test_loss 3.0237e-04\n",
      "step 375, train_loss 2.6921e-04, test_loss 2.2315e-04\n",
      "step 376, train_loss 1.9386e-04, test_loss 2.1400e-04\n",
      "step 377, train_loss 1.8391e-04, test_loss 2.6879e-04\n",
      "step 378, train_loss 2.3723e-04, test_loss 2.6903e-04\n",
      "step 379, train_loss 2.4044e-04, test_loss 2.2024e-04\n",
      "step 380, train_loss 1.8958e-04, test_loss 2.0793e-04\n",
      "step 381, train_loss 1.7701e-04, test_loss 2.3868e-04\n",
      "step 382, train_loss 2.1042e-04, test_loss 2.4726e-04\n",
      "step 383, train_loss 2.1554e-04, test_loss 2.1072e-04\n",
      "step 384, train_loss 1.8194e-04, test_loss 1.9904e-04\n",
      "step 385, train_loss 1.6931e-04, test_loss 2.2030e-04\n",
      "step 386, train_loss 1.8994e-04, test_loss 2.2497e-04\n",
      "step 387, train_loss 1.9671e-04, test_loss 2.0553e-04\n",
      "step 388, train_loss 1.7580e-04, test_loss 1.9340e-04\n",
      "step 389, train_loss 1.6406e-04, test_loss 2.0398e-04\n",
      "step 390, train_loss 1.7604e-04, test_loss 2.1371e-04\n",
      "step 391, train_loss 1.8368e-04, test_loss 1.9994e-04\n",
      "step 392, train_loss 1.7201e-04, test_loss 1.9063e-04\n",
      "step 393, train_loss 1.6160e-04, test_loss 1.9642e-04\n",
      "step 394, train_loss 1.6733e-04, test_loss 2.0286e-04\n",
      "step 395, train_loss 1.7488e-04, test_loss 1.9902e-04\n",
      "step 396, train_loss 1.7007e-04, test_loss 1.9067e-04\n",
      "step 397, train_loss 1.6223e-04, test_loss 1.9204e-04\n",
      "step 398, train_loss 1.6445e-04, test_loss 2.0122e-04\n",
      "step 399, train_loss 1.7218e-04, test_loss 2.0133e-04\n",
      "step 400, train_loss 1.7449e-04, test_loss 2.0220e-04\n",
      "step 401, train_loss 1.7357e-04, test_loss 2.0727e-04\n",
      "step 402, train_loss 1.8011e-04, test_loss 2.2532e-04\n",
      "step 403, train_loss 1.9732e-04, test_loss 2.4811e-04\n",
      "step 404, train_loss 2.2108e-04, test_loss 2.8215e-04\n",
      "step 405, train_loss 2.5377e-04, test_loss 3.3316e-04\n",
      "step 406, train_loss 3.0745e-04, test_loss 4.2406e-04\n",
      "step 407, train_loss 3.9462e-04, test_loss 5.3908e-04\n",
      "step 408, train_loss 5.1516e-04, test_loss 6.8408e-04\n",
      "step 409, train_loss 6.5408e-04, test_loss 7.8644e-04\n",
      "step 410, train_loss 7.6325e-04, test_loss 8.0206e-04\n",
      "step 411, train_loss 7.7203e-04, test_loss 6.4684e-04\n",
      "step 412, train_loss 6.2185e-04, test_loss 4.0221e-04\n",
      "step 413, train_loss 3.7238e-04, test_loss 2.0913e-04\n",
      "step 414, train_loss 1.8124e-04, test_loss 1.9228e-04\n",
      "step 415, train_loss 1.6459e-04, test_loss 3.1433e-04\n",
      "step 416, train_loss 2.8595e-04, test_loss 4.3204e-04\n",
      "step 417, train_loss 4.0778e-04, test_loss 4.4336e-04\n",
      "step 418, train_loss 4.1579e-04, test_loss 3.2983e-04\n",
      "step 419, train_loss 3.0630e-04, test_loss 2.1050e-04\n",
      "step 420, train_loss 1.8398e-04, test_loss 1.7528e-04\n",
      "step 421, train_loss 1.4994e-04, test_loss 2.3272e-04\n",
      "step 422, train_loss 2.0832e-04, test_loss 3.0667e-04\n",
      "step 423, train_loss 2.7981e-04, test_loss 3.1053e-04\n",
      "step 424, train_loss 2.8699e-04, test_loss 2.5307e-04\n",
      "step 425, train_loss 2.2586e-04, test_loss 1.8451e-04\n",
      "step 426, train_loss 1.5917e-04, test_loss 1.7218e-04\n",
      "step 427, train_loss 1.4632e-04, test_loss 2.1096e-04\n",
      "step 428, train_loss 1.8402e-04, test_loss 2.4541e-04\n",
      "step 429, train_loss 2.2116e-04, test_loss 2.4430e-04\n",
      "step 430, train_loss 2.1751e-04, test_loss 2.0414e-04\n",
      "step 431, train_loss 1.7971e-04, test_loss 1.7181e-04\n",
      "step 432, train_loss 1.4646e-04, test_loss 1.6982e-04\n",
      "step 433, train_loss 1.4450e-04, test_loss 1.9001e-04\n",
      "step 434, train_loss 1.6620e-04, test_loss 2.0970e-04\n",
      "step 435, train_loss 1.8430e-04, test_loss 2.0408e-04\n",
      "step 436, train_loss 1.8053e-04, test_loss 1.8491e-04\n",
      "step 437, train_loss 1.6004e-04, test_loss 1.6627e-04\n",
      "step 438, train_loss 1.4194e-04, test_loss 1.6410e-04\n",
      "step 439, train_loss 1.3987e-04, test_loss 1.7590e-04\n",
      "step 440, train_loss 1.5096e-04, test_loss 1.8543e-04\n",
      "step 441, train_loss 1.6156e-04, test_loss 1.8614e-04\n",
      "step 442, train_loss 1.6115e-04, test_loss 1.7472e-04\n",
      "step 443, train_loss 1.5071e-04, test_loss 1.6429e-04\n",
      "step 444, train_loss 1.3968e-04, test_loss 1.6041e-04\n",
      "step 445, train_loss 1.3613e-04, test_loss 1.6434e-04\n",
      "step 446, train_loss 1.4042e-04, test_loss 1.7096e-04\n",
      "step 447, train_loss 1.4662e-04, test_loss 1.7207e-04\n",
      "step 448, train_loss 1.4872e-04, test_loss 1.6934e-04\n",
      "step 449, train_loss 1.4521e-04, test_loss 1.6229e-04\n",
      "step 450, train_loss 1.3906e-04, test_loss 1.5826e-04\n",
      "step 451, train_loss 1.3456e-04, test_loss 1.5747e-04\n",
      "step 452, train_loss 1.3397e-04, test_loss 1.5960e-04\n",
      "step 453, train_loss 1.3639e-04, test_loss 1.6289e-04\n",
      "step 454, train_loss 1.3912e-04, test_loss 1.6276e-04\n",
      "step 455, train_loss 1.3977e-04, test_loss 1.6163e-04\n",
      "step 456, train_loss 1.3786e-04, test_loss 1.5778e-04\n",
      "step 457, train_loss 1.3467e-04, test_loss 1.5553e-04\n",
      "step 458, train_loss 1.3208e-04, test_loss 1.5453e-04\n",
      "step 459, train_loss 1.3121e-04, test_loss 1.5489e-04\n",
      "step 460, train_loss 1.3189e-04, test_loss 1.5642e-04\n",
      "step 461, train_loss 1.3309e-04, test_loss 1.5643e-04\n",
      "step 462, train_loss 1.3376e-04, test_loss 1.5648e-04\n",
      "step 463, train_loss 1.3338e-04, test_loss 1.5468e-04\n",
      "step 464, train_loss 1.3212e-04, test_loss 1.5336e-04\n",
      "step 465, train_loss 1.3055e-04, test_loss 1.5187e-04\n",
      "step 466, train_loss 1.2927e-04, test_loss 1.5120e-04\n",
      "step 467, train_loss 1.2863e-04, test_loss 1.5125e-04\n",
      "step 468, train_loss 1.2860e-04, test_loss 1.5134e-04\n",
      "step 469, train_loss 1.2891e-04, test_loss 1.5183e-04\n",
      "step 470, train_loss 1.2918e-04, test_loss 1.5148e-04\n",
      "step 471, train_loss 1.2916e-04, test_loss 1.5133e-04\n",
      "step 472, train_loss 1.2875e-04, test_loss 1.5029e-04\n",
      "step 473, train_loss 1.2807e-04, test_loss 1.4970e-04\n",
      "step 474, train_loss 1.2728e-04, test_loss 1.4869e-04\n",
      "step 475, train_loss 1.2656e-04, test_loss 1.4821e-04\n",
      "step 476, train_loss 1.2600e-04, test_loss 1.4771e-04\n",
      "step 477, train_loss 1.2564e-04, test_loss 1.4742e-04\n",
      "step 478, train_loss 1.2545e-04, test_loss 1.4737e-04\n",
      "step 479, train_loss 1.2536e-04, test_loss 1.4707e-04\n",
      "step 480, train_loss 1.2528e-04, test_loss 1.4714e-04\n",
      "step 481, train_loss 1.2517e-04, test_loss 1.4665e-04\n",
      "step 482, train_loss 1.2499e-04, test_loss 1.4661e-04\n",
      "step 483, train_loss 1.2472e-04, test_loss 1.4598e-04\n",
      "step 484, train_loss 1.2438e-04, test_loss 1.4579e-04\n",
      "step 485, train_loss 1.2401e-04, test_loss 1.4516e-04\n",
      "step 486, train_loss 1.2361e-04, test_loss 1.4487e-04\n",
      "step 487, train_loss 1.2322e-04, test_loss 1.4430e-04\n",
      "step 488, train_loss 1.2283e-04, test_loss 1.4399e-04\n",
      "step 489, train_loss 1.2247e-04, test_loss 1.4351e-04\n",
      "step 490, train_loss 1.2214e-04, test_loss 1.4321e-04\n",
      "step 491, train_loss 1.2182e-04, test_loss 1.4280e-04\n",
      "step 492, train_loss 1.2153e-04, test_loss 1.4251e-04\n",
      "step 493, train_loss 1.2126e-04, test_loss 1.4218e-04\n",
      "step 494, train_loss 1.2099e-04, test_loss 1.4188e-04\n",
      "step 495, train_loss 1.2074e-04, test_loss 1.4160e-04\n",
      "step 496, train_loss 1.2049e-04, test_loss 1.4129e-04\n",
      "step 497, train_loss 1.2026e-04, test_loss 1.4107e-04\n",
      "step 498, train_loss 1.2002e-04, test_loss 1.4072e-04\n",
      "step 499, train_loss 1.1980e-04, test_loss 1.4056e-04\n",
      "step 500, train_loss 1.1958e-04, test_loss 1.4020e-04\n",
      "step 501, train_loss 1.1938e-04, test_loss 1.4010e-04\n",
      "step 502, train_loss 1.1920e-04, test_loss 1.3976e-04\n",
      "step 503, train_loss 1.1905e-04, test_loss 1.3977e-04\n",
      "step 504, train_loss 1.1895e-04, test_loss 1.3949e-04\n",
      "step 505, train_loss 1.1892e-04, test_loss 1.3977e-04\n",
      "step 506, train_loss 1.1900e-04, test_loss 1.3969e-04\n",
      "step 507, train_loss 1.1927e-04, test_loss 1.4058e-04\n",
      "step 508, train_loss 1.1984e-04, test_loss 1.4115e-04\n",
      "step 509, train_loss 1.2092e-04, test_loss 1.4363e-04\n",
      "step 510, train_loss 1.2285e-04, test_loss 1.4622e-04\n",
      "step 511, train_loss 1.2625e-04, test_loss 1.5304e-04\n",
      "step 512, train_loss 1.3215e-04, test_loss 1.6201e-04\n",
      "step 513, train_loss 1.4242e-04, test_loss 1.8149e-04\n",
      "step 514, train_loss 1.6034e-04, test_loss 2.1044e-04\n",
      "step 515, train_loss 1.9150e-04, test_loss 2.6706e-04\n",
      "step 516, train_loss 2.4546e-04, test_loss 3.5437e-04\n",
      "step 517, train_loss 3.3658e-04, test_loss 5.0682e-04\n",
      "step 518, train_loss 4.8455e-04, test_loss 7.1771e-04\n",
      "step 519, train_loss 7.0177e-04, test_loss 9.9340e-04\n",
      "step 520, train_loss 9.7035e-04, test_loss 1.1959e-03\n",
      "step 521, train_loss 1.1814e-03, test_loss 1.1847e-03\n",
      "step 522, train_loss 1.1605e-03, test_loss 8.2230e-04\n",
      "step 523, train_loss 8.0493e-04, test_loss 3.5849e-04\n",
      "step 524, train_loss 3.3395e-04, test_loss 1.3730e-04\n",
      "step 525, train_loss 1.1484e-04, test_loss 2.8399e-04\n",
      "step 526, train_loss 2.6408e-04, test_loss 5.6061e-04\n",
      "step 527, train_loss 5.3797e-04, test_loss 6.2485e-04\n",
      "step 528, train_loss 6.0929e-04, test_loss 4.2358e-04\n",
      "step 529, train_loss 4.0266e-04, test_loss 1.7601e-04\n",
      "step 530, train_loss 1.5848e-04, test_loss 1.5210e-04\n",
      "step 531, train_loss 1.3411e-04, test_loss 3.1273e-04\n",
      "step 532, train_loss 2.9286e-04, test_loss 4.1067e-04\n",
      "step 533, train_loss 3.9486e-04, test_loss 3.3046e-04\n",
      "step 534, train_loss 3.0975e-04, test_loss 1.7332e-04\n",
      "step 535, train_loss 1.5487e-04, test_loss 1.3722e-04\n",
      "step 536, train_loss 1.1747e-04, test_loss 2.2808e-04\n",
      "step 537, train_loss 2.0705e-04, test_loss 2.9333e-04\n",
      "step 538, train_loss 2.7534e-04, test_loss 2.5027e-04\n",
      "step 539, train_loss 2.2912e-04, test_loss 1.5535e-04\n",
      "step 540, train_loss 1.3651e-04, test_loss 1.3298e-04\n",
      "step 541, train_loss 1.1367e-04, test_loss 1.8732e-04\n",
      "step 542, train_loss 1.6751e-04, test_loss 2.2525e-04\n",
      "step 543, train_loss 2.0793e-04, test_loss 1.9905e-04\n",
      "step 544, train_loss 1.7955e-04, test_loss 1.4207e-04\n",
      "step 545, train_loss 1.2428e-04, test_loss 1.2909e-04\n",
      "step 546, train_loss 1.1078e-04, test_loss 1.6178e-04\n",
      "step 547, train_loss 1.4285e-04, test_loss 1.8477e-04\n",
      "step 548, train_loss 1.6736e-04, test_loss 1.7045e-04\n",
      "step 549, train_loss 1.5118e-04, test_loss 1.3619e-04\n",
      "step 550, train_loss 1.1796e-04, test_loss 1.2701e-04\n",
      "step 551, train_loss 1.0826e-04, test_loss 1.4565e-04\n",
      "step 552, train_loss 1.2638e-04, test_loss 1.6045e-04\n",
      "step 553, train_loss 1.4233e-04, test_loss 1.5415e-04\n",
      "step 554, train_loss 1.3480e-04, test_loss 1.3323e-04\n",
      "step 555, train_loss 1.1487e-04, test_loss 1.2501e-04\n",
      "step 556, train_loss 1.0645e-04, test_loss 1.3408e-04\n",
      "step 557, train_loss 1.1536e-04, test_loss 1.4395e-04\n",
      "step 558, train_loss 1.2625e-04, test_loss 1.4317e-04\n",
      "step 559, train_loss 1.2464e-04, test_loss 1.3104e-04\n",
      "step 560, train_loss 1.1333e-04, test_loss 1.2372e-04\n",
      "step 561, train_loss 1.0572e-04, test_loss 1.2668e-04\n",
      "step 562, train_loss 1.0848e-04, test_loss 1.3317e-04\n",
      "step 563, train_loss 1.1553e-04, test_loss 1.3583e-04\n",
      "step 564, train_loss 1.1735e-04, test_loss 1.2999e-04\n",
      "step 565, train_loss 1.1210e-04, test_loss 1.2435e-04\n",
      "step 566, train_loss 1.0601e-04, test_loss 1.2338e-04\n",
      "step 567, train_loss 1.0502e-04, test_loss 1.2649e-04\n",
      "step 568, train_loss 1.0854e-04, test_loss 1.2989e-04\n",
      "step 569, train_loss 1.1143e-04, test_loss 1.2801e-04\n",
      "step 570, train_loss 1.1027e-04, test_loss 1.2461e-04\n",
      "step 571, train_loss 1.0650e-04, test_loss 1.2176e-04\n",
      "step 572, train_loss 1.0394e-04, test_loss 1.2207e-04\n",
      "step 573, train_loss 1.0446e-04, test_loss 1.2449e-04\n",
      "step 574, train_loss 1.0657e-04, test_loss 1.2494e-04\n",
      "step 575, train_loss 1.0755e-04, test_loss 1.2424e-04\n",
      "step 576, train_loss 1.0634e-04, test_loss 1.2176e-04\n",
      "step 577, train_loss 1.0418e-04, test_loss 1.2072e-04\n",
      "step 578, train_loss 1.0296e-04, test_loss 1.2122e-04\n",
      "step 579, train_loss 1.0335e-04, test_loss 1.2202e-04\n",
      "step 580, train_loss 1.0443e-04, test_loss 1.2283e-04\n",
      "step 581, train_loss 1.0487e-04, test_loss 1.2172e-04\n",
      "step 582, train_loss 1.0419e-04, test_loss 1.2076e-04\n",
      "step 583, train_loss 1.0298e-04, test_loss 1.1972e-04\n",
      "step 584, train_loss 1.0216e-04, test_loss 1.1965e-04\n",
      "step 585, train_loss 1.0216e-04, test_loss 1.2023e-04\n",
      "step 586, train_loss 1.0264e-04, test_loss 1.2025e-04\n",
      "step 587, train_loss 1.0295e-04, test_loss 1.2026e-04\n",
      "step 588, train_loss 1.0271e-04, test_loss 1.1936e-04\n",
      "step 589, train_loss 1.0208e-04, test_loss 1.1891e-04\n",
      "step 590, train_loss 1.0146e-04, test_loss 1.1857e-04\n",
      "step 591, train_loss 1.0119e-04, test_loss 1.1860e-04\n",
      "step 592, train_loss 1.0127e-04, test_loss 1.1890e-04\n",
      "step 593, train_loss 1.0145e-04, test_loss 1.1873e-04\n",
      "step 594, train_loss 1.0147e-04, test_loss 1.1864e-04\n",
      "step 595, train_loss 1.0123e-04, test_loss 1.1808e-04\n",
      "step 596, train_loss 1.0084e-04, test_loss 1.1778e-04\n",
      "step 597, train_loss 1.0048e-04, test_loss 1.1753e-04\n",
      "step 598, train_loss 1.0029e-04, test_loss 1.1742e-04\n",
      "step 599, train_loss 1.0026e-04, test_loss 1.1751e-04\n",
      "step 600, train_loss 1.0028e-04, test_loss 1.1732e-04\n",
      "step 601, train_loss 1.0025e-04, test_loss 1.1728e-04\n",
      "step 602, train_loss 1.0010e-04, test_loss 1.1691e-04\n",
      "step 603, train_loss 9.9876e-05, test_loss 1.1673e-04\n",
      "step 604, train_loss 9.9631e-05, test_loss 1.1648e-04\n",
      "step 605, train_loss 9.9435e-05, test_loss 1.1633e-04\n",
      "step 606, train_loss 9.9314e-05, test_loss 1.1631e-04\n",
      "step 607, train_loss 9.9247e-05, test_loss 1.1615e-04\n",
      "step 608, train_loss 9.9193e-05, test_loss 1.1616e-04\n",
      "step 609, train_loss 9.9112e-05, test_loss 1.1590e-04\n",
      "step 610, train_loss 9.8989e-05, test_loss 1.1583e-04\n",
      "step 611, train_loss 9.8830e-05, test_loss 1.1554e-04\n",
      "step 612, train_loss 9.8660e-05, test_loss 1.1542e-04\n",
      "step 613, train_loss 9.8500e-05, test_loss 1.1521e-04\n",
      "step 614, train_loss 9.8368e-05, test_loss 1.1509e-04\n",
      "step 615, train_loss 9.8260e-05, test_loss 1.1498e-04\n",
      "step 616, train_loss 9.8169e-05, test_loss 1.1485e-04\n",
      "step 617, train_loss 9.8081e-05, test_loss 1.1477e-04\n",
      "step 618, train_loss 9.7986e-05, test_loss 1.1461e-04\n",
      "step 619, train_loss 9.7878e-05, test_loss 1.1450e-04\n",
      "step 620, train_loss 9.7759e-05, test_loss 1.1435e-04\n",
      "step 621, train_loss 9.7634e-05, test_loss 1.1420e-04\n",
      "step 622, train_loss 9.7512e-05, test_loss 1.1410e-04\n",
      "step 623, train_loss 9.7396e-05, test_loss 1.1391e-04\n",
      "step 624, train_loss 9.7294e-05, test_loss 1.1390e-04\n",
      "step 625, train_loss 9.7207e-05, test_loss 1.1368e-04\n",
      "step 626, train_loss 9.7144e-05, test_loss 1.1379e-04\n",
      "step 627, train_loss 9.7103e-05, test_loss 1.1354e-04\n",
      "step 628, train_loss 9.7110e-05, test_loss 1.1388e-04\n",
      "step 629, train_loss 9.7178e-05, test_loss 1.1369e-04\n",
      "step 630, train_loss 9.7373e-05, test_loss 1.1452e-04\n",
      "step 631, train_loss 9.7761e-05, test_loss 1.1469e-04\n",
      "step 632, train_loss 9.8532e-05, test_loss 1.1682e-04\n",
      "step 633, train_loss 9.9940e-05, test_loss 1.1846e-04\n",
      "step 634, train_loss 1.0256e-04, test_loss 1.2446e-04\n",
      "step 635, train_loss 1.0732e-04, test_loss 1.3154e-04\n",
      "step 636, train_loss 1.1611e-04, test_loss 1.4979e-04\n",
      "step 637, train_loss 1.3217e-04, test_loss 1.7628e-04\n",
      "step 638, train_loss 1.6171e-04, test_loss 2.3382e-04\n",
      "step 639, train_loss 2.1533e-04, test_loss 3.2324e-04\n",
      "step 640, train_loss 3.1028e-04, test_loss 4.8955e-04\n",
      "step 641, train_loss 4.6970e-04, test_loss 7.1679e-04\n",
      "step 642, train_loss 7.0647e-04, test_loss 1.0073e-03\n",
      "step 643, train_loss 9.8576e-04, test_loss 1.1616e-03\n",
      "step 644, train_loss 1.1531e-03, test_loss 1.0316e-03\n",
      "step 645, train_loss 1.0090e-03, test_loss 5.6432e-04\n",
      "step 646, train_loss 5.5144e-04, test_loss 1.7375e-04\n",
      "step 647, train_loss 1.5377e-04, test_loss 1.6644e-04\n",
      "step 648, train_loss 1.4755e-04, test_loss 4.3844e-04\n",
      "step 649, train_loss 4.2590e-04, test_loss 6.2012e-04\n",
      "step 650, train_loss 6.0073e-04, test_loss 4.5932e-04\n",
      "step 651, train_loss 4.4849e-04, test_loss 1.8776e-04\n",
      "step 652, train_loss 1.7079e-04, test_loss 1.2247e-04\n",
      "step 653, train_loss 1.0651e-04, test_loss 2.8401e-04\n",
      "step 654, train_loss 2.7126e-04, test_loss 4.0255e-04\n",
      "step 655, train_loss 3.8380e-04, test_loss 2.9298e-04\n",
      "step 656, train_loss 2.7959e-04, test_loss 1.3611e-04\n",
      "step 657, train_loss 1.1857e-04, test_loss 1.3299e-04\n",
      "step 658, train_loss 1.1537e-04, test_loss 2.4168e-04\n",
      "step 659, train_loss 2.2791e-04, test_loss 2.7972e-04\n",
      "step 660, train_loss 2.6137e-04, test_loss 1.8277e-04\n",
      "step 661, train_loss 1.6884e-04, test_loss 1.0923e-04\n",
      "step 662, train_loss 9.3511e-05, test_loss 1.4568e-04\n",
      "step 663, train_loss 1.2907e-04, test_loss 2.0676e-04\n",
      "step 664, train_loss 1.9373e-04, test_loss 1.9735e-04\n",
      "step 665, train_loss 1.8013e-04, test_loss 1.2862e-04\n",
      "step 666, train_loss 1.1408e-04, test_loss 1.0883e-04\n",
      "step 667, train_loss 9.3358e-05, test_loss 1.4962e-04\n",
      "step 668, train_loss 1.3262e-04, test_loss 1.7195e-04\n",
      "step 669, train_loss 1.5797e-04, test_loss 1.4699e-04\n",
      "step 670, train_loss 1.3010e-04, test_loss 1.0940e-04\n",
      "step 671, train_loss 9.4260e-05, test_loss 1.1392e-04\n",
      "step 672, train_loss 9.9039e-05, test_loss 1.4243e-04\n",
      "step 673, train_loss 1.2605e-04, test_loss 1.4322e-04\n",
      "step 674, train_loss 1.2922e-04, test_loss 1.2127e-04\n",
      "step 675, train_loss 1.0528e-04, test_loss 1.0560e-04\n",
      "step 676, train_loss 9.0244e-05, test_loss 1.1562e-04\n",
      "step 677, train_loss 1.0090e-04, test_loss 1.3155e-04\n",
      "step 678, train_loss 1.1514e-04, test_loss 1.2491e-04\n",
      "step 679, train_loss 1.1039e-04, test_loss 1.1071e-04\n",
      "step 680, train_loss 9.4868e-05, test_loss 1.0578e-04\n",
      "step 681, train_loss 9.0282e-05, test_loss 1.1386e-04\n",
      "step 682, train_loss 9.9291e-05, test_loss 1.2161e-04\n",
      "step 683, train_loss 1.0568e-04, test_loss 1.1449e-04\n",
      "step 684, train_loss 1.0011e-04, test_loss 1.0648e-04\n",
      "step 685, train_loss 9.1130e-05, test_loss 1.0557e-04\n",
      "step 686, train_loss 9.0317e-05, test_loss 1.1090e-04\n",
      "step 687, train_loss 9.6263e-05, test_loss 1.1481e-04\n",
      "step 688, train_loss 9.9026e-05, test_loss 1.0965e-04\n",
      "step 689, train_loss 9.4871e-05, test_loss 1.0514e-04\n",
      "step 690, train_loss 8.9744e-05, test_loss 1.0518e-04\n",
      "step 691, train_loss 8.9777e-05, test_loss 1.0809e-04\n",
      "step 692, train_loss 9.3369e-05, test_loss 1.1031e-04\n",
      "step 693, train_loss 9.4769e-05, test_loss 1.0681e-04\n",
      "step 694, train_loss 9.2186e-05, test_loss 1.0418e-04\n",
      "step 695, train_loss 8.9114e-05, test_loss 1.0409e-04\n",
      "step 696, train_loss 8.9036e-05, test_loss 1.0571e-04\n",
      "step 697, train_loss 9.1119e-05, test_loss 1.0744e-04\n",
      "step 698, train_loss 9.2098e-05, test_loss 1.0542e-04\n",
      "step 699, train_loss 9.0737e-05, test_loss 1.0398e-04\n",
      "step 700, train_loss 8.8798e-05, test_loss 1.0352e-04\n",
      "step 701, train_loss 8.8428e-05, test_loss 1.0436e-04\n",
      "step 702, train_loss 8.9524e-05, test_loss 1.0558e-04\n",
      "step 703, train_loss 9.0320e-05, test_loss 1.0450e-04\n",
      "step 704, train_loss 8.9782e-05, test_loss 1.0357e-04\n",
      "step 705, train_loss 8.8568e-05, test_loss 1.0289e-04\n",
      "step 706, train_loss 8.8003e-05, test_loss 1.0308e-04\n",
      "step 707, train_loss 8.8430e-05, test_loss 1.0411e-04\n",
      "step 708, train_loss 8.9047e-05, test_loss 1.0360e-04\n",
      "step 709, train_loss 8.9041e-05, test_loss 1.0345e-04\n",
      "step 710, train_loss 8.8417e-05, test_loss 1.0262e-04\n",
      "step 711, train_loss 8.7881e-05, test_loss 1.0278e-04\n",
      "step 712, train_loss 8.7909e-05, test_loss 1.0324e-04\n",
      "step 713, train_loss 8.8339e-05, test_loss 1.0345e-04\n",
      "step 714, train_loss 8.8675e-05, test_loss 1.0351e-04\n",
      "step 715, train_loss 8.8676e-05, test_loss 1.0344e-04\n",
      "step 716, train_loss 8.8601e-05, test_loss 1.0346e-04\n",
      "step 717, train_loss 8.8888e-05, test_loss 1.0481e-04\n",
      "step 718, train_loss 8.9796e-05, test_loss 1.0568e-04\n",
      "step 719, train_loss 9.1375e-05, test_loss 1.0889e-04\n",
      "step 720, train_loss 9.3700e-05, test_loss 1.1145e-04\n",
      "step 721, train_loss 9.7335e-05, test_loss 1.1878e-04\n",
      "step 722, train_loss 1.0343e-04, test_loss 1.2790e-04\n",
      "step 723, train_loss 1.1401e-04, test_loss 1.4781e-04\n",
      "step 724, train_loss 1.3221e-04, test_loss 1.7664e-04\n",
      "step 725, train_loss 1.6328e-04, test_loss 2.3204e-04\n",
      "step 726, train_loss 2.1594e-04, test_loss 3.1612e-04\n",
      "step 727, train_loss 3.0388e-04, test_loss 4.6377e-04\n",
      "step 728, train_loss 4.4682e-04, test_loss 6.7333e-04\n",
      "step 729, train_loss 6.6304e-04, test_loss 9.7157e-04\n",
      "step 730, train_loss 9.5357e-04, test_loss 1.2564e-03\n",
      "step 731, train_loss 1.2482e-03, test_loss 1.4080e-03\n",
      "step 732, train_loss 1.3887e-03, test_loss 1.1891e-03\n",
      "step 733, train_loss 1.1792e-03, test_loss 6.8509e-04\n",
      "step 734, train_loss 6.6492e-04, test_loss 2.0955e-04\n",
      "step 735, train_loss 1.9363e-04, test_loss 1.2371e-04\n",
      "step 736, train_loss 1.0736e-04, test_loss 3.8742e-04\n",
      "step 737, train_loss 3.6958e-04, test_loss 6.4943e-04\n",
      "step 738, train_loss 6.3960e-04, test_loss 6.3750e-04\n",
      "step 739, train_loss 6.2134e-04, test_loss 3.4998e-04\n",
      "step 740, train_loss 3.3973e-04, test_loss 1.1946e-04\n",
      "step 741, train_loss 1.0553e-04, test_loss 1.4995e-04\n",
      "step 742, train_loss 1.3558e-04, test_loss 3.3304e-04\n",
      "step 743, train_loss 3.2219e-04, test_loss 4.2195e-04\n",
      "step 744, train_loss 4.0566e-04, test_loss 2.9866e-04\n",
      "step 745, train_loss 2.8657e-04, test_loss 1.3695e-04\n",
      "step 746, train_loss 1.2088e-04, test_loss 1.1154e-04\n",
      "step 747, train_loss 9.5739e-05, test_loss 2.1256e-04\n",
      "step 748, train_loss 1.9920e-04, test_loss 2.8627e-04\n",
      "step 749, train_loss 2.6960e-04, test_loss 2.2776e-04\n",
      "step 750, train_loss 2.1521e-04, test_loss 1.2873e-04\n",
      "step 751, train_loss 1.1361e-04, test_loss 1.0107e-04\n",
      "step 752, train_loss 8.6880e-05, test_loss 1.5657e-04\n",
      "step 753, train_loss 1.4421e-04, test_loss 2.0693e-04\n",
      "step 754, train_loss 1.9203e-04, test_loss 1.7847e-04\n",
      "step 755, train_loss 1.6661e-04, test_loss 1.2006e-04\n",
      "step 756, train_loss 1.0573e-04, test_loss 9.7616e-05\n",
      "step 757, train_loss 8.3792e-05, test_loss 1.2751e-04\n",
      "step 758, train_loss 1.1451e-04, test_loss 1.6116e-04\n",
      "step 759, train_loss 1.4601e-04, test_loss 1.4879e-04\n",
      "step 760, train_loss 1.3587e-04, test_loss 1.1505e-04\n",
      "step 761, train_loss 1.0012e-04, test_loss 9.7067e-05\n",
      "step 762, train_loss 8.2808e-05, test_loss 1.1146e-04\n",
      "step 763, train_loss 9.7831e-05, test_loss 1.3334e-04\n",
      "step 764, train_loss 1.1840e-04, test_loss 1.2964e-04\n",
      "step 765, train_loss 1.1670e-04, test_loss 1.1096e-04\n",
      "step 766, train_loss 9.6584e-05, test_loss 9.6322e-05\n",
      "step 767, train_loss 8.2822e-05, test_loss 1.0137e-04\n",
      "step 768, train_loss 8.8182e-05, test_loss 1.1531e-04\n",
      "step 769, train_loss 1.0120e-04, test_loss 1.1687e-04\n",
      "step 770, train_loss 1.0415e-04, test_loss 1.0837e-04\n",
      "step 771, train_loss 9.4237e-05, test_loss 9.7254e-05\n",
      "step 772, train_loss 8.3799e-05, test_loss 9.7098e-05\n",
      "step 773, train_loss 8.3421e-05, test_loss 1.0493e-04\n",
      "step 774, train_loss 9.0618e-05, test_loss 1.0858e-04\n",
      "step 775, train_loss 9.5209e-05, test_loss 1.0635e-04\n",
      "step 776, train_loss 9.1905e-05, test_loss 9.8648e-05\n",
      "step 777, train_loss 8.5056e-05, test_loss 9.5806e-05\n",
      "step 778, train_loss 8.1959e-05, test_loss 9.8489e-05\n",
      "step 779, train_loss 8.4573e-05, test_loss 1.0173e-04\n",
      "step 780, train_loss 8.8546e-05, test_loss 1.0294e-04\n",
      "step 781, train_loss 8.9023e-05, test_loss 9.8892e-05\n",
      "step 782, train_loss 8.5769e-05, test_loss 9.6022e-05\n",
      "step 783, train_loss 8.2387e-05, test_loss 9.5514e-05\n",
      "step 784, train_loss 8.1950e-05, test_loss 9.7377e-05\n",
      "step 785, train_loss 8.4008e-05, test_loss 9.9741e-05\n",
      "step 786, train_loss 8.5780e-05, test_loss 9.8756e-05\n",
      "step 787, train_loss 8.5360e-05, test_loss 9.7302e-05\n",
      "step 788, train_loss 8.3329e-05, test_loss 9.5370e-05\n",
      "step 789, train_loss 8.1725e-05, test_loss 9.5423e-05\n",
      "step 790, train_loss 8.1768e-05, test_loss 9.6740e-05\n",
      "step 791, train_loss 8.2925e-05, test_loss 9.7109e-05\n",
      "step 792, train_loss 8.3764e-05, test_loss 9.7185e-05\n",
      "step 793, train_loss 8.3429e-05, test_loss 9.5632e-05\n",
      "step 794, train_loss 8.2322e-05, test_loss 9.4984e-05\n",
      "step 795, train_loss 8.1435e-05, test_loss 9.4890e-05\n",
      "step 796, train_loss 8.1392e-05, test_loss 9.5342e-05\n",
      "step 797, train_loss 8.1963e-05, test_loss 9.6138e-05\n",
      "step 798, train_loss 8.2451e-05, test_loss 9.5757e-05\n",
      "step 799, train_loss 8.2386e-05, test_loss 9.5559e-05\n",
      "step 800, train_loss 8.1844e-05, test_loss 9.4788e-05\n",
      "step 801, train_loss 8.1295e-05, test_loss 9.4689e-05\n",
      "step 802, train_loss 8.1107e-05, test_loss 9.4908e-05\n",
      "step 803, train_loss 8.1298e-05, test_loss 9.5007e-05\n",
      "step 804, train_loss 8.1588e-05, test_loss 9.5302e-05\n",
      "step 805, train_loss 8.1675e-05, test_loss 9.4838e-05\n",
      "step 806, train_loss 8.1487e-05, test_loss 9.4709e-05\n",
      "step 807, train_loss 8.1163e-05, test_loss 9.4324e-05\n",
      "step 808, train_loss 8.0927e-05, test_loss 9.4320e-05\n",
      "step 809, train_loss 8.0886e-05, test_loss 9.4480e-05\n",
      "step 810, train_loss 8.0993e-05, test_loss 9.4472e-05\n",
      "step 811, train_loss 8.1108e-05, test_loss 9.4655e-05\n",
      "step 812, train_loss 8.1114e-05, test_loss 9.4365e-05\n",
      "step 813, train_loss 8.1000e-05, test_loss 9.4351e-05\n",
      "step 814, train_loss 8.0829e-05, test_loss 9.4113e-05\n",
      "step 815, train_loss 8.0698e-05, test_loss 9.4102e-05\n",
      "step 816, train_loss 8.0651e-05, test_loss 9.4137e-05\n",
      "step 817, train_loss 8.0676e-05, test_loss 9.4088e-05\n",
      "step 818, train_loss 8.0715e-05, test_loss 9.4187e-05\n",
      "step 819, train_loss 8.0717e-05, test_loss 9.3994e-05\n",
      "step 820, train_loss 8.0666e-05, test_loss 9.4011e-05\n",
      "step 821, train_loss 8.0575e-05, test_loss 9.3815e-05\n",
      "step 822, train_loss 8.0485e-05, test_loss 9.3806e-05\n",
      "step 823, train_loss 8.0422e-05, test_loss 9.3757e-05\n",
      "step 824, train_loss 8.0396e-05, test_loss 9.3734e-05\n",
      "step 825, train_loss 8.0393e-05, test_loss 9.3786e-05\n",
      "step 826, train_loss 8.0392e-05, test_loss 9.3695e-05\n",
      "step 827, train_loss 8.0375e-05, test_loss 9.3739e-05\n",
      "step 828, train_loss 8.0335e-05, test_loss 9.3598e-05\n",
      "step 829, train_loss 8.0282e-05, test_loss 9.3605e-05\n",
      "step 830, train_loss 8.0224e-05, test_loss 9.3493e-05\n",
      "step 831, train_loss 8.0175e-05, test_loss 9.3473e-05\n",
      "step 832, train_loss 8.0138e-05, test_loss 9.3430e-05\n",
      "step 833, train_loss 8.0113e-05, test_loss 9.3382e-05\n",
      "step 834, train_loss 8.0093e-05, test_loss 9.3386e-05\n",
      "step 835, train_loss 8.0072e-05, test_loss 9.3306e-05\n",
      "step 836, train_loss 8.0045e-05, test_loss 9.3322e-05\n",
      "step 837, train_loss 8.0011e-05, test_loss 9.3226e-05\n",
      "step 838, train_loss 7.9972e-05, test_loss 9.3234e-05\n",
      "step 839, train_loss 7.9931e-05, test_loss 9.3152e-05\n",
      "step 840, train_loss 7.9893e-05, test_loss 9.3143e-05\n",
      "step 841, train_loss 7.9857e-05, test_loss 9.3088e-05\n",
      "step 842, train_loss 7.9825e-05, test_loss 9.3057e-05\n",
      "step 843, train_loss 7.9796e-05, test_loss 9.3025e-05\n",
      "step 844, train_loss 7.9769e-05, test_loss 9.2972e-05\n",
      "step 845, train_loss 7.9741e-05, test_loss 9.2956e-05\n",
      "step 846, train_loss 7.9712e-05, test_loss 9.2889e-05\n",
      "step 847, train_loss 7.9681e-05, test_loss 9.2880e-05\n",
      "step 848, train_loss 7.9648e-05, test_loss 9.2809e-05\n",
      "step 849, train_loss 7.9615e-05, test_loss 9.2802e-05\n",
      "step 850, train_loss 7.9581e-05, test_loss 9.2736e-05\n",
      "step 851, train_loss 7.9547e-05, test_loss 9.2724e-05\n",
      "step 852, train_loss 7.9514e-05, test_loss 9.2666e-05\n",
      "step 853, train_loss 7.9482e-05, test_loss 9.2645e-05\n",
      "step 854, train_loss 7.9450e-05, test_loss 9.2596e-05\n",
      "step 855, train_loss 7.9420e-05, test_loss 9.2566e-05\n",
      "step 856, train_loss 7.9389e-05, test_loss 9.2525e-05\n",
      "step 857, train_loss 7.9359e-05, test_loss 9.2487e-05\n",
      "step 858, train_loss 7.9329e-05, test_loss 9.2452e-05\n",
      "step 859, train_loss 7.9298e-05, test_loss 9.2409e-05\n",
      "step 860, train_loss 7.9268e-05, test_loss 9.2380e-05\n",
      "step 861, train_loss 7.9238e-05, test_loss 9.2335e-05\n",
      "step 862, train_loss 7.9207e-05, test_loss 9.2308e-05\n",
      "step 863, train_loss 7.9176e-05, test_loss 9.2262e-05\n",
      "step 864, train_loss 7.9146e-05, test_loss 9.2236e-05\n",
      "step 865, train_loss 7.9115e-05, test_loss 9.2189e-05\n",
      "step 866, train_loss 7.9084e-05, test_loss 9.2163e-05\n",
      "step 867, train_loss 7.9054e-05, test_loss 9.2116e-05\n",
      "step 868, train_loss 7.9023e-05, test_loss 9.2090e-05\n",
      "step 869, train_loss 7.8992e-05, test_loss 9.2042e-05\n",
      "step 870, train_loss 7.8962e-05, test_loss 9.2016e-05\n",
      "step 871, train_loss 7.8932e-05, test_loss 9.1969e-05\n",
      "step 872, train_loss 7.8903e-05, test_loss 9.1944e-05\n",
      "step 873, train_loss 7.8874e-05, test_loss 9.1898e-05\n",
      "step 874, train_loss 7.8845e-05, test_loss 9.1876e-05\n",
      "step 875, train_loss 7.8818e-05, test_loss 9.1833e-05\n",
      "step 876, train_loss 7.8792e-05, test_loss 9.1815e-05\n",
      "step 877, train_loss 7.8769e-05, test_loss 9.1778e-05\n",
      "step 878, train_loss 7.8749e-05, test_loss 9.1768e-05\n",
      "step 879, train_loss 7.8734e-05, test_loss 9.1743e-05\n",
      "step 880, train_loss 7.8726e-05, test_loss 9.1751e-05\n",
      "step 881, train_loss 7.8729e-05, test_loss 9.1757e-05\n",
      "step 882, train_loss 7.8751e-05, test_loss 9.1809e-05\n",
      "step 883, train_loss 7.8802e-05, test_loss 9.1895e-05\n",
      "step 884, train_loss 7.8898e-05, test_loss 9.2060e-05\n",
      "step 885, train_loss 7.9071e-05, test_loss 9.2359e-05\n",
      "step 886, train_loss 7.9367e-05, test_loss 9.2837e-05\n",
      "step 887, train_loss 7.9875e-05, test_loss 9.3727e-05\n",
      "step 888, train_loss 8.0731e-05, test_loss 9.5117e-05\n",
      "step 889, train_loss 8.2195e-05, test_loss 9.7712e-05\n",
      "step 890, train_loss 8.4693e-05, test_loss 1.0187e-04\n",
      "step 891, train_loss 8.9020e-05, test_loss 1.0961e-04\n",
      "step 892, train_loss 9.6533e-05, test_loss 1.2242e-04\n",
      "step 893, train_loss 1.0973e-04, test_loss 1.4615e-04\n",
      "step 894, train_loss 1.3295e-04, test_loss 1.8631e-04\n",
      "step 895, train_loss 1.7394e-04, test_loss 2.5902e-04\n",
      "step 896, train_loss 2.4560e-04, test_loss 3.7982e-04\n",
      "step 897, train_loss 3.6813e-04, test_loss 5.8114e-04\n",
      "step 898, train_loss 5.6740e-04, test_loss 8.6985e-04\n",
      "step 899, train_loss 8.5942e-04, test_loss 1.2216e-03\n",
      "step 900, train_loss 1.2074e-03, test_loss 1.4617e-03\n",
      "step 901, train_loss 1.4522e-03, test_loss 1.3643e-03\n",
      "step 902, train_loss 1.3489e-03, test_loss 8.3971e-04\n",
      "step 903, train_loss 8.2746e-04, test_loss 2.6709e-04\n",
      "step 904, train_loss 2.5104e-04, test_loss 1.0363e-04\n",
      "step 905, train_loss 8.8552e-05, test_loss 3.8169e-04\n",
      "step 906, train_loss 3.6984e-04, test_loss 6.9915e-04\n",
      "step 907, train_loss 6.8580e-04, test_loss 6.5900e-04\n",
      "step 908, train_loss 6.4975e-04, test_loss 3.2548e-04\n",
      "step 909, train_loss 3.1319e-04, test_loss 9.5256e-05\n",
      "step 910, train_loss 8.3161e-05, test_loss 1.9514e-04\n",
      "step 911, train_loss 1.8413e-04, test_loss 4.1302e-04\n",
      "step 912, train_loss 3.9901e-04, test_loss 4.1831e-04\n",
      "step 913, train_loss 4.0752e-04, test_loss 2.2294e-04\n",
      "step 914, train_loss 2.0847e-04, test_loss 9.1246e-05\n",
      "step 915, train_loss 7.8141e-05, test_loss 1.6922e-04\n",
      "step 916, train_loss 1.5662e-04, test_loss 2.9345e-04\n",
      "step 917, train_loss 2.8004e-04, test_loss 2.6667e-04\n",
      "step 918, train_loss 2.5539e-04, test_loss 1.4009e-04\n",
      "step 919, train_loss 1.2753e-04, test_loss 8.9567e-05\n",
      "step 920, train_loss 7.7184e-05, test_loss 1.5754e-04\n",
      "step 921, train_loss 1.4635e-04, test_loss 2.1838e-04\n",
      "step 922, train_loss 2.0539e-04, test_loss 1.7518e-04\n",
      "step 923, train_loss 1.6383e-04, test_loss 1.0166e-04\n",
      "step 924, train_loss 8.8917e-05, test_loss 9.5919e-05\n",
      "step 925, train_loss 8.3181e-05, test_loss 1.4576e-04\n",
      "step 926, train_loss 1.3411e-04, test_loss 1.6639e-04\n",
      "step 927, train_loss 1.5335e-04, test_loss 1.2569e-04\n",
      "step 928, train_loss 1.1406e-04, test_loss 8.9001e-05\n",
      "step 929, train_loss 7.6527e-05, test_loss 1.0016e-04\n",
      "step 930, train_loss 8.7752e-05, test_loss 1.3044e-04\n",
      "step 931, train_loss 1.1868e-04, test_loss 1.3169e-04\n",
      "step 932, train_loss 1.1907e-04, test_loss 1.0276e-04\n",
      "step 933, train_loss 9.0653e-05, test_loss 8.6851e-05\n",
      "step 934, train_loss 7.4690e-05, test_loss 1.0052e-04\n",
      "step 935, train_loss 8.7822e-05, test_loss 1.1569e-04\n",
      "step 936, train_loss 1.0418e-04, test_loss 1.1137e-04\n",
      "step 937, train_loss 9.8740e-05, test_loss 9.2590e-05\n",
      "step 938, train_loss 8.0961e-05, test_loss 8.7375e-05\n",
      "step 939, train_loss 7.5230e-05, test_loss 9.7421e-05\n",
      "step 940, train_loss 8.5360e-05, test_loss 1.0549e-04\n",
      "step 941, train_loss 9.3568e-05, test_loss 1.0043e-04\n",
      "step 942, train_loss 8.8242e-05, test_loss 9.0340e-05\n",
      "step 943, train_loss 7.7975e-05, test_loss 8.8242e-05\n",
      "step 944, train_loss 7.6342e-05, test_loss 9.6106e-05\n",
      "step 945, train_loss 8.3304e-05, test_loss 9.9584e-05\n",
      "step 946, train_loss 8.8066e-05, test_loss 9.7807e-05\n",
      "step 947, train_loss 8.5037e-05, test_loss 9.1544e-05\n",
      "step 948, train_loss 8.0125e-05, test_loss 9.3519e-05\n",
      "step 949, train_loss 8.1022e-05, test_loss 9.8936e-05\n",
      "step 950, train_loss 8.7554e-05, test_loss 1.0631e-04\n",
      "step 951, train_loss 9.3773e-05, test_loss 1.0830e-04\n",
      "step 952, train_loss 9.7164e-05, test_loss 1.1505e-04\n",
      "step 953, train_loss 1.0189e-04, test_loss 1.2447e-04\n",
      "step 954, train_loss 1.1389e-04, test_loss 1.4934e-04\n",
      "step 955, train_loss 1.3533e-04, test_loss 1.7565e-04\n",
      "step 956, train_loss 1.6593e-04, test_loss 2.2293e-04\n",
      "step 957, train_loss 2.0814e-04, test_loss 2.7785e-04\n",
      "step 958, train_loss 2.6931e-04, test_loss 3.7465e-04\n",
      "step 959, train_loss 3.5906e-04, test_loss 4.8801e-04\n",
      "step 960, train_loss 4.8110e-04, test_loss 6.4626e-04\n",
      "step 961, train_loss 6.2962e-04, test_loss 7.7989e-04\n",
      "step 962, train_loss 7.7463e-04, test_loss 8.8497e-04\n",
      "step 963, train_loss 8.6714e-04, test_loss 8.4176e-04\n",
      "step 964, train_loss 8.3630e-04, test_loss 6.7560e-04\n",
      "step 965, train_loss 6.5744e-04, test_loss 3.9369e-04\n",
      "step 966, train_loss 3.8460e-04, test_loss 1.6911e-04\n",
      "step 967, train_loss 1.5356e-04, test_loss 8.6441e-05\n",
      "step 968, train_loss 7.3371e-05, test_loss 1.5882e-04\n",
      "step 969, train_loss 1.4895e-04, test_loss 3.0481e-04\n",
      "step 970, train_loss 2.9048e-04, test_loss 3.8989e-04\n",
      "step 971, train_loss 3.8386e-04, test_loss 3.7817e-04\n",
      "step 972, train_loss 3.6401e-04, test_loss 2.5715e-04\n",
      "step 973, train_loss 2.4935e-04, test_loss 1.3911e-04\n",
      "step 974, train_loss 1.2591e-04, test_loss 8.6164e-05\n",
      "step 975, train_loss 7.3883e-05, test_loss 1.1977e-04\n",
      "step 976, train_loss 1.0875e-04, test_loss 1.9566e-04\n",
      "step 977, train_loss 1.8085e-04, test_loss 2.3274e-04\n",
      "step 978, train_loss 2.2329e-04, test_loss 2.1797e-04\n",
      "step 979, train_loss 2.0338e-04, test_loss 1.5101e-04\n",
      "step 980, train_loss 1.4082e-04, test_loss 9.8193e-05\n",
      "step 981, train_loss 8.5609e-05, test_loss 8.5752e-05\n",
      "step 982, train_loss 7.3798e-05, test_loss 1.1226e-04\n",
      "step 983, train_loss 1.0209e-04, test_loss 1.5083e-04\n",
      "step 984, train_loss 1.3781e-04, test_loss 1.5856e-04\n",
      "step 985, train_loss 1.4925e-04, test_loss 1.4226e-04\n",
      "step 986, train_loss 1.2920e-04, test_loss 1.0630e-04\n",
      "step 987, train_loss 9.5774e-05, test_loss 8.6172e-05\n",
      "step 988, train_loss 7.4017e-05, test_loss 8.7845e-05\n",
      "step 989, train_loss 7.5592e-05, test_loss 1.0365e-04\n",
      "step 990, train_loss 9.2787e-05, test_loss 1.2140e-04\n",
      "step 991, train_loss 1.0828e-04, test_loss 1.2007e-04\n",
      "step 992, train_loss 1.0971e-04, test_loss 1.1021e-04\n",
      "step 993, train_loss 9.7320e-05, test_loss 9.2225e-05\n",
      "step 994, train_loss 8.1253e-05, test_loss 8.4131e-05\n",
      "step 995, train_loss 7.2268e-05, test_loss 8.6142e-05\n",
      "step 996, train_loss 7.4219e-05, test_loss 9.3548e-05\n",
      "step 997, train_loss 8.2792e-05, test_loss 1.0256e-04\n",
      "step 998, train_loss 9.0118e-05, test_loss 1.0125e-04\n",
      "step 999, train_loss 9.0840e-05, test_loss 9.7356e-05\n",
      "step 1000, train_loss 8.5017e-05, test_loss 8.8129e-05\n",
      "step 1001, train_loss 7.7137e-05, test_loss 8.3942e-05\n",
      "step 1002, train_loss 7.2133e-05, test_loss 8.4080e-05\n",
      "step 1003, train_loss 7.2199e-05, test_loss 8.7134e-05\n",
      "step 1004, train_loss 7.5901e-05, test_loss 9.2262e-05\n",
      "step 1005, train_loss 7.9855e-05, test_loss 9.2296e-05\n",
      "step 1006, train_loss 8.1314e-05, test_loss 9.1898e-05\n",
      "step 1007, train_loss 7.9574e-05, test_loss 8.7190e-05\n",
      "step 1008, train_loss 7.6055e-05, test_loss 8.4669e-05\n",
      "step 1009, train_loss 7.2863e-05, test_loss 8.3027e-05\n",
      "step 1010, train_loss 7.1532e-05, test_loss 8.3491e-05\n",
      "step 1011, train_loss 7.2235e-05, test_loss 8.5857e-05\n",
      "step 1012, train_loss 7.4024e-05, test_loss 8.6639e-05\n",
      "step 1013, train_loss 7.5616e-05, test_loss 8.8094e-05\n",
      "step 1014, train_loss 7.6076e-05, test_loss 8.6464e-05\n",
      "step 1015, train_loss 7.5296e-05, test_loss 8.5757e-05\n",
      "step 1016, train_loss 7.3775e-05, test_loss 8.3813e-05\n",
      "step 1017, train_loss 7.2330e-05, test_loss 8.3280e-05\n",
      "step 1018, train_loss 7.1545e-05, test_loss 8.3325e-05\n",
      "step 1019, train_loss 7.1596e-05, test_loss 8.3640e-05\n",
      "step 1020, train_loss 7.2231e-05, test_loss 8.4802e-05\n",
      "step 1021, train_loss 7.2984e-05, test_loss 8.4653e-05\n",
      "step 1022, train_loss 7.3462e-05, test_loss 8.5259e-05\n",
      "step 1023, train_loss 7.3457e-05, test_loss 8.4246e-05\n",
      "step 1024, train_loss 7.3047e-05, test_loss 8.4168e-05\n",
      "step 1025, train_loss 7.2426e-05, test_loss 8.3250e-05\n",
      "step 1026, train_loss 7.1861e-05, test_loss 8.3161e-05\n",
      "step 1027, train_loss 7.1511e-05, test_loss 8.3062e-05\n",
      "step 1028, train_loss 7.1443e-05, test_loss 8.3126e-05\n",
      "step 1029, train_loss 7.1601e-05, test_loss 8.3625e-05\n",
      "step 1030, train_loss 7.1864e-05, test_loss 8.3512e-05\n",
      "step 1031, train_loss 7.2116e-05, test_loss 8.4032e-05\n",
      "step 1032, train_loss 7.2251e-05, test_loss 8.3574e-05\n",
      "step 1033, train_loss 7.2249e-05, test_loss 8.3837e-05\n",
      "step 1034, train_loss 7.2112e-05, test_loss 8.3256e-05\n",
      "step 1035, train_loss 7.1909e-05, test_loss 8.3335e-05\n",
      "step 1036, train_loss 7.1689e-05, test_loss 8.2954e-05\n",
      "step 1037, train_loss 7.1513e-05, test_loss 8.2978e-05\n",
      "step 1038, train_loss 7.1403e-05, test_loss 8.2921e-05\n",
      "step 1039, train_loss 7.1368e-05, test_loss 8.2903e-05\n",
      "step 1040, train_loss 7.1393e-05, test_loss 8.3083e-05\n",
      "step 1041, train_loss 7.1452e-05, test_loss 8.2982e-05\n",
      "step 1042, train_loss 7.1527e-05, test_loss 8.3252e-05\n",
      "step 1043, train_loss 7.1589e-05, test_loss 8.3050e-05\n",
      "step 1044, train_loss 7.1634e-05, test_loss 8.3308e-05\n",
      "step 1045, train_loss 7.1648e-05, test_loss 8.3037e-05\n",
      "step 1046, train_loss 7.1639e-05, test_loss 8.3246e-05\n",
      "step 1047, train_loss 7.1603e-05, test_loss 8.2961e-05\n",
      "step 1048, train_loss 7.1558e-05, test_loss 8.3121e-05\n",
      "step 1049, train_loss 7.1502e-05, test_loss 8.2870e-05\n",
      "step 1050, train_loss 7.1448e-05, test_loss 8.2990e-05\n",
      "step 1051, train_loss 7.1395e-05, test_loss 8.2800e-05\n",
      "step 1052, train_loss 7.1352e-05, test_loss 8.2884e-05\n",
      "step 1053, train_loss 7.1314e-05, test_loss 8.2760e-05\n",
      "step 1054, train_loss 7.1285e-05, test_loss 8.2806e-05\n",
      "step 1055, train_loss 7.1261e-05, test_loss 8.2740e-05\n",
      "step 1056, train_loss 7.1243e-05, test_loss 8.2748e-05\n",
      "step 1057, train_loss 7.1229e-05, test_loss 8.2728e-05\n",
      "step 1058, train_loss 7.1219e-05, test_loss 8.2702e-05\n",
      "step 1059, train_loss 7.1211e-05, test_loss 8.2718e-05\n",
      "step 1060, train_loss 7.1204e-05, test_loss 8.2665e-05\n",
      "step 1061, train_loss 7.1200e-05, test_loss 8.2712e-05\n",
      "step 1062, train_loss 7.1195e-05, test_loss 8.2640e-05\n",
      "step 1063, train_loss 7.1193e-05, test_loss 8.2718e-05\n",
      "step 1064, train_loss 7.1192e-05, test_loss 8.2628e-05\n",
      "step 1065, train_loss 7.1194e-05, test_loss 8.2738e-05\n",
      "step 1066, train_loss 7.1197e-05, test_loss 8.2627e-05\n",
      "step 1067, train_loss 7.1207e-05, test_loss 8.2778e-05\n",
      "step 1068, train_loss 7.1221e-05, test_loss 8.2640e-05\n",
      "step 1069, train_loss 7.1246e-05, test_loss 8.2856e-05\n",
      "step 1070, train_loss 7.1281e-05, test_loss 8.2692e-05\n",
      "step 1071, train_loss 7.1339e-05, test_loss 8.3025e-05\n",
      "step 1072, train_loss 7.1423e-05, test_loss 8.2851e-05\n",
      "step 1073, train_loss 7.1556e-05, test_loss 8.3403e-05\n",
      "step 1074, train_loss 7.1752e-05, test_loss 8.3275e-05\n",
      "step 1075, train_loss 7.2060e-05, test_loss 8.4260e-05\n",
      "step 1076, train_loss 7.2523e-05, test_loss 8.4350e-05\n",
      "step 1077, train_loss 7.3252e-05, test_loss 8.6254e-05\n",
      "step 1078, train_loss 7.4376e-05, test_loss 8.7077e-05\n",
      "step 1079, train_loss 7.6168e-05, test_loss 9.1100e-05\n",
      "step 1080, train_loss 7.8999e-05, test_loss 9.4169e-05\n",
      "step 1081, train_loss 8.3575e-05, test_loss 1.0343e-04\n",
      "step 1082, train_loss 9.0963e-05, test_loss 1.1312e-04\n",
      "step 1083, train_loss 1.0306e-04, test_loss 1.3595e-04\n",
      "step 1084, train_loss 1.2289e-04, test_loss 1.6469e-04\n",
      "step 1085, train_loss 1.5554e-04, test_loss 2.2310e-04\n",
      "step 1086, train_loss 2.0911e-04, test_loss 3.0331e-04\n",
      "step 1087, train_loss 2.9573e-04, test_loss 4.4794e-04\n",
      "step 1088, train_loss 4.3256e-04, test_loss 6.4094e-04\n",
      "step 1089, train_loss 6.3587e-04, test_loss 9.2893e-04\n",
      "step 1090, train_loss 9.1179e-04, test_loss 1.2168e-03\n",
      "step 1091, train_loss 1.2146e-03, test_loss 1.4488e-03\n",
      "step 1092, train_loss 1.4300e-03, test_loss 1.3726e-03\n",
      "step 1093, train_loss 1.3699e-03, test_loss 9.9206e-04\n",
      "step 1094, train_loss 9.7284e-04, test_loss 4.3973e-04\n",
      "step 1095, train_loss 4.3011e-04, test_loss 1.1992e-04\n",
      "step 1096, train_loss 1.0538e-04, test_loss 1.8231e-04\n",
      "step 1097, train_loss 1.6736e-04, test_loss 4.5790e-04\n",
      "step 1098, train_loss 4.5225e-04, test_loss 6.6064e-04\n",
      "step 1099, train_loss 6.4589e-04, test_loss 5.6164e-04\n",
      "step 1100, train_loss 5.5806e-04, test_loss 3.0220e-04\n",
      "step 1101, train_loss 2.8950e-04, test_loss 1.1480e-04\n",
      "step 1102, train_loss 1.0482e-04, test_loss 1.5463e-04\n",
      "step 1103, train_loss 1.4584e-04, test_loss 3.1595e-04\n",
      "step 1104, train_loss 3.0102e-04, test_loss 3.7076e-04\n",
      "step 1105, train_loss 3.6372e-04, test_loss 2.7992e-04\n",
      "step 1106, train_loss 2.6480e-04, test_loss 1.3524e-04\n",
      "step 1107, train_loss 1.2462e-04, test_loss 1.0301e-04\n",
      "step 1108, train_loss 9.1843e-05, test_loss 1.8317e-04\n",
      "step 1109, train_loss 1.6942e-04, test_loss 2.4429e-04\n",
      "step 1110, train_loss 2.3690e-04, test_loss 2.2056e-04\n",
      "step 1111, train_loss 2.0715e-04, test_loss 1.2755e-04\n",
      "step 1112, train_loss 1.1884e-04, test_loss 8.3649e-05\n",
      "step 1113, train_loss 7.3062e-05, test_loss 1.1843e-04\n",
      "step 1114, train_loss 1.0648e-04, test_loss 1.6860e-04\n",
      "step 1115, train_loss 1.6056e-04, test_loss 1.7714e-04\n",
      "step 1116, train_loss 1.6408e-04, test_loss 1.2435e-04\n",
      "step 1117, train_loss 1.1522e-04, test_loss 8.3671e-05\n",
      "step 1118, train_loss 7.2040e-05, test_loss 8.8418e-05\n",
      "step 1119, train_loss 7.6505e-05, test_loss 1.1995e-04\n",
      "step 1120, train_loss 1.1048e-04, test_loss 1.4025e-04\n",
      "step 1121, train_loss 1.2730e-04, test_loss 1.1794e-04\n",
      "step 1122, train_loss 1.0853e-04, test_loss 9.0265e-05\n",
      "step 1123, train_loss 7.8552e-05, test_loss 8.0351e-05\n",
      "step 1124, train_loss 6.9324e-05, test_loss 9.3512e-05\n",
      "step 1125, train_loss 8.3864e-05, test_loss 1.1098e-04\n",
      "step 1126, train_loss 9.9052e-05, test_loss 1.0534e-04\n",
      "step 1127, train_loss 9.6215e-05, test_loss 9.1662e-05\n",
      "step 1128, train_loss 8.0260e-05, test_loss 7.9998e-05\n",
      "step 1129, train_loss 6.9544e-05, test_loss 8.3420e-05\n",
      "step 1130, train_loss 7.3180e-05, test_loss 9.4912e-05\n",
      "step 1131, train_loss 8.3133e-05, test_loss 9.6125e-05\n",
      "step 1132, train_loss 8.6269e-05, test_loss 9.1113e-05\n",
      "step 1133, train_loss 7.9254e-05, test_loss 8.0878e-05\n",
      "step 1134, train_loss 7.0273e-05, test_loss 7.9010e-05\n",
      "step 1135, train_loss 6.8156e-05, test_loss 8.4528e-05\n",
      "step 1136, train_loss 7.3150e-05, test_loss 8.8212e-05\n",
      "step 1137, train_loss 7.8287e-05, test_loss 8.9136e-05\n",
      "step 1138, train_loss 7.7774e-05, test_loss 8.2620e-05\n",
      "step 1139, train_loss 7.2600e-05, test_loss 7.8868e-05\n",
      "step 1140, train_loss 6.8128e-05, test_loss 7.8866e-05\n",
      "step 1141, train_loss 6.8058e-05, test_loss 8.1380e-05\n",
      "step 1142, train_loss 7.1169e-05, test_loss 8.4892e-05\n",
      "step 1143, train_loss 7.3515e-05, test_loss 8.3078e-05\n",
      "step 1144, train_loss 7.2773e-05, test_loss 8.1264e-05\n",
      "step 1145, train_loss 7.0001e-05, test_loss 7.8807e-05\n",
      "step 1146, train_loss 6.7984e-05, test_loss 7.8900e-05\n",
      "step 1147, train_loss 6.8213e-05, test_loss 8.0987e-05\n",
      "step 1148, train_loss 6.9812e-05, test_loss 8.1113e-05\n",
      "step 1149, train_loss 7.0850e-05, test_loss 8.1367e-05\n",
      "step 1150, train_loss 7.0279e-05, test_loss 7.9116e-05\n",
      "step 1151, train_loss 6.8755e-05, test_loss 7.8381e-05\n",
      "step 1152, train_loss 6.7650e-05, test_loss 7.8533e-05\n",
      "step 1153, train_loss 6.7747e-05, test_loss 7.9113e-05\n",
      "step 1154, train_loss 6.8660e-05, test_loss 8.0487e-05\n",
      "step 1155, train_loss 6.9386e-05, test_loss 7.9772e-05\n",
      "step 1156, train_loss 6.9302e-05, test_loss 7.9620e-05\n",
      "step 1157, train_loss 6.8552e-05, test_loss 7.8519e-05\n",
      "step 1158, train_loss 6.7813e-05, test_loss 7.8381e-05\n",
      "step 1159, train_loss 6.7600e-05, test_loss 7.8835e-05\n",
      "step 1160, train_loss 6.7911e-05, test_loss 7.8867e-05\n",
      "step 1161, train_loss 6.8344e-05, test_loss 7.9446e-05\n",
      "step 1162, train_loss 6.8480e-05, test_loss 7.8739e-05\n",
      "step 1163, train_loss 6.8242e-05, test_loss 7.8691e-05\n",
      "step 1164, train_loss 6.7845e-05, test_loss 7.8271e-05\n",
      "step 1165, train_loss 6.7599e-05, test_loss 7.8316e-05\n",
      "step 1166, train_loss 6.7636e-05, test_loss 7.8724e-05\n",
      "step 1167, train_loss 6.7858e-05, test_loss 7.8654e-05\n",
      "step 1168, train_loss 6.8059e-05, test_loss 7.9015e-05\n",
      "step 1169, train_loss 6.8079e-05, test_loss 7.8563e-05\n",
      "step 1170, train_loss 6.7930e-05, test_loss 7.8578e-05\n",
      "step 1171, train_loss 6.7721e-05, test_loss 7.8337e-05\n",
      "step 1172, train_loss 6.7593e-05, test_loss 7.8310e-05\n",
      "step 1173, train_loss 6.7595e-05, test_loss 7.8522e-05\n",
      "step 1174, train_loss 6.7686e-05, test_loss 7.8393e-05\n",
      "step 1175, train_loss 6.7778e-05, test_loss 7.8650e-05\n",
      "step 1176, train_loss 6.7797e-05, test_loss 7.8352e-05\n",
      "step 1177, train_loss 6.7739e-05, test_loss 7.8443e-05\n",
      "step 1178, train_loss 6.7642e-05, test_loss 7.8257e-05\n",
      "step 1179, train_loss 6.7567e-05, test_loss 7.8272e-05\n",
      "step 1180, train_loss 6.7545e-05, test_loss 7.8360e-05\n",
      "step 1181, train_loss 6.7574e-05, test_loss 7.8300e-05\n",
      "step 1182, train_loss 6.7625e-05, test_loss 7.8495e-05\n",
      "step 1183, train_loss 6.7657e-05, test_loss 7.8322e-05\n",
      "step 1184, train_loss 6.7657e-05, test_loss 7.8445e-05\n",
      "step 1185, train_loss 6.7623e-05, test_loss 7.8267e-05\n",
      "step 1186, train_loss 6.7581e-05, test_loss 7.8305e-05\n",
      "step 1187, train_loss 6.7548e-05, test_loss 7.8257e-05\n",
      "step 1188, train_loss 6.7538e-05, test_loss 7.8240e-05\n",
      "step 1189, train_loss 6.7549e-05, test_loss 7.8322e-05\n",
      "step 1190, train_loss 6.7570e-05, test_loss 7.8252e-05\n",
      "step 1191, train_loss 6.7590e-05, test_loss 7.8369e-05\n",
      "step 1192, train_loss 6.7600e-05, test_loss 7.8276e-05\n",
      "step 1193, train_loss 6.7601e-05, test_loss 7.8361e-05\n",
      "step 1194, train_loss 6.7598e-05, test_loss 7.8311e-05\n",
      "step 1195, train_loss 6.7602e-05, test_loss 7.8352e-05\n",
      "step 1196, train_loss 6.7622e-05, test_loss 7.8405e-05\n",
      "step 1197, train_loss 6.7666e-05, test_loss 7.8428e-05\n",
      "step 1198, train_loss 6.7743e-05, test_loss 7.8618e-05\n",
      "step 1199, train_loss 6.7862e-05, test_loss 7.8690e-05\n",
      "step 1200, train_loss 6.8045e-05, test_loss 7.9083e-05\n",
      "step 1201, train_loss 6.8320e-05, test_loss 7.9374e-05\n",
      "step 1202, train_loss 6.8749e-05, test_loss 8.0198e-05\n",
      "step 1203, train_loss 6.9426e-05, test_loss 8.1133e-05\n",
      "step 1204, train_loss 7.0516e-05, test_loss 8.3064e-05\n",
      "step 1205, train_loss 7.2282e-05, test_loss 8.5777e-05\n",
      "step 1206, train_loss 7.5177e-05, test_loss 9.0756e-05\n",
      "step 1207, train_loss 7.9956e-05, test_loss 9.8460e-05\n",
      "step 1208, train_loss 8.7913e-05, test_loss 1.1207e-04\n",
      "step 1209, train_loss 1.0124e-04, test_loss 1.3409e-04\n",
      "step 1210, train_loss 1.2367e-04, test_loss 1.7229e-04\n",
      "step 1211, train_loss 1.6141e-04, test_loss 2.3470e-04\n",
      "step 1212, train_loss 2.2453e-04, test_loss 3.3913e-04\n",
      "step 1213, train_loss 3.2821e-04, test_loss 5.0169e-04\n",
      "step 1214, train_loss 4.9200e-04, test_loss 7.4332e-04\n",
      "step 1215, train_loss 7.3243e-04, test_loss 1.0470e-03\n",
      "step 1216, train_loss 1.0380e-03, test_loss 1.3381e-03\n",
      "step 1217, train_loss 1.3272e-03, test_loss 1.4332e-03\n",
      "step 1218, train_loss 1.4239e-03, test_loss 1.1763e-03\n",
      "step 1219, train_loss 1.1645e-03, test_loss 6.3773e-04\n",
      "step 1220, train_loss 6.2570e-04, test_loss 1.8247e-04\n",
      "step 1221, train_loss 1.7040e-04, test_loss 1.1759e-04\n",
      "step 1222, train_loss 1.0473e-04, test_loss 3.7688e-04\n",
      "step 1223, train_loss 3.6787e-04, test_loss 6.3785e-04\n",
      "step 1224, train_loss 6.2767e-04, test_loss 6.1318e-04\n",
      "step 1225, train_loss 6.0535e-04, test_loss 3.4259e-04\n",
      "step 1226, train_loss 3.3332e-04, test_loss 1.1450e-04\n",
      "step 1227, train_loss 1.0382e-04, test_loss 1.3441e-04\n",
      "step 1228, train_loss 1.2529e-04, test_loss 3.1281e-04\n",
      "step 1229, train_loss 3.0065e-04, test_loss 3.9133e-04\n",
      "step 1230, train_loss 3.8219e-04, test_loss 2.8246e-04\n",
      "step 1231, train_loss 2.7072e-04, test_loss 1.1970e-04\n",
      "step 1232, train_loss 1.0881e-04, test_loss 8.8547e-05\n",
      "step 1233, train_loss 7.8610e-05, test_loss 1.8868e-04\n",
      "step 1234, train_loss 1.7718e-04, test_loss 2.5984e-04\n",
      "step 1235, train_loss 2.5159e-04, test_loss 2.1601e-04\n",
      "step 1236, train_loss 2.0505e-04, test_loss 1.1156e-04\n",
      "step 1237, train_loss 1.0231e-04, test_loss 7.5721e-05\n",
      "step 1238, train_loss 6.5731e-05, test_loss 1.2788e-04\n",
      "step 1239, train_loss 1.1713e-04, test_loss 1.7893e-04\n",
      "step 1240, train_loss 1.6996e-04, test_loss 1.6450e-04\n",
      "step 1241, train_loss 1.5337e-04, test_loss 1.0356e-04\n",
      "step 1242, train_loss 9.4141e-05, test_loss 7.6633e-05\n",
      "step 1243, train_loss 6.6123e-05, test_loss 1.0177e-04\n",
      "step 1244, train_loss 9.1486e-05, test_loss 1.3367e-04\n",
      "step 1245, train_loss 1.2408e-04, test_loss 1.2921e-04\n",
      "step 1246, train_loss 1.1856e-04, test_loss 9.4385e-05\n",
      "step 1247, train_loss 8.4701e-05, test_loss 7.5571e-05\n",
      "step 1248, train_loss 6.5109e-05, test_loss 8.7770e-05\n",
      "step 1249, train_loss 7.7622e-05, test_loss 1.0852e-04\n",
      "step 1250, train_loss 9.8626e-05, test_loss 1.0925e-04\n",
      "step 1251, train_loss 9.9067e-05, test_loss 8.9550e-05\n",
      "step 1252, train_loss 7.9773e-05, test_loss 7.4695e-05\n",
      "step 1253, train_loss 6.4788e-05, test_loss 7.8773e-05\n",
      "step 1254, train_loss 6.8760e-05, test_loss 9.1512e-05\n",
      "step 1255, train_loss 8.1815e-05, test_loss 9.5982e-05\n",
      "step 1256, train_loss 8.5818e-05, test_loss 8.6726e-05\n",
      "step 1257, train_loss 7.6717e-05, test_loss 7.6378e-05\n",
      "step 1258, train_loss 6.6268e-05, test_loss 7.5925e-05\n",
      "step 1259, train_loss 6.5488e-05, test_loss 8.2247e-05\n",
      "step 1260, train_loss 7.2393e-05, test_loss 8.7253e-05\n",
      "step 1261, train_loss 7.6851e-05, test_loss 8.3280e-05\n",
      "step 1262, train_loss 7.3529e-05, test_loss 7.6812e-05\n",
      "step 1263, train_loss 6.6820e-05, test_loss 7.4009e-05\n",
      "step 1264, train_loss 6.4083e-05, test_loss 7.6641e-05\n",
      "step 1265, train_loss 6.7022e-05, test_loss 8.1134e-05\n",
      "step 1266, train_loss 7.0966e-05, test_loss 8.0791e-05\n",
      "step 1267, train_loss 7.1136e-05, test_loss 7.7973e-05\n",
      "step 1268, train_loss 6.7687e-05, test_loss 7.4561e-05\n",
      "step 1269, train_loss 6.4559e-05, test_loss 7.4760e-05\n",
      "step 1270, train_loss 6.4586e-05, test_loss 7.7052e-05\n",
      "step 1271, train_loss 6.6822e-05, test_loss 7.8232e-05\n",
      "step 1272, train_loss 6.8286e-05, test_loss 7.7580e-05\n",
      "step 1273, train_loss 6.7409e-05, test_loss 7.5159e-05\n",
      "step 1274, train_loss 6.5325e-05, test_loss 7.4158e-05\n",
      "step 1275, train_loss 6.4170e-05, test_loss 7.4653e-05\n",
      "step 1276, train_loss 6.4764e-05, test_loss 7.5978e-05\n",
      "step 1277, train_loss 6.6069e-05, test_loss 7.6589e-05\n",
      "step 1278, train_loss 6.6576e-05, test_loss 7.5847e-05\n",
      "step 1279, train_loss 6.5841e-05, test_loss 7.4764e-05\n",
      "step 1280, train_loss 6.4690e-05, test_loss 7.4314e-05\n",
      "step 1281, train_loss 6.4179e-05, test_loss 7.4592e-05\n",
      "step 1282, train_loss 6.4569e-05, test_loss 7.5396e-05\n",
      "step 1283, train_loss 6.5251e-05, test_loss 7.5438e-05\n",
      "step 1284, train_loss 6.5486e-05, test_loss 7.5139e-05\n",
      "step 1285, train_loss 6.5091e-05, test_loss 7.4455e-05\n",
      "step 1286, train_loss 6.4490e-05, test_loss 7.4156e-05\n",
      "step 1287, train_loss 6.4210e-05, test_loss 7.4449e-05\n",
      "step 1288, train_loss 6.4399e-05, test_loss 7.4694e-05\n",
      "step 1289, train_loss 6.4779e-05, test_loss 7.5094e-05\n",
      "step 1290, train_loss 6.4967e-05, test_loss 7.4774e-05\n",
      "step 1291, train_loss 6.4823e-05, test_loss 7.4636e-05\n",
      "step 1292, train_loss 6.4507e-05, test_loss 7.4293e-05\n",
      "step 1293, train_loss 6.4292e-05, test_loss 7.4379e-05\n",
      "step 1294, train_loss 6.4310e-05, test_loss 7.4515e-05\n",
      "step 1295, train_loss 6.4487e-05, test_loss 7.4650e-05\n",
      "step 1296, train_loss 6.4635e-05, test_loss 7.4662e-05\n",
      "step 1297, train_loss 6.4632e-05, test_loss 7.4507e-05\n",
      "step 1298, train_loss 6.4495e-05, test_loss 7.4361e-05\n",
      "step 1299, train_loss 6.4342e-05, test_loss 7.4324e-05\n",
      "step 1300, train_loss 6.4281e-05, test_loss 7.4332e-05\n",
      "step 1301, train_loss 6.4330e-05, test_loss 7.4492e-05\n",
      "step 1302, train_loss 6.4425e-05, test_loss 7.4478e-05\n",
      "step 1303, train_loss 6.4485e-05, test_loss 7.4531e-05\n",
      "step 1304, train_loss 6.4469e-05, test_loss 7.4400e-05\n",
      "step 1305, train_loss 6.4398e-05, test_loss 7.4371e-05\n",
      "step 1306, train_loss 6.4328e-05, test_loss 7.4328e-05\n",
      "step 1307, train_loss 6.4302e-05, test_loss 7.4350e-05\n",
      "step 1308, train_loss 6.4326e-05, test_loss 7.4420e-05\n",
      "step 1309, train_loss 6.4372e-05, test_loss 7.4417e-05\n",
      "step 1310, train_loss 6.4404e-05, test_loss 7.4453e-05\n",
      "step 1311, train_loss 6.4402e-05, test_loss 7.4382e-05\n",
      "step 1312, train_loss 6.4373e-05, test_loss 7.4371e-05\n",
      "step 1313, train_loss 6.4337e-05, test_loss 7.4327e-05\n",
      "step 1314, train_loss 6.4315e-05, test_loss 7.4334e-05\n",
      "step 1315, train_loss 6.4316e-05, test_loss 7.4355e-05\n",
      "step 1316, train_loss 6.4334e-05, test_loss 7.4368e-05\n",
      "step 1317, train_loss 6.4354e-05, test_loss 7.4394e-05\n",
      "step 1318, train_loss 6.4363e-05, test_loss 7.4382e-05\n",
      "step 1319, train_loss 6.4358e-05, test_loss 7.4372e-05\n",
      "step 1320, train_loss 6.4343e-05, test_loss 7.4361e-05\n",
      "step 1321, train_loss 6.4327e-05, test_loss 7.4328e-05\n",
      "step 1322, train_loss 6.4318e-05, test_loss 7.4357e-05\n",
      "step 1323, train_loss 6.4317e-05, test_loss 7.4310e-05\n",
      "step 1324, train_loss 6.4326e-05, test_loss 7.4384e-05\n",
      "step 1325, train_loss 6.4337e-05, test_loss 7.4311e-05\n",
      "step 1326, train_loss 6.4349e-05, test_loss 7.4426e-05\n",
      "step 1327, train_loss 6.4361e-05, test_loss 7.4321e-05\n",
      "step 1328, train_loss 6.4378e-05, test_loss 7.4501e-05\n",
      "step 1329, train_loss 6.4406e-05, test_loss 7.4374e-05\n",
      "step 1330, train_loss 6.4462e-05, test_loss 7.4703e-05\n",
      "step 1331, train_loss 6.4561e-05, test_loss 7.4590e-05\n",
      "step 1332, train_loss 6.4741e-05, test_loss 7.5269e-05\n",
      "step 1333, train_loss 6.5050e-05, test_loss 7.5324e-05\n",
      "step 1334, train_loss 6.5597e-05, test_loss 7.6906e-05\n",
      "step 1335, train_loss 6.6546e-05, test_loss 7.7748e-05\n",
      "step 1336, train_loss 6.8239e-05, test_loss 8.1878e-05\n",
      "step 1337, train_loss 7.1250e-05, test_loss 8.5814e-05\n",
      "step 1338, train_loss 7.6696e-05, test_loss 9.7685e-05\n",
      "step 1339, train_loss 8.6567e-05, test_loss 1.1301e-04\n",
      "step 1340, train_loss 1.0463e-04, test_loss 1.4972e-04\n",
      "step 1341, train_loss 1.3773e-04, test_loss 2.0533e-04\n",
      "step 1342, train_loss 1.9839e-04, test_loss 3.2224e-04\n",
      "step 1343, train_loss 3.0877e-04, test_loss 5.0864e-04\n",
      "step 1344, train_loss 5.0447e-04, test_loss 8.5219e-04\n",
      "step 1345, train_loss 8.3651e-04, test_loss 1.3402e-03\n",
      "step 1346, train_loss 1.3408e-03, test_loss 1.9883e-03\n",
      "step 1347, train_loss 1.9701e-03, test_loss 2.4198e-03\n",
      "step 1348, train_loss 2.4241e-03, test_loss 2.2668e-03\n",
      "step 1349, train_loss 2.2463e-03, test_loss 1.2961e-03\n",
      "step 1350, train_loss 1.2922e-03, test_loss 3.2733e-04\n",
      "step 1351, train_loss 3.0966e-04, test_loss 1.6607e-04\n",
      "step 1352, train_loss 1.5045e-04, test_loss 7.2499e-04\n",
      "step 1353, train_loss 7.2133e-04, test_loss 1.1748e-03\n",
      "step 1354, train_loss 1.1593e-03, test_loss 8.7852e-04\n",
      "step 1355, train_loss 8.7898e-04, test_loss 2.9108e-04\n",
      "step 1356, train_loss 2.8039e-04, test_loss 1.4206e-04\n",
      "step 1357, train_loss 1.3249e-04, test_loss 4.7999e-04\n",
      "step 1358, train_loss 4.7735e-04, test_loss 6.9155e-04\n",
      "step 1359, train_loss 6.7697e-04, test_loss 4.1649e-04\n",
      "step 1360, train_loss 4.1149e-04, test_loss 1.2045e-04\n",
      "step 1361, train_loss 1.0826e-04, test_loss 2.0139e-04\n",
      "step 1362, train_loss 1.8779e-04, test_loss 4.2580e-04\n",
      "step 1363, train_loss 4.2031e-04, test_loss 3.9580e-04\n",
      "step 1364, train_loss 3.8145e-04, test_loss 1.4748e-04\n",
      "step 1365, train_loss 1.3999e-04, test_loss 8.7359e-05\n",
      "step 1366, train_loss 7.8887e-05, test_loss 2.4894e-04\n",
      "step 1367, train_loss 2.3712e-04, test_loss 3.0854e-04\n",
      "step 1368, train_loss 3.0430e-04, test_loss 1.8006e-04\n",
      "step 1369, train_loss 1.6898e-04, test_loss 6.9657e-05\n",
      "step 1370, train_loss 6.0973e-05, test_loss 1.3445e-04\n",
      "step 1371, train_loss 1.2761e-04, test_loss 2.2588e-04\n",
      "step 1372, train_loss 2.1378e-04, test_loss 1.7201e-04\n",
      "step 1373, train_loss 1.6524e-04, test_loss 8.4541e-05\n",
      "step 1374, train_loss 7.4125e-05, test_loss 9.4016e-05\n",
      "step 1375, train_loss 8.3161e-05, test_loss 1.5378e-04\n",
      "step 1376, train_loss 1.4667e-04, test_loss 1.5332e-04\n",
      "step 1377, train_loss 1.4164e-04, test_loss 8.9396e-05\n",
      "step 1378, train_loss 8.1114e-05, test_loss 7.5502e-05\n",
      "step 1379, train_loss 6.6780e-05, test_loss 1.1747e-04\n",
      "step 1380, train_loss 1.0681e-04, test_loss 1.2687e-04\n",
      "step 1381, train_loss 1.2007e-04, test_loss 9.3900e-05\n",
      "step 1382, train_loss 8.3868e-05, test_loss 6.8779e-05\n",
      "step 1383, train_loss 5.9955e-05, test_loss 8.7820e-05\n",
      "step 1384, train_loss 8.0082e-05, test_loss 1.1120e-04\n",
      "step 1385, train_loss 1.0066e-04, test_loss 9.3631e-05\n",
      "step 1386, train_loss 8.5757e-05, test_loss 7.1921e-05\n",
      "step 1387, train_loss 6.2193e-05, test_loss 7.5460e-05\n",
      "step 1388, train_loss 6.5405e-05, test_loss 9.0683e-05\n",
      "step 1389, train_loss 8.2458e-05, test_loss 9.2431e-05\n",
      "step 1390, train_loss 8.1887e-05, test_loss 7.4869e-05\n",
      "step 1391, train_loss 6.6197e-05, test_loss 6.9893e-05\n",
      "step 1392, train_loss 6.0957e-05, test_loss 8.0292e-05\n",
      "step 1393, train_loss 7.0516e-05, test_loss 8.3411e-05\n",
      "step 1394, train_loss 7.5575e-05, test_loss 7.7248e-05\n",
      "step 1395, train_loss 6.7691e-05, test_loss 6.8992e-05\n",
      "step 1396, train_loss 6.0202e-05, test_loss 7.2105e-05\n",
      "step 1397, train_loss 6.3541e-05, test_loss 7.9752e-05\n",
      "step 1398, train_loss 6.9824e-05, test_loss 7.6763e-05\n",
      "step 1399, train_loss 6.8206e-05, test_loss 7.1447e-05\n",
      "step 1400, train_loss 6.1737e-05, test_loss 6.9726e-05\n",
      "step 1401, train_loss 6.0192e-05, test_loss 7.3088e-05\n",
      "step 1402, train_loss 6.4287e-05, test_loss 7.6279e-05\n",
      "step 1403, train_loss 6.6413e-05, test_loss 7.2105e-05\n",
      "step 1404, train_loss 6.3427e-05, test_loss 6.9421e-05\n",
      "step 1405, train_loss 6.0269e-05, test_loss 7.0423e-05\n",
      "step 1406, train_loss 6.1148e-05, test_loss 7.2131e-05\n",
      "step 1407, train_loss 6.3611e-05, test_loss 7.2971e-05\n",
      "step 1408, train_loss 6.3448e-05, test_loss 7.0000e-05\n",
      "step 1409, train_loss 6.1130e-05, test_loss 6.9349e-05\n",
      "step 1410, train_loss 6.0174e-05, test_loss 7.1091e-05\n",
      "step 1411, train_loss 6.1526e-05, test_loss 7.1596e-05\n",
      "step 1412, train_loss 6.2692e-05, test_loss 7.1532e-05\n",
      "step 1413, train_loss 6.1893e-05, test_loss 6.9584e-05\n",
      "step 1414, train_loss 6.0438e-05, test_loss 6.9444e-05\n",
      "step 1415, train_loss 6.0302e-05, test_loss 7.0758e-05\n",
      "step 1416, train_loss 6.1299e-05, test_loss 7.0612e-05\n",
      "step 1417, train_loss 6.1769e-05, test_loss 7.0478e-05\n",
      "step 1418, train_loss 6.1103e-05, test_loss 6.9448e-05\n",
      "step 1419, train_loss 6.0360e-05, test_loss 6.9551e-05\n",
      "step 1420, train_loss 6.0486e-05, test_loss 7.0510e-05\n",
      "step 1421, train_loss 6.1082e-05, test_loss 7.0206e-05\n",
      "step 1422, train_loss 6.1211e-05, test_loss 7.0168e-05\n",
      "step 1423, train_loss 6.0743e-05, test_loss 6.9624e-05\n",
      "step 1424, train_loss 6.0377e-05, test_loss 6.9731e-05\n",
      "step 1425, train_loss 6.0550e-05, test_loss 7.0378e-05\n",
      "step 1426, train_loss 6.0923e-05, test_loss 7.0045e-05\n",
      "step 1427, train_loss 6.0967e-05, test_loss 7.0039e-05\n",
      "step 1428, train_loss 6.0668e-05, test_loss 6.9671e-05\n",
      "step 1429, train_loss 6.0452e-05, test_loss 6.9705e-05\n",
      "step 1430, train_loss 6.0556e-05, test_loss 7.0142e-05\n",
      "step 1431, train_loss 6.0776e-05, test_loss 6.9897e-05\n",
      "step 1432, train_loss 6.0813e-05, test_loss 6.9988e-05\n",
      "step 1433, train_loss 6.0655e-05, test_loss 6.9770e-05\n",
      "step 1434, train_loss 6.0538e-05, test_loss 6.9808e-05\n",
      "step 1435, train_loss 6.0602e-05, test_loss 7.0121e-05\n",
      "step 1436, train_loss 6.0738e-05, test_loss 6.9947e-05\n",
      "step 1437, train_loss 6.0775e-05, test_loss 7.0058e-05\n",
      "step 1438, train_loss 6.0686e-05, test_loss 6.9870e-05\n",
      "step 1439, train_loss 6.0605e-05, test_loss 6.9874e-05\n",
      "step 1440, train_loss 6.0626e-05, test_loss 7.0060e-05\n",
      "step 1441, train_loss 6.0710e-05, test_loss 6.9930e-05\n",
      "step 1442, train_loss 6.0754e-05, test_loss 7.0050e-05\n",
      "step 1443, train_loss 6.0721e-05, test_loss 6.9897e-05\n",
      "step 1444, train_loss 6.0672e-05, test_loss 6.9916e-05\n",
      "step 1445, train_loss 6.0672e-05, test_loss 7.0037e-05\n",
      "step 1446, train_loss 6.0719e-05, test_loss 6.9970e-05\n",
      "step 1447, train_loss 6.0760e-05, test_loss 7.0106e-05\n",
      "step 1448, train_loss 6.0757e-05, test_loss 6.9988e-05\n",
      "step 1449, train_loss 6.0729e-05, test_loss 7.0019e-05\n",
      "step 1450, train_loss 6.0716e-05, test_loss 7.0062e-05\n",
      "step 1451, train_loss 6.0737e-05, test_loss 7.0012e-05\n",
      "step 1452, train_loss 6.0768e-05, test_loss 7.0115e-05\n",
      "step 1453, train_loss 6.0780e-05, test_loss 7.0009e-05\n",
      "step 1454, train_loss 6.0771e-05, test_loss 7.0047e-05\n",
      "step 1455, train_loss 6.0759e-05, test_loss 7.0043e-05\n",
      "step 1456, train_loss 6.0763e-05, test_loss 7.0028e-05\n",
      "step 1457, train_loss 6.0782e-05, test_loss 7.0117e-05\n",
      "step 1458, train_loss 6.0798e-05, test_loss 7.0054e-05\n",
      "step 1459, train_loss 6.0803e-05, test_loss 7.0114e-05\n",
      "step 1460, train_loss 6.0797e-05, test_loss 7.0084e-05\n",
      "step 1461, train_loss 6.0794e-05, test_loss 7.0085e-05\n",
      "step 1462, train_loss 6.0800e-05, test_loss 7.0129e-05\n",
      "step 1463, train_loss 6.0811e-05, test_loss 7.0079e-05\n",
      "step 1464, train_loss 6.0819e-05, test_loss 7.0130e-05\n",
      "step 1465, train_loss 6.0820e-05, test_loss 7.0081e-05\n",
      "step 1466, train_loss 6.0817e-05, test_loss 7.0099e-05\n",
      "step 1467, train_loss 6.0816e-05, test_loss 7.0109e-05\n",
      "step 1468, train_loss 6.0821e-05, test_loss 7.0091e-05\n",
      "step 1469, train_loss 6.0828e-05, test_loss 7.0139e-05\n",
      "step 1470, train_loss 6.0833e-05, test_loss 7.0101e-05\n",
      "step 1471, train_loss 6.0834e-05, test_loss 7.0134e-05\n",
      "step 1472, train_loss 6.0833e-05, test_loss 7.0117e-05\n",
      "step 1473, train_loss 6.0833e-05, test_loss 7.0116e-05\n",
      "step 1474, train_loss 6.0835e-05, test_loss 7.0135e-05\n",
      "step 1475, train_loss 6.0838e-05, test_loss 7.0107e-05\n",
      "step 1476, train_loss 6.0841e-05, test_loss 7.0136e-05\n",
      "step 1477, train_loss 6.0841e-05, test_loss 7.0107e-05\n",
      "step 1478, train_loss 6.0840e-05, test_loss 7.0120e-05\n",
      "step 1479, train_loss 6.0839e-05, test_loss 7.0118e-05\n",
      "step 1480, train_loss 6.0839e-05, test_loss 7.0109e-05\n",
      "step 1481, train_loss 6.0840e-05, test_loss 7.0129e-05\n",
      "step 1482, train_loss 6.0841e-05, test_loss 7.0106e-05\n",
      "step 1483, train_loss 6.0842e-05, test_loss 7.0127e-05\n",
      "step 1484, train_loss 6.0841e-05, test_loss 7.0109e-05\n",
      "step 1485, train_loss 6.0841e-05, test_loss 7.0116e-05\n",
      "step 1486, train_loss 6.0841e-05, test_loss 7.0117e-05\n",
      "step 1487, train_loss 6.0841e-05, test_loss 7.0109e-05\n",
      "step 1488, train_loss 6.0844e-05, test_loss 7.0124e-05\n",
      "step 1489, train_loss 6.0847e-05, test_loss 7.0113e-05\n",
      "step 1490, train_loss 6.0853e-05, test_loss 7.0133e-05\n",
      "step 1491, train_loss 6.0862e-05, test_loss 7.0138e-05\n",
      "step 1492, train_loss 6.0877e-05, test_loss 7.0163e-05\n",
      "step 1493, train_loss 6.0900e-05, test_loss 7.0206e-05\n",
      "step 1494, train_loss 6.0940e-05, test_loss 7.0257e-05\n",
      "step 1495, train_loss 6.1003e-05, test_loss 7.0374e-05\n",
      "step 1496, train_loss 6.1106e-05, test_loss 7.0520e-05\n",
      "step 1497, train_loss 6.1271e-05, test_loss 7.0811e-05\n",
      "step 1498, train_loss 6.1544e-05, test_loss 7.1238e-05\n",
      "step 1499, train_loss 6.1992e-05, test_loss 7.2005e-05\n",
      "step 1500, train_loss 6.2742e-05, test_loss 7.3237e-05\n",
      "step 1501, train_loss 6.3997e-05, test_loss 7.5391e-05\n",
      "step 1502, train_loss 6.6133e-05, test_loss 7.9003e-05\n",
      "step 1503, train_loss 6.9777e-05, test_loss 8.5327e-05\n",
      "step 1504, train_loss 7.6073e-05, test_loss 9.6186e-05\n",
      "step 1505, train_loss 8.6994e-05, test_loss 1.1534e-04\n",
      "step 1506, train_loss 1.0609e-04, test_loss 1.4863e-04\n",
      "step 1507, train_loss 1.3952e-04, test_loss 2.0717e-04\n",
      "step 1508, train_loss 1.9797e-04, test_loss 3.0790e-04\n",
      "step 1509, train_loss 2.9899e-04, test_loss 4.7813e-04\n",
      "step 1510, train_loss 4.6913e-04, test_loss 7.4878e-04\n",
      "step 1511, train_loss 7.4033e-04, test_loss 1.1374e-03\n",
      "step 1512, train_loss 1.1289e-03, test_loss 1.5852e-03\n",
      "step 1513, train_loss 1.5773e-03, test_loss 1.8873e-03\n",
      "step 1514, train_loss 1.8789e-03, test_loss 1.7367e-03\n",
      "step 1515, train_loss 1.7275e-03, test_loss 1.0632e-03\n",
      "step 1516, train_loss 1.0528e-03, test_loss 3.2007e-04\n",
      "step 1517, train_loss 3.0789e-04, test_loss 8.6940e-05\n",
      "step 1518, train_loss 7.6520e-05, test_loss 4.2203e-04\n",
      "step 1519, train_loss 4.1211e-04, test_loss 8.2972e-04\n",
      "step 1520, train_loss 8.2272e-04, test_loss 8.2437e-04\n",
      "step 1521, train_loss 8.1784e-04, test_loss 4.2369e-04\n",
      "step 1522, train_loss 4.1577e-04, test_loss 1.0178e-04\n",
      "step 1523, train_loss 9.4494e-05, test_loss 1.8083e-04\n",
      "step 1524, train_loss 1.7097e-04, test_loss 4.4047e-04\n",
      "step 1525, train_loss 4.3248e-04, test_loss 4.9229e-04\n",
      "step 1526, train_loss 4.8280e-04, test_loss 2.7450e-04\n",
      "step 1527, train_loss 2.6452e-04, test_loss 9.2169e-05\n",
      "step 1528, train_loss 8.3395e-05, test_loss 1.5504e-04\n",
      "step 1529, train_loss 1.4454e-04, test_loss 3.0165e-04\n",
      "step 1530, train_loss 2.9423e-04, test_loss 2.9971e-04\n",
      "step 1531, train_loss 2.9096e-04, test_loss 1.5506e-04\n",
      "step 1532, train_loss 1.4671e-04, test_loss 7.5535e-05\n",
      "step 1533, train_loss 6.8043e-05, test_loss 1.4537e-04\n",
      "step 1534, train_loss 1.3590e-04, test_loss 2.2174e-04\n",
      "step 1535, train_loss 2.1463e-04, test_loss 1.8774e-04\n",
      "step 1536, train_loss 1.7854e-04, test_loss 9.4297e-05\n",
      "step 1537, train_loss 8.5634e-05, test_loss 7.3666e-05\n",
      "step 1538, train_loss 6.5528e-05, test_loss 1.3400e-04\n",
      "step 1539, train_loss 1.2436e-04, test_loss 1.6523e-04\n",
      "step 1540, train_loss 1.5779e-04, test_loss 1.2520e-04\n",
      "step 1541, train_loss 1.1593e-04, test_loss 7.1338e-05\n",
      "step 1542, train_loss 6.2892e-05, test_loss 7.5757e-05\n",
      "step 1543, train_loss 6.7528e-05, test_loss 1.1656e-04\n",
      "step 1544, train_loss 1.0726e-04, test_loss 1.2392e-04\n",
      "step 1545, train_loss 1.1628e-04, test_loss 9.2895e-05\n",
      "step 1546, train_loss 8.3766e-05, test_loss 6.6136e-05\n",
      "step 1547, train_loss 5.7925e-05, test_loss 7.6938e-05\n",
      "step 1548, train_loss 6.8754e-05, test_loss 9.9708e-05\n",
      "step 1549, train_loss 9.0932e-05, test_loss 9.7049e-05\n",
      "step 1550, train_loss 8.9345e-05, test_loss 7.7354e-05\n",
      "step 1551, train_loss 6.8460e-05, test_loss 6.6287e-05\n",
      "step 1552, train_loss 5.8019e-05, test_loss 7.6398e-05\n",
      "step 1553, train_loss 6.7822e-05, test_loss 8.7563e-05\n",
      "step 1554, train_loss 7.8673e-05, test_loss 8.2325e-05\n",
      "step 1555, train_loss 7.4002e-05, test_loss 7.0485e-05\n",
      "step 1556, train_loss 6.1547e-05, test_loss 6.6446e-05\n",
      "step 1557, train_loss 5.8110e-05, test_loss 7.3849e-05\n",
      "step 1558, train_loss 6.5405e-05, test_loss 7.9055e-05\n",
      "step 1559, train_loss 7.0691e-05, test_loss 7.4421e-05\n",
      "step 1560, train_loss 6.6293e-05, test_loss 6.7181e-05\n",
      "step 1561, train_loss 5.8753e-05, test_loss 6.5893e-05\n",
      "step 1562, train_loss 5.7600e-05, test_loss 7.1040e-05\n",
      "step 1563, train_loss 6.2520e-05, test_loss 7.4179e-05\n",
      "step 1564, train_loss 6.5598e-05, test_loss 7.1381e-05\n",
      "step 1565, train_loss 6.2737e-05, test_loss 6.6768e-05\n",
      "step 1566, train_loss 5.8099e-05, test_loss 6.5931e-05\n",
      "step 1567, train_loss 5.7279e-05, test_loss 6.8658e-05\n",
      "step 1568, train_loss 6.0147e-05, test_loss 7.0624e-05\n",
      "step 1569, train_loss 6.2156e-05, test_loss 6.9144e-05\n",
      "step 1570, train_loss 6.0742e-05, test_loss 6.6336e-05\n",
      "step 1571, train_loss 5.8029e-05, test_loss 6.5746e-05\n",
      "step 1572, train_loss 5.7265e-05, test_loss 6.7085e-05\n",
      "step 1573, train_loss 5.8741e-05, test_loss 6.8653e-05\n",
      "step 1574, train_loss 6.0056e-05, test_loss 6.8066e-05\n",
      "step 1575, train_loss 5.9513e-05, test_loss 6.6583e-05\n",
      "step 1576, train_loss 5.7984e-05, test_loss 6.6045e-05\n",
      "step 1577, train_loss 5.7327e-05, test_loss 6.6521e-05\n",
      "step 1578, train_loss 5.8035e-05, test_loss 6.7604e-05\n",
      "step 1579, train_loss 5.8926e-05, test_loss 6.7250e-05\n",
      "step 1580, train_loss 5.8836e-05, test_loss 6.6474e-05\n",
      "step 1581, train_loss 5.7957e-05, test_loss 6.5827e-05\n",
      "step 1582, train_loss 5.7342e-05, test_loss 6.5983e-05\n",
      "step 1583, train_loss 5.7572e-05, test_loss 6.6810e-05\n",
      "step 1584, train_loss 5.8195e-05, test_loss 6.6863e-05\n",
      "step 1585, train_loss 5.8421e-05, test_loss 6.6718e-05\n",
      "step 1586, train_loss 5.8049e-05, test_loss 6.6102e-05\n",
      "step 1587, train_loss 5.7552e-05, test_loss 6.6057e-05\n",
      "step 1588, train_loss 5.7450e-05, test_loss 6.6368e-05\n",
      "step 1589, train_loss 5.7745e-05, test_loss 6.6540e-05\n",
      "step 1590, train_loss 5.8031e-05, test_loss 6.6626e-05\n",
      "step 1591, train_loss 5.8002e-05, test_loss 6.6219e-05\n",
      "step 1592, train_loss 5.7738e-05, test_loss 6.6137e-05\n",
      "step 1593, train_loss 5.7547e-05, test_loss 6.6130e-05\n",
      "step 1594, train_loss 5.7599e-05, test_loss 6.6350e-05\n",
      "step 1595, train_loss 5.7785e-05, test_loss 6.6483e-05\n",
      "step 1596, train_loss 5.7888e-05, test_loss 6.6377e-05\n",
      "step 1597, train_loss 5.7816e-05, test_loss 6.6290e-05\n",
      "step 1598, train_loss 5.7672e-05, test_loss 6.6178e-05\n",
      "step 1599, train_loss 5.7610e-05, test_loss 6.6281e-05\n",
      "step 1600, train_loss 5.7677e-05, test_loss 6.6365e-05\n",
      "step 1601, train_loss 5.7789e-05, test_loss 6.6425e-05\n",
      "step 1602, train_loss 5.7834e-05, test_loss 6.6369e-05\n",
      "step 1603, train_loss 5.7787e-05, test_loss 6.6301e-05\n",
      "step 1604, train_loss 5.7708e-05, test_loss 6.6263e-05\n",
      "step 1605, train_loss 5.7677e-05, test_loss 6.6315e-05\n",
      "step 1606, train_loss 5.7716e-05, test_loss 6.6366e-05\n",
      "step 1607, train_loss 5.7780e-05, test_loss 6.6406e-05\n",
      "step 1608, train_loss 5.7813e-05, test_loss 6.6390e-05\n",
      "step 1609, train_loss 5.7797e-05, test_loss 6.6342e-05\n",
      "step 1610, train_loss 5.7762e-05, test_loss 6.6353e-05\n",
      "step 1611, train_loss 5.7745e-05, test_loss 6.6339e-05\n",
      "step 1612, train_loss 5.7762e-05, test_loss 6.6420e-05\n",
      "step 1613, train_loss 5.7798e-05, test_loss 6.6407e-05\n",
      "step 1614, train_loss 5.7822e-05, test_loss 6.6444e-05\n",
      "step 1615, train_loss 5.7822e-05, test_loss 6.6403e-05\n",
      "step 1616, train_loss 5.7805e-05, test_loss 6.6397e-05\n",
      "step 1617, train_loss 5.7793e-05, test_loss 6.6402e-05\n",
      "step 1618, train_loss 5.7797e-05, test_loss 6.6399e-05\n",
      "step 1619, train_loss 5.7815e-05, test_loss 6.6445e-05\n",
      "step 1620, train_loss 5.7835e-05, test_loss 6.6422e-05\n",
      "step 1621, train_loss 5.7844e-05, test_loss 6.6458e-05\n",
      "step 1622, train_loss 5.7842e-05, test_loss 6.6424e-05\n",
      "step 1623, train_loss 5.7836e-05, test_loss 6.6452e-05\n",
      "step 1624, train_loss 5.7834e-05, test_loss 6.6442e-05\n",
      "step 1625, train_loss 5.7839e-05, test_loss 6.6463e-05\n",
      "step 1626, train_loss 5.7849e-05, test_loss 6.6466e-05\n",
      "step 1627, train_loss 5.7859e-05, test_loss 6.6465e-05\n",
      "step 1628, train_loss 5.7862e-05, test_loss 6.6464e-05\n",
      "step 1629, train_loss 5.7862e-05, test_loss 6.6453e-05\n",
      "step 1630, train_loss 5.7858e-05, test_loss 6.6456e-05\n",
      "step 1631, train_loss 5.7858e-05, test_loss 6.6456e-05\n",
      "step 1632, train_loss 5.7861e-05, test_loss 6.6466e-05\n",
      "step 1633, train_loss 5.7866e-05, test_loss 6.6472e-05\n",
      "step 1634, train_loss 5.7872e-05, test_loss 6.6480e-05\n",
      "step 1635, train_loss 5.7875e-05, test_loss 6.6477e-05\n",
      "step 1636, train_loss 5.7876e-05, test_loss 6.6481e-05\n",
      "step 1637, train_loss 5.7874e-05, test_loss 6.6469e-05\n",
      "step 1638, train_loss 5.7873e-05, test_loss 6.6478e-05\n",
      "step 1639, train_loss 5.7873e-05, test_loss 6.6462e-05\n",
      "step 1640, train_loss 5.7874e-05, test_loss 6.6477e-05\n",
      "step 1641, train_loss 5.7876e-05, test_loss 6.6461e-05\n",
      "step 1642, train_loss 5.7877e-05, test_loss 6.6479e-05\n",
      "step 1643, train_loss 5.7877e-05, test_loss 6.6461e-05\n",
      "step 1644, train_loss 5.7876e-05, test_loss 6.6477e-05\n",
      "step 1645, train_loss 5.7875e-05, test_loss 6.6459e-05\n",
      "step 1646, train_loss 5.7873e-05, test_loss 6.6473e-05\n",
      "step 1647, train_loss 5.7872e-05, test_loss 6.6455e-05\n",
      "step 1648, train_loss 5.7871e-05, test_loss 6.6468e-05\n",
      "step 1649, train_loss 5.7870e-05, test_loss 6.6449e-05\n",
      "step 1650, train_loss 5.7869e-05, test_loss 6.6463e-05\n",
      "step 1651, train_loss 5.7867e-05, test_loss 6.6441e-05\n",
      "step 1652, train_loss 5.7866e-05, test_loss 6.6459e-05\n",
      "step 1653, train_loss 5.7864e-05, test_loss 6.6431e-05\n",
      "step 1654, train_loss 5.7862e-05, test_loss 6.6458e-05\n",
      "step 1655, train_loss 5.7859e-05, test_loss 6.6420e-05\n",
      "step 1656, train_loss 5.7858e-05, test_loss 6.6459e-05\n",
      "step 1657, train_loss 5.7857e-05, test_loss 6.6409e-05\n",
      "step 1658, train_loss 5.7857e-05, test_loss 6.6466e-05\n",
      "step 1659, train_loss 5.7858e-05, test_loss 6.6399e-05\n",
      "step 1660, train_loss 5.7860e-05, test_loss 6.6484e-05\n",
      "step 1661, train_loss 5.7866e-05, test_loss 6.6395e-05\n",
      "step 1662, train_loss 5.7875e-05, test_loss 6.6527e-05\n",
      "step 1663, train_loss 5.7892e-05, test_loss 6.6411e-05\n",
      "step 1664, train_loss 5.7919e-05, test_loss 6.6628e-05\n",
      "step 1665, train_loss 5.7964e-05, test_loss 6.6485e-05\n",
      "step 1666, train_loss 5.8038e-05, test_loss 6.6867e-05\n",
      "step 1667, train_loss 5.8155e-05, test_loss 6.6726e-05\n",
      "step 1668, train_loss 5.8348e-05, test_loss 6.7455e-05\n",
      "step 1669, train_loss 5.8662e-05, test_loss 6.7442e-05\n",
      "step 1670, train_loss 5.9179e-05, test_loss 6.8964e-05\n",
      "step 1671, train_loss 6.0033e-05, test_loss 6.9532e-05\n",
      "step 1672, train_loss 6.1462e-05, test_loss 7.3031e-05\n",
      "step 1673, train_loss 6.3865e-05, test_loss 7.5686e-05\n",
      "step 1674, train_loss 6.7948e-05, test_loss 8.4498e-05\n",
      "step 1675, train_loss 7.4928e-05, test_loss 9.4104e-05\n",
      "step 1676, train_loss 8.6954e-05, test_loss 1.1804e-04\n",
      "step 1677, train_loss 1.0778e-04, test_loss 1.5001e-04\n",
      "step 1678, train_loss 1.4392e-04, test_loss 2.1802e-04\n",
      "step 1679, train_loss 2.0661e-04, test_loss 3.1811e-04\n",
      "step 1680, train_loss 3.1395e-04, test_loss 5.0736e-04\n",
      "step 1681, train_loss 4.9416e-04, test_loss 7.8105e-04\n",
      "step 1682, train_loss 7.8024e-04, test_loss 1.2118e-03\n",
      "step 1683, train_loss 1.1963e-03, test_loss 1.6855e-03\n",
      "step 1684, train_loss 1.6891e-03, test_loss 2.0886e-03\n",
      "step 1685, train_loss 2.0708e-03, test_loss 1.9933e-03\n",
      "step 1686, train_loss 1.9966e-03, test_loss 1.3543e-03\n",
      "step 1687, train_loss 1.3357e-03, test_loss 4.7947e-04\n",
      "step 1688, train_loss 4.7287e-04, test_loss 9.1359e-05\n",
      "step 1689, train_loss 7.9955e-05, test_loss 3.6394e-04\n",
      "step 1690, train_loss 3.5065e-04, test_loss 8.3091e-04\n",
      "step 1691, train_loss 8.3177e-04, test_loss 9.5334e-04\n",
      "step 1692, train_loss 9.4088e-04, test_loss 5.5663e-04\n",
      "step 1693, train_loss 5.5677e-04, test_loss 1.5006e-04\n",
      "step 1694, train_loss 1.4107e-04, test_loss 1.4327e-04\n",
      "step 1695, train_loss 1.3364e-04, test_loss 4.2355e-04\n",
      "step 1696, train_loss 4.2039e-04, test_loss 5.6691e-04\n",
      "step 1697, train_loss 5.5301e-04, test_loss 3.5372e-04\n",
      "step 1698, train_loss 3.4908e-04, test_loss 1.0628e-04\n",
      "step 1699, train_loss 9.5212e-05, test_loss 1.1278e-04\n",
      "step 1700, train_loss 1.0218e-04, test_loss 2.9194e-04\n",
      "step 1701, train_loss 2.8765e-04, test_loss 3.6170e-04\n",
      "step 1702, train_loss 3.5016e-04, test_loss 2.0858e-04\n",
      "step 1703, train_loss 2.0442e-04, test_loss 7.1049e-05\n",
      "step 1704, train_loss 6.2973e-05, test_loss 1.0575e-04\n",
      "step 1705, train_loss 9.6788e-05, test_loss 2.1416e-04\n",
      "step 1706, train_loss 2.1006e-04, test_loss 2.2995e-04\n",
      "step 1707, train_loss 2.1929e-04, test_loss 1.2472e-04\n",
      "step 1708, train_loss 1.1874e-04, test_loss 6.4786e-05\n",
      "step 1709, train_loss 5.6549e-05, test_loss 1.1017e-04\n",
      "step 1710, train_loss 1.0028e-04, test_loss 1.6405e-04\n",
      "step 1711, train_loss 1.5864e-04, test_loss 1.4894e-04\n",
      "step 1712, train_loss 1.3867e-04, test_loss 8.1702e-05\n",
      "step 1713, train_loss 7.4849e-05, test_loss 6.4933e-05\n",
      "step 1714, train_loss 5.7473e-05, test_loss 1.0534e-04\n",
      "step 1715, train_loss 9.6046e-05, test_loss 1.2665e-04\n",
      "step 1716, train_loss 1.2123e-04, test_loss 1.0460e-04\n",
      "step 1717, train_loss 9.5468e-05, test_loss 6.5677e-05\n",
      "step 1718, train_loss 5.8697e-05, test_loss 6.6016e-05\n",
      "step 1719, train_loss 5.9029e-05, test_loss 9.4282e-05\n",
      "step 1720, train_loss 8.5265e-05, test_loss 9.9713e-05\n",
      "step 1721, train_loss 9.3638e-05, test_loss 8.2432e-05\n",
      "step 1722, train_loss 7.3489e-05, test_loss 6.2727e-05\n",
      "step 1723, train_loss 5.5016e-05, test_loss 6.7774e-05\n",
      "step 1724, train_loss 6.0413e-05, test_loss 8.4670e-05\n",
      "step 1725, train_loss 7.5560e-05, test_loss 8.2863e-05\n",
      "step 1726, train_loss 7.6196e-05, test_loss 7.0964e-05\n",
      "step 1727, train_loss 6.2425e-05, test_loss 6.1392e-05\n",
      "step 1728, train_loss 5.3767e-05, test_loss 6.6443e-05\n",
      "step 1729, train_loss 5.9440e-05, test_loss 7.6613e-05\n",
      "step 1730, train_loss 6.8150e-05, test_loss 7.3509e-05\n",
      "step 1731, train_loss 6.6848e-05, test_loss 6.6268e-05\n",
      "step 1732, train_loss 5.8087e-05, test_loss 6.1446e-05\n",
      "step 1733, train_loss 5.3639e-05, test_loss 6.4950e-05\n",
      "step 1734, train_loss 5.7559e-05, test_loss 7.1228e-05\n",
      "step 1735, train_loss 6.2535e-05, test_loss 6.8737e-05\n",
      "step 1736, train_loss 6.1455e-05, test_loss 6.4673e-05\n",
      "step 1737, train_loss 5.6344e-05, test_loss 6.1844e-05\n",
      "step 1738, train_loss 5.3943e-05, test_loss 6.3675e-05\n",
      "step 1739, train_loss 5.6300e-05, test_loss 6.7422e-05\n",
      "step 1740, train_loss 5.9148e-05, test_loss 6.5581e-05\n",
      "step 1741, train_loss 5.8473e-05, test_loss 6.3408e-05\n",
      "step 1742, train_loss 5.5416e-05, test_loss 6.1593e-05\n",
      "step 1743, train_loss 5.3864e-05, test_loss 6.2698e-05\n",
      "step 1744, train_loss 5.5180e-05, test_loss 6.5371e-05\n",
      "step 1745, train_loss 5.7051e-05, test_loss 6.4470e-05\n",
      "step 1746, train_loss 5.6979e-05, test_loss 6.3502e-05\n",
      "step 1747, train_loss 5.5269e-05, test_loss 6.1997e-05\n",
      "step 1748, train_loss 5.4104e-05, test_loss 6.2316e-05\n",
      "step 1749, train_loss 5.4598e-05, test_loss 6.3895e-05\n",
      "step 1750, train_loss 5.5725e-05, test_loss 6.3401e-05\n",
      "step 1751, train_loss 5.5941e-05, test_loss 6.3106e-05\n",
      "step 1752, train_loss 5.5070e-05, test_loss 6.1939e-05\n",
      "step 1753, train_loss 5.4231e-05, test_loss 6.2027e-05\n",
      "step 1754, train_loss 5.4305e-05, test_loss 6.3064e-05\n",
      "step 1755, train_loss 5.4991e-05, test_loss 6.2992e-05\n",
      "step 1756, train_loss 5.5372e-05, test_loss 6.3192e-05\n",
      "step 1757, train_loss 5.5053e-05, test_loss 6.2305e-05\n",
      "step 1758, train_loss 5.4484e-05, test_loss 6.2209e-05\n",
      "step 1759, train_loss 5.4300e-05, test_loss 6.2650e-05\n",
      "step 1760, train_loss 5.4592e-05, test_loss 6.2632e-05\n",
      "step 1761, train_loss 5.4930e-05, test_loss 6.3001e-05\n",
      "step 1762, train_loss 5.4921e-05, test_loss 6.2364e-05\n",
      "step 1763, train_loss 5.4622e-05, test_loss 6.2299e-05\n",
      "step 1764, train_loss 5.4389e-05, test_loss 6.2381e-05\n",
      "step 1765, train_loss 5.4443e-05, test_loss 6.2429e-05\n",
      "step 1766, train_loss 5.4672e-05, test_loss 6.2866e-05\n",
      "step 1767, train_loss 5.4808e-05, test_loss 6.2513e-05\n",
      "step 1768, train_loss 5.4733e-05, test_loss 6.2569e-05\n",
      "step 1769, train_loss 5.4564e-05, test_loss 6.2416e-05\n",
      "step 1770, train_loss 5.4489e-05, test_loss 6.2438e-05\n",
      "step 1771, train_loss 5.4564e-05, test_loss 6.2728e-05\n",
      "step 1772, train_loss 5.4690e-05, test_loss 6.2551e-05\n",
      "step 1773, train_loss 5.4736e-05, test_loss 6.2692e-05\n",
      "step 1774, train_loss 5.4676e-05, test_loss 6.2460e-05\n",
      "step 1775, train_loss 5.4588e-05, test_loss 6.2474e-05\n",
      "step 1776, train_loss 5.4564e-05, test_loss 6.2584e-05\n",
      "step 1777, train_loss 5.4617e-05, test_loss 6.2525e-05\n",
      "step 1778, train_loss 5.4689e-05, test_loss 6.2724e-05\n",
      "step 1779, train_loss 5.4715e-05, test_loss 6.2550e-05\n",
      "step 1780, train_loss 5.4687e-05, test_loss 6.2623e-05\n",
      "step 1781, train_loss 5.4647e-05, test_loss 6.2588e-05\n",
      "step 1782, train_loss 5.4639e-05, test_loss 6.2584e-05\n",
      "step 1783, train_loss 5.4670e-05, test_loss 6.2720e-05\n",
      "step 1784, train_loss 5.4712e-05, test_loss 6.2614e-05\n",
      "step 1785, train_loss 5.4733e-05, test_loss 6.2718e-05\n",
      "step 1786, train_loss 5.4724e-05, test_loss 6.2605e-05\n",
      "step 1787, train_loss 5.4705e-05, test_loss 6.2633e-05\n",
      "step 1788, train_loss 5.4697e-05, test_loss 6.2660e-05\n",
      "step 1789, train_loss 5.4712e-05, test_loss 6.2632e-05\n",
      "step 1790, train_loss 5.4738e-05, test_loss 6.2741e-05\n",
      "step 1791, train_loss 5.4757e-05, test_loss 6.2664e-05\n",
      "step 1792, train_loss 5.4762e-05, test_loss 6.2738e-05\n",
      "step 1793, train_loss 5.4757e-05, test_loss 6.2695e-05\n",
      "step 1794, train_loss 5.4754e-05, test_loss 6.2707e-05\n",
      "step 1795, train_loss 5.4761e-05, test_loss 6.2748e-05\n",
      "step 1796, train_loss 5.4777e-05, test_loss 6.2707e-05\n",
      "step 1797, train_loss 5.4795e-05, test_loss 6.2785e-05\n",
      "step 1798, train_loss 5.4810e-05, test_loss 6.2726e-05\n",
      "step 1799, train_loss 5.4822e-05, test_loss 6.2791e-05\n",
      "step 1800, train_loss 5.4834e-05, test_loss 6.2784e-05\n",
      "step 1801, train_loss 5.4857e-05, test_loss 6.2832e-05\n",
      "step 1802, train_loss 5.4894e-05, test_loss 6.2909e-05\n",
      "step 1803, train_loss 5.4953e-05, test_loss 6.2965e-05\n",
      "step 1804, train_loss 5.5035e-05, test_loss 6.3120e-05\n",
      "step 1805, train_loss 5.5156e-05, test_loss 6.3264e-05\n",
      "step 1806, train_loss 5.5330e-05, test_loss 6.3553e-05\n",
      "step 1807, train_loss 5.5604e-05, test_loss 6.3974e-05\n",
      "step 1808, train_loss 5.6028e-05, test_loss 6.4630e-05\n",
      "step 1809, train_loss 5.6711e-05, test_loss 6.5754e-05\n",
      "step 1810, train_loss 5.7793e-05, test_loss 6.7448e-05\n",
      "step 1811, train_loss 5.9554e-05, test_loss 7.0379e-05\n",
      "step 1812, train_loss 6.2406e-05, test_loss 7.4993e-05\n",
      "step 1813, train_loss 6.7119e-05, test_loss 8.2886e-05\n",
      "step 1814, train_loss 7.4909e-05, test_loss 9.5808e-05\n",
      "step 1815, train_loss 8.7963e-05, test_loss 1.1781e-04\n",
      "step 1816, train_loss 1.0984e-04, test_loss 1.5448e-04\n",
      "step 1817, train_loss 1.4671e-04, test_loss 2.1636e-04\n",
      "step 1818, train_loss 2.0845e-04, test_loss 3.1832e-04\n",
      "step 1819, train_loss 3.1076e-04, test_loss 4.8319e-04\n",
      "step 1820, train_loss 4.7544e-04, test_loss 7.3371e-04\n",
      "step 1821, train_loss 7.2658e-04, test_loss 1.0793e-03\n",
      "step 1822, train_loss 1.0719e-03, test_loss 1.4655e-03\n",
      "step 1823, train_loss 1.4589e-03, test_loss 1.7329e-03\n",
      "step 1824, train_loss 1.7254e-03, test_loss 1.6381e-03\n",
      "step 1825, train_loss 1.6309e-03, test_loss 1.1014e-03\n",
      "step 1826, train_loss 1.0920e-03, test_loss 4.1725e-04\n",
      "step 1827, train_loss 4.0806e-04, test_loss 7.3505e-05\n",
      "step 1828, train_loss 6.3426e-05, test_loss 2.3625e-04\n",
      "step 1829, train_loss 2.2846e-04, test_loss 6.2221e-04\n",
      "step 1830, train_loss 6.1591e-04, test_loss 7.9707e-04\n",
      "step 1831, train_loss 7.9127e-04, test_loss 5.8092e-04\n",
      "step 1832, train_loss 5.7581e-04, test_loss 2.1619e-04\n",
      "step 1833, train_loss 2.0849e-04, test_loss 7.0332e-05\n",
      "step 1834, train_loss 6.3289e-05, test_loss 2.2762e-04\n",
      "step 1835, train_loss 2.1896e-04, test_loss 4.2344e-04\n",
      "step 1836, train_loss 4.1560e-04, test_loss 4.0525e-04\n",
      "step 1837, train_loss 3.9744e-04, test_loss 2.0912e-04\n",
      "step 1838, train_loss 2.0039e-04, test_loss 7.3644e-05\n",
      "step 1839, train_loss 6.6557e-05, test_loss 1.2960e-04\n",
      "step 1840, train_loss 1.2142e-04, test_loss 2.5045e-04\n",
      "step 1841, train_loss 2.4413e-04, test_loss 2.6457e-04\n",
      "step 1842, train_loss 2.5779e-04, test_loss 1.5862e-04\n",
      "step 1843, train_loss 1.5141e-04, test_loss 7.1102e-05\n",
      "step 1844, train_loss 6.4579e-05, test_loss 9.6472e-05\n",
      "step 1845, train_loss 8.8315e-05, test_loss 1.6764e-04\n",
      "step 1846, train_loss 1.6102e-04, test_loss 1.8089e-04\n",
      "step 1847, train_loss 1.7310e-04, test_loss 1.1890e-04\n",
      "step 1848, train_loss 1.1143e-04, test_loss 6.5689e-05\n",
      "step 1849, train_loss 5.8626e-05, test_loss 8.0061e-05\n",
      "step 1850, train_loss 7.2011e-05, test_loss 1.2310e-04\n",
      "step 1851, train_loss 1.1658e-04, test_loss 1.3328e-04\n",
      "step 1852, train_loss 1.2552e-04, test_loss 9.5612e-05\n",
      "step 1853, train_loss 8.8591e-05, test_loss 6.2012e-05\n",
      "step 1854, train_loss 5.4837e-05, test_loss 6.8796e-05\n",
      "step 1855, train_loss 6.1074e-05, test_loss 9.5405e-05\n",
      "step 1856, train_loss 8.8817e-05, test_loss 1.0480e-04\n",
      "step 1857, train_loss 9.7101e-05, test_loss 8.3039e-05\n",
      "step 1858, train_loss 7.6284e-05, test_loss 6.1315e-05\n",
      "step 1859, train_loss 5.4037e-05, test_loss 6.2202e-05\n",
      "step 1860, train_loss 5.4795e-05, test_loss 7.8091e-05\n",
      "step 1861, train_loss 7.1219e-05, test_loss 8.6892e-05\n",
      "step 1862, train_loss 7.9102e-05, test_loss 7.6084e-05\n",
      "step 1863, train_loss 6.9096e-05, test_loss 6.2498e-05\n",
      "step 1864, train_loss 5.4830e-05, test_loss 5.9616e-05\n",
      "step 1865, train_loss 5.2265e-05, test_loss 6.7887e-05\n",
      "step 1866, train_loss 6.0770e-05, test_loss 7.4711e-05\n",
      "step 1867, train_loss 6.7255e-05, test_loss 7.0480e-05\n",
      "step 1868, train_loss 6.3705e-05, test_loss 6.2709e-05\n",
      "step 1869, train_loss 5.5354e-05, test_loss 5.8804e-05\n",
      "step 1870, train_loss 5.1836e-05, test_loss 6.2652e-05\n",
      "step 1871, train_loss 5.5430e-05, test_loss 6.7407e-05\n",
      "step 1872, train_loss 6.0016e-05, test_loss 6.6876e-05\n",
      "step 1873, train_loss 5.9664e-05, test_loss 6.2905e-05\n",
      "step 1874, train_loss 5.5270e-05, test_loss 5.9327e-05\n",
      "step 1875, train_loss 5.2056e-05, test_loss 6.0454e-05\n",
      "step 1876, train_loss 5.2964e-05, test_loss 6.3105e-05\n",
      "step 1877, train_loss 5.5848e-05, test_loss 6.4016e-05\n",
      "step 1878, train_loss 5.6831e-05, test_loss 6.2150e-05\n",
      "step 1879, train_loss 5.4909e-05, test_loss 5.9476e-05\n",
      "step 1880, train_loss 5.2399e-05, test_loss 5.9178e-05\n",
      "step 1881, train_loss 5.1874e-05, test_loss 6.0555e-05\n",
      "step 1882, train_loss 5.3346e-05, test_loss 6.2153e-05\n",
      "step 1883, train_loss 5.4750e-05, test_loss 6.1903e-05\n",
      "step 1884, train_loss 5.4511e-05, test_loss 6.0452e-05\n",
      "step 1885, train_loss 5.3015e-05, test_loss 5.9328e-05\n",
      "step 1886, train_loss 5.1888e-05, test_loss 5.9425e-05\n",
      "step 1887, train_loss 5.2074e-05, test_loss 6.0410e-05\n",
      "step 1888, train_loss 5.3054e-05, test_loss 6.0891e-05\n",
      "step 1889, train_loss 5.3651e-05, test_loss 6.0579e-05\n",
      "step 1890, train_loss 5.3281e-05, test_loss 5.9670e-05\n",
      "step 1891, train_loss 5.2436e-05, test_loss 5.9281e-05\n",
      "step 1892, train_loss 5.1945e-05, test_loss 5.9484e-05\n",
      "step 1893, train_loss 5.2157e-05, test_loss 6.0095e-05\n",
      "step 1894, train_loss 5.2699e-05, test_loss 6.0387e-05\n",
      "step 1895, train_loss 5.2968e-05, test_loss 6.0148e-05\n",
      "step 1896, train_loss 5.2756e-05, test_loss 5.9763e-05\n",
      "step 1897, train_loss 5.2324e-05, test_loss 5.9428e-05\n",
      "step 1898, train_loss 5.2093e-05, test_loss 5.9612e-05\n",
      "step 1899, train_loss 5.2211e-05, test_loss 5.9787e-05\n",
      "step 1900, train_loss 5.2486e-05, test_loss 6.0001e-05\n",
      "step 1901, train_loss 5.2636e-05, test_loss 5.9877e-05\n",
      "step 1902, train_loss 5.2537e-05, test_loss 5.9684e-05\n",
      "step 1903, train_loss 5.2323e-05, test_loss 5.9604e-05\n",
      "step 1904, train_loss 5.2191e-05, test_loss 5.9607e-05\n",
      "step 1905, train_loss 5.2240e-05, test_loss 5.9847e-05\n",
      "step 1906, train_loss 5.2396e-05, test_loss 5.9875e-05\n",
      "step 1907, train_loss 5.2508e-05, test_loss 5.9935e-05\n",
      "step 1908, train_loss 5.2499e-05, test_loss 5.9764e-05\n",
      "step 1909, train_loss 5.2393e-05, test_loss 5.9696e-05\n",
      "step 1910, train_loss 5.2297e-05, test_loss 5.9677e-05\n",
      "step 1911, train_loss 5.2284e-05, test_loss 5.9727e-05\n",
      "step 1912, train_loss 5.2351e-05, test_loss 5.9858e-05\n",
      "step 1913, train_loss 5.2437e-05, test_loss 5.9850e-05\n",
      "step 1914, train_loss 5.2476e-05, test_loss 5.9892e-05\n",
      "step 1915, train_loss 5.2456e-05, test_loss 5.9788e-05\n",
      "step 1916, train_loss 5.2405e-05, test_loss 5.9802e-05\n",
      "step 1917, train_loss 5.2373e-05, test_loss 5.9777e-05\n",
      "step 1918, train_loss 5.2382e-05, test_loss 5.9836e-05\n",
      "step 1919, train_loss 5.2421e-05, test_loss 5.9874e-05\n",
      "step 1920, train_loss 5.2463e-05, test_loss 5.9886e-05\n",
      "step 1921, train_loss 5.2480e-05, test_loss 5.9897e-05\n",
      "step 1922, train_loss 5.2472e-05, test_loss 5.9856e-05\n",
      "step 1923, train_loss 5.2452e-05, test_loss 5.9872e-05\n",
      "step 1924, train_loss 5.2441e-05, test_loss 5.9851e-05\n",
      "step 1925, train_loss 5.2449e-05, test_loss 5.9896e-05\n",
      "step 1926, train_loss 5.2470e-05, test_loss 5.9895e-05\n",
      "step 1927, train_loss 5.2494e-05, test_loss 5.9928e-05\n",
      "step 1928, train_loss 5.2507e-05, test_loss 5.9915e-05\n",
      "step 1929, train_loss 5.2509e-05, test_loss 5.9924e-05\n",
      "step 1930, train_loss 5.2502e-05, test_loss 5.9913e-05\n",
      "step 1931, train_loss 5.2496e-05, test_loss 5.9923e-05\n",
      "step 1932, train_loss 5.2497e-05, test_loss 5.9930e-05\n",
      "step 1933, train_loss 5.2506e-05, test_loss 5.9942e-05\n",
      "step 1934, train_loss 5.2519e-05, test_loss 5.9954e-05\n",
      "step 1935, train_loss 5.2530e-05, test_loss 5.9951e-05\n",
      "step 1936, train_loss 5.2537e-05, test_loss 5.9958e-05\n",
      "step 1937, train_loss 5.2537e-05, test_loss 5.9944e-05\n",
      "step 1938, train_loss 5.2536e-05, test_loss 5.9957e-05\n",
      "step 1939, train_loss 5.2535e-05, test_loss 5.9946e-05\n",
      "step 1940, train_loss 5.2537e-05, test_loss 5.9970e-05\n",
      "step 1941, train_loss 5.2542e-05, test_loss 5.9961e-05\n",
      "step 1942, train_loss 5.2548e-05, test_loss 5.9985e-05\n",
      "step 1943, train_loss 5.2554e-05, test_loss 5.9971e-05\n",
      "step 1944, train_loss 5.2557e-05, test_loss 5.9986e-05\n",
      "step 1945, train_loss 5.2559e-05, test_loss 5.9968e-05\n",
      "step 1946, train_loss 5.2558e-05, test_loss 5.9978e-05\n",
      "step 1947, train_loss 5.2558e-05, test_loss 5.9963e-05\n",
      "step 1948, train_loss 5.2557e-05, test_loss 5.9974e-05\n",
      "step 1949, train_loss 5.2557e-05, test_loss 5.9967e-05\n",
      "step 1950, train_loss 5.2559e-05, test_loss 5.9979e-05\n",
      "step 1951, train_loss 5.2561e-05, test_loss 5.9974e-05\n",
      "step 1952, train_loss 5.2563e-05, test_loss 5.9983e-05\n",
      "step 1953, train_loss 5.2564e-05, test_loss 5.9975e-05\n",
      "step 1954, train_loss 5.2564e-05, test_loss 5.9980e-05\n",
      "step 1955, train_loss 5.2563e-05, test_loss 5.9969e-05\n",
      "step 1956, train_loss 5.2562e-05, test_loss 5.9972e-05\n",
      "step 1957, train_loss 5.2560e-05, test_loss 5.9961e-05\n",
      "step 1958, train_loss 5.2558e-05, test_loss 5.9967e-05\n",
      "step 1959, train_loss 5.2557e-05, test_loss 5.9956e-05\n",
      "step 1960, train_loss 5.2556e-05, test_loss 5.9965e-05\n",
      "step 1961, train_loss 5.2555e-05, test_loss 5.9953e-05\n",
      "step 1962, train_loss 5.2554e-05, test_loss 5.9963e-05\n",
      "step 1963, train_loss 5.2552e-05, test_loss 5.9947e-05\n",
      "step 1964, train_loss 5.2551e-05, test_loss 5.9959e-05\n",
      "step 1965, train_loss 5.2549e-05, test_loss 5.9937e-05\n",
      "step 1966, train_loss 5.2546e-05, test_loss 5.9954e-05\n",
      "step 1967, train_loss 5.2544e-05, test_loss 5.9924e-05\n",
      "step 1968, train_loss 5.2541e-05, test_loss 5.9951e-05\n",
      "step 1969, train_loss 5.2540e-05, test_loss 5.9912e-05\n",
      "step 1970, train_loss 5.2538e-05, test_loss 5.9954e-05\n",
      "step 1971, train_loss 5.2537e-05, test_loss 5.9900e-05\n",
      "step 1972, train_loss 5.2538e-05, test_loss 5.9968e-05\n",
      "step 1973, train_loss 5.2542e-05, test_loss 5.9893e-05\n",
      "step 1974, train_loss 5.2548e-05, test_loss 6.0004e-05\n",
      "step 1975, train_loss 5.2561e-05, test_loss 5.9900e-05\n",
      "step 1976, train_loss 5.2584e-05, test_loss 6.0094e-05\n",
      "step 1977, train_loss 5.2623e-05, test_loss 5.9961e-05\n",
      "step 1978, train_loss 5.2689e-05, test_loss 6.0321e-05\n",
      "step 1979, train_loss 5.2801e-05, test_loss 6.0189e-05\n",
      "step 1980, train_loss 5.2989e-05, test_loss 6.0913e-05\n",
      "step 1981, train_loss 5.3308e-05, test_loss 6.0927e-05\n",
      "step 1982, train_loss 5.3848e-05, test_loss 6.2532e-05\n",
      "step 1983, train_loss 5.4777e-05, test_loss 6.3243e-05\n",
      "step 1984, train_loss 5.6376e-05, test_loss 6.7177e-05\n",
      "step 1985, train_loss 5.9160e-05, test_loss 7.0524e-05\n",
      "step 1986, train_loss 6.4031e-05, test_loss 8.1112e-05\n",
      "step 1987, train_loss 7.2635e-05, test_loss 9.3700e-05\n",
      "step 1988, train_loss 8.7888e-05, test_loss 1.2440e-04\n",
      "step 1989, train_loss 1.1512e-04, test_loss 1.6819e-04\n",
      "step 1990, train_loss 1.6365e-04, test_loss 2.6069e-04\n",
      "step 1991, train_loss 2.5004e-04, test_loss 4.0315e-04\n",
      "step 1992, train_loss 4.0098e-04, test_loss 6.7024e-04\n",
      "step 1993, train_loss 6.5746e-04, test_loss 1.0599e-03\n",
      "step 1994, train_loss 1.0619e-03, test_loss 1.6407e-03\n",
      "step 1995, train_loss 1.6252e-03, test_loss 2.2006e-03\n",
      "step 1996, train_loss 2.2073e-03, test_loss 2.4804e-03\n",
      "step 1997, train_loss 2.4625e-03, test_loss 1.9756e-03\n",
      "step 1998, train_loss 1.9793e-03, test_loss 9.4950e-04\n",
      "step 1999, train_loss 9.3224e-04, test_loss 1.5321e-04\n",
      "step 2000, train_loss 1.4473e-04, test_loss 2.3001e-04\n",
      "best test loss at step 1869, train_loss 5.5354e-05, test_loss 5.8804e-05\n"
     ]
    }
   ],
   "source": [
    "print_results(stats_hnn, 1)\n",
    "print_best(stats_hnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model:\n",
      "step 0, train_loss 8.9177e-01, test_loss 9.7633e-01\n",
      "step 200, train_loss 1.8746e-03, test_loss 1.0905e-03\n",
      "step 400, train_loss 5.7407e-05, test_loss 3.5991e-05\n",
      "step 600, train_loss 3.7400e-05, test_loss 7.1743e-05\n",
      "step 800, train_loss 1.7748e-03, test_loss 1.2458e-03\n",
      "step 1000, train_loss 2.2464e-05, test_loss 2.6716e-05\n",
      "step 1200, train_loss 2.2518e-05, test_loss 2.6828e-05\n",
      "step 1400, train_loss 2.1751e-05, test_loss 2.5885e-05\n",
      "step 1600, train_loss 4.3046e-05, test_loss 5.0439e-05\n",
      "step 1800, train_loss 2.8079e-05, test_loss 3.6848e-05\n",
      "step 2000, train_loss 2.2038e-05, test_loss 2.6113e-05\n",
      "Final train loss 2.1999e-05 +/- 4.0849e-07\n",
      "Final test loss 2.6113e-05 +/- 4.4631e-07\n"
     ]
    }
   ],
   "source": [
    "args.baseline = True\n",
    "model_baseline, stats_baseline = train(args)\n",
    "\n",
    "# save\n",
    "os.makedirs(args.save_dir) if not os.path.exists(args.save_dir) else None\n",
    "label = '-baseline'\n",
    "path = \"{}/{}{}.tar\".format(args.save_dir, args.name, label)\n",
    "torch.save(model_baseline.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train_loss 8.9177e-01, test_loss 9.7633e-01\n",
      "step 1, train_loss 9.5587e-01, test_loss 8.2766e-01\n",
      "step 2, train_loss 8.0879e-01, test_loss 7.8033e-01\n",
      "step 3, train_loss 7.6315e-01, test_loss 7.7991e-01\n",
      "step 4, train_loss 7.6415e-01, test_loss 7.1956e-01\n",
      "step 5, train_loss 7.0481e-01, test_loss 6.4505e-01\n",
      "step 6, train_loss 6.3109e-01, test_loss 6.0629e-01\n",
      "step 7, train_loss 5.9309e-01, test_loss 5.8841e-01\n",
      "step 8, train_loss 5.7607e-01, test_loss 5.5222e-01\n",
      "step 9, train_loss 5.4087e-01, test_loss 4.9717e-01\n",
      "step 10, train_loss 4.8690e-01, test_loss 4.4882e-01\n",
      "step 11, train_loss 4.3965e-01, test_loss 4.1928e-01\n",
      "step 12, train_loss 4.1118e-01, test_loss 3.9483e-01\n",
      "step 13, train_loss 3.8769e-01, test_loss 3.5939e-01\n",
      "step 14, train_loss 3.5307e-01, test_loss 3.1649e-01\n",
      "step 15, train_loss 3.1087e-01, test_loss 2.8031e-01\n",
      "step 16, train_loss 2.7532e-01, test_loss 2.5555e-01\n",
      "step 17, train_loss 2.5118e-01, test_loss 2.3272e-01\n",
      "step 18, train_loss 2.2897e-01, test_loss 2.0340e-01\n",
      "step 19, train_loss 2.0027e-01, test_loss 1.7183e-01\n",
      "step 20, train_loss 1.6932e-01, test_loss 1.4720e-01\n",
      "step 21, train_loss 1.4524e-01, test_loss 1.3032e-01\n",
      "step 22, train_loss 1.2884e-01, test_loss 1.1367e-01\n",
      "step 23, train_loss 1.1256e-01, test_loss 9.3682e-02\n",
      "step 24, train_loss 9.2824e-02, test_loss 7.5592e-02\n",
      "step 25, train_loss 7.4909e-02, test_loss 6.4343e-02\n",
      "step 26, train_loss 6.3781e-02, test_loss 5.6797e-02\n",
      "step 27, train_loss 5.6328e-02, test_loss 4.7433e-02\n",
      "step 28, train_loss 4.7039e-02, test_loss 3.7359e-02\n",
      "step 29, train_loss 3.7022e-02, test_loss 3.1309e-02\n",
      "step 30, train_loss 3.1006e-02, test_loss 2.8827e-02\n",
      "step 31, train_loss 2.8532e-02, test_loss 2.5177e-02\n",
      "step 32, train_loss 2.4870e-02, test_loss 1.9830e-02\n",
      "step 33, train_loss 1.9506e-02, test_loss 1.6542e-02\n",
      "step 34, train_loss 1.6212e-02, test_loss 1.5669e-02\n",
      "step 35, train_loss 1.5353e-02, test_loss 1.3696e-02\n",
      "step 36, train_loss 1.3413e-02, test_loss 1.0342e-02\n",
      "step 37, train_loss 1.0103e-02, test_loss 8.6739e-03\n",
      "step 38, train_loss 8.4823e-03, test_loss 8.6417e-03\n",
      "step 39, train_loss 8.4984e-03, test_loss 7.5816e-03\n",
      "step 40, train_loss 7.4858e-03, test_loss 5.9900e-03\n",
      "step 41, train_loss 5.9406e-03, test_loss 6.0265e-03\n",
      "step 42, train_loss 6.0199e-03, test_loss 6.6918e-03\n",
      "step 43, train_loss 6.7179e-03, test_loss 6.2840e-03\n",
      "step 44, train_loss 6.3277e-03, test_loss 6.0060e-03\n",
      "step 45, train_loss 6.0539e-03, test_loss 6.7761e-03\n",
      "step 46, train_loss 6.8206e-03, test_loss 7.1178e-03\n",
      "step 47, train_loss 7.1569e-03, test_loss 6.6428e-03\n",
      "step 48, train_loss 6.6764e-03, test_loss 6.6304e-03\n",
      "step 49, train_loss 6.6565e-03, test_loss 6.8594e-03\n",
      "step 50, train_loss 6.8734e-03, test_loss 6.3311e-03\n",
      "step 51, train_loss 6.3279e-03, test_loss 5.6428e-03\n",
      "step 52, train_loss 5.6207e-03, test_loss 5.3975e-03\n",
      "step 53, train_loss 5.3595e-03, test_loss 4.8920e-03\n",
      "step 54, train_loss 4.8434e-03, test_loss 3.9938e-03\n",
      "step 55, train_loss 3.9395e-03, test_loss 3.4055e-03\n",
      "step 56, train_loss 3.3482e-03, test_loss 2.9906e-03\n",
      "step 57, train_loss 2.9312e-03, test_loss 2.2967e-03\n",
      "step 58, train_loss 2.2360e-03, test_loss 1.6910e-03\n",
      "step 59, train_loss 1.6308e-03, test_loss 1.4104e-03\n",
      "step 60, train_loss 1.3530e-03, test_loss 1.0689e-03\n",
      "step 61, train_loss 1.0156e-03, test_loss 6.6816e-04\n",
      "step 62, train_loss 6.1959e-04, test_loss 5.2681e-04\n",
      "step 63, train_loss 4.8288e-04, test_loss 4.8357e-04\n",
      "step 64, train_loss 4.4401e-04, test_loss 3.4073e-04\n",
      "step 65, train_loss 3.0547e-04, test_loss 3.0567e-04\n",
      "step 66, train_loss 2.7468e-04, test_loss 4.1064e-04\n",
      "step 67, train_loss 3.8336e-04, test_loss 4.4067e-04\n",
      "step 68, train_loss 4.1599e-04, test_loss 4.5133e-04\n",
      "step 69, train_loss 4.2834e-04, test_loss 5.6230e-04\n",
      "step 70, train_loss 5.4063e-04, test_loss 6.3805e-04\n",
      "step 71, train_loss 6.1782e-04, test_loss 6.3200e-04\n",
      "step 72, train_loss 6.1350e-04, test_loss 6.6589e-04\n",
      "step 73, train_loss 6.4919e-04, test_loss 6.9977e-04\n",
      "step 74, train_loss 6.8447e-04, test_loss 6.5204e-04\n",
      "step 75, train_loss 6.3765e-04, test_loss 6.0461e-04\n",
      "step 76, train_loss 5.9097e-04, test_loss 5.8033e-04\n",
      "step 77, train_loss 5.6762e-04, test_loss 5.0514e-04\n",
      "step 78, train_loss 4.9357e-04, test_loss 4.1708e-04\n",
      "step 79, train_loss 4.0673e-04, test_loss 3.6498e-04\n",
      "step 80, train_loss 3.5564e-04, test_loss 2.9704e-04\n",
      "step 81, train_loss 2.8834e-04, test_loss 2.1794e-04\n",
      "step 82, train_loss 2.0960e-04, test_loss 1.7564e-04\n",
      "step 83, train_loss 1.6757e-04, test_loss 1.3860e-04\n",
      "step 84, train_loss 1.3073e-04, test_loss 9.2942e-05\n",
      "step 85, train_loss 8.5172e-05, test_loss 7.5964e-05\n",
      "step 86, train_loss 6.8215e-05, test_loss 7.0561e-05\n",
      "step 87, train_loss 6.2738e-05, test_loss 5.5894e-05\n",
      "step 88, train_loss 4.7988e-05, test_loss 5.7964e-05\n",
      "step 89, train_loss 5.0062e-05, test_loss 6.9031e-05\n",
      "step 90, train_loss 6.1188e-05, test_loss 6.8917e-05\n",
      "step 91, train_loss 6.1174e-05, test_loss 7.5671e-05\n",
      "step 92, train_loss 6.8126e-05, test_loss 8.7245e-05\n",
      "step 93, train_loss 8.0009e-05, test_loss 8.7251e-05\n",
      "step 94, train_loss 8.0441e-05, test_loss 8.8864e-05\n",
      "step 95, train_loss 8.2596e-05, test_loss 9.3188e-05\n",
      "step 96, train_loss 8.7498e-05, test_loss 8.8094e-05\n",
      "step 97, train_loss 8.2966e-05, test_loss 8.3511e-05\n",
      "step 98, train_loss 7.8957e-05, test_loss 8.1459e-05\n",
      "step 99, train_loss 7.7476e-05, test_loss 7.3069e-05\n",
      "step 100, train_loss 6.9627e-05, test_loss 6.5899e-05\n",
      "step 101, train_loss 6.2957e-05, test_loss 6.1700e-05\n",
      "step 102, train_loss 5.9170e-05, test_loss 5.3868e-05\n",
      "step 103, train_loss 5.1643e-05, test_loss 4.8022e-05\n",
      "step 104, train_loss 4.6020e-05, test_loss 4.5047e-05\n",
      "step 105, train_loss 4.3176e-05, test_loss 3.9959e-05\n",
      "step 106, train_loss 3.8116e-05, test_loss 3.6987e-05\n",
      "step 107, train_loss 3.5087e-05, test_loss 3.6218e-05\n",
      "step 108, train_loss 3.4169e-05, test_loss 3.3976e-05\n",
      "step 109, train_loss 3.1700e-05, test_loss 3.3512e-05\n",
      "step 110, train_loss 3.0953e-05, test_loss 3.4338e-05\n",
      "step 111, train_loss 3.1430e-05, test_loss 3.3927e-05\n",
      "step 112, train_loss 3.0617e-05, test_loss 3.4834e-05\n",
      "step 113, train_loss 3.1092e-05, test_loss 3.6213e-05\n",
      "step 114, train_loss 3.2018e-05, test_loss 3.6491e-05\n",
      "step 115, train_loss 3.1846e-05, test_loss 3.7671e-05\n",
      "step 116, train_loss 3.2589e-05, test_loss 3.8746e-05\n",
      "step 117, train_loss 3.3236e-05, test_loss 3.8923e-05\n",
      "step 118, train_loss 3.3014e-05, test_loss 3.9699e-05\n",
      "step 119, train_loss 3.3434e-05, test_loss 4.0033e-05\n",
      "step 120, train_loss 3.3466e-05, test_loss 3.9730e-05\n",
      "step 121, train_loss 3.2929e-05, test_loss 3.9838e-05\n",
      "step 122, train_loss 3.2862e-05, test_loss 3.9423e-05\n",
      "step 123, train_loss 3.2333e-05, test_loss 3.8704e-05\n",
      "step 124, train_loss 3.1568e-05, test_loss 3.8296e-05\n",
      "step 125, train_loss 3.1175e-05, test_loss 3.7448e-05\n",
      "step 126, train_loss 3.0408e-05, test_loss 3.6608e-05\n",
      "step 127, train_loss 2.9704e-05, test_loss 3.6015e-05\n",
      "step 128, train_loss 2.9290e-05, test_loss 3.5149e-05\n",
      "step 129, train_loss 2.8641e-05, test_loss 3.4499e-05\n",
      "step 130, train_loss 2.8233e-05, test_loss 3.4004e-05\n",
      "step 131, train_loss 2.8001e-05, test_loss 3.3380e-05\n",
      "step 132, train_loss 2.7652e-05, test_loss 3.3025e-05\n",
      "step 133, train_loss 2.7570e-05, test_loss 3.2710e-05\n",
      "step 134, train_loss 2.7519e-05, test_loss 3.2359e-05\n",
      "step 135, train_loss 2.7415e-05, test_loss 3.2215e-05\n",
      "step 136, train_loss 2.7496e-05, test_loss 3.2013e-05\n",
      "step 137, train_loss 2.7494e-05, test_loss 3.1831e-05\n",
      "step 138, train_loss 2.7479e-05, test_loss 3.1758e-05\n",
      "step 139, train_loss 2.7541e-05, test_loss 3.1599e-05\n",
      "step 140, train_loss 2.7481e-05, test_loss 3.1501e-05\n",
      "step 141, train_loss 2.7445e-05, test_loss 3.1439e-05\n",
      "step 142, train_loss 2.7414e-05, test_loss 3.1330e-05\n",
      "step 143, train_loss 2.7300e-05, test_loss 3.1305e-05\n",
      "step 144, train_loss 2.7244e-05, test_loss 3.1284e-05\n",
      "step 145, train_loss 2.7164e-05, test_loss 3.1271e-05\n",
      "step 146, train_loss 2.7070e-05, test_loss 3.1337e-05\n",
      "step 147, train_loss 2.7038e-05, test_loss 3.1394e-05\n",
      "step 148, train_loss 2.6983e-05, test_loss 3.1489e-05\n",
      "step 149, train_loss 2.6961e-05, test_loss 3.1625e-05\n",
      "step 150, train_loss 2.6975e-05, test_loss 3.1743e-05\n",
      "step 151, train_loss 2.6973e-05, test_loss 3.1895e-05\n",
      "step 152, train_loss 2.7009e-05, test_loss 3.2037e-05\n",
      "step 153, train_loss 2.7044e-05, test_loss 3.2157e-05\n",
      "step 154, train_loss 2.7071e-05, test_loss 3.2284e-05\n",
      "step 155, train_loss 2.7116e-05, test_loss 3.2369e-05\n",
      "step 156, train_loss 2.7136e-05, test_loss 3.2439e-05\n",
      "step 157, train_loss 2.7154e-05, test_loss 3.2486e-05\n",
      "step 158, train_loss 2.7168e-05, test_loss 3.2495e-05\n",
      "step 159, train_loss 2.7159e-05, test_loss 3.2492e-05\n",
      "step 160, train_loss 2.7153e-05, test_loss 3.2460e-05\n",
      "step 161, train_loss 2.7132e-05, test_loss 3.2409e-05\n",
      "step 162, train_loss 2.7102e-05, test_loss 3.2349e-05\n",
      "step 163, train_loss 2.7074e-05, test_loss 3.2271e-05\n",
      "step 164, train_loss 2.7035e-05, test_loss 3.2191e-05\n",
      "step 165, train_loss 2.7001e-05, test_loss 3.2107e-05\n",
      "step 166, train_loss 2.6965e-05, test_loss 3.2018e-05\n",
      "step 167, train_loss 2.6926e-05, test_loss 3.1938e-05\n",
      "step 168, train_loss 2.6894e-05, test_loss 3.1855e-05\n",
      "step 169, train_loss 2.6860e-05, test_loss 3.1781e-05\n",
      "step 170, train_loss 2.6830e-05, test_loss 3.1714e-05\n",
      "step 171, train_loss 2.6803e-05, test_loss 3.1653e-05\n",
      "step 172, train_loss 2.6775e-05, test_loss 3.1602e-05\n",
      "step 173, train_loss 2.6754e-05, test_loss 3.1558e-05\n",
      "step 174, train_loss 2.6732e-05, test_loss 3.1521e-05\n",
      "step 175, train_loss 2.6712e-05, test_loss 3.1496e-05\n",
      "step 176, train_loss 2.6697e-05, test_loss 3.1473e-05\n",
      "step 177, train_loss 2.6681e-05, test_loss 3.1462e-05\n",
      "step 178, train_loss 2.6668e-05, test_loss 3.1452e-05\n",
      "step 179, train_loss 2.6657e-05, test_loss 3.1452e-05\n",
      "step 180, train_loss 2.6646e-05, test_loss 3.1450e-05\n",
      "step 181, train_loss 2.6638e-05, test_loss 3.1459e-05\n",
      "step 182, train_loss 2.6630e-05, test_loss 3.1458e-05\n",
      "step 183, train_loss 2.6623e-05, test_loss 3.1477e-05\n",
      "step 184, train_loss 2.6617e-05, test_loss 3.1468e-05\n",
      "step 185, train_loss 2.6612e-05, test_loss 3.1505e-05\n",
      "step 186, train_loss 2.6612e-05, test_loss 3.1484e-05\n",
      "step 187, train_loss 2.6617e-05, test_loss 3.1579e-05\n",
      "step 188, train_loss 2.6643e-05, test_loss 3.1568e-05\n",
      "step 189, train_loss 2.6714e-05, test_loss 3.1913e-05\n",
      "step 190, train_loss 2.6912e-05, test_loss 3.2207e-05\n",
      "step 191, train_loss 2.7426e-05, test_loss 3.3968e-05\n",
      "step 192, train_loss 2.8824e-05, test_loss 3.7142e-05\n",
      "step 193, train_loss 3.2588e-05, test_loss 4.8526e-05\n",
      "step 194, train_loss 4.3015e-05, test_loss 7.5797e-05\n",
      "step 195, train_loss 7.1908e-05, test_loss 1.5806e-04\n",
      "step 196, train_loss 1.5159e-04, test_loss 3.6131e-04\n",
      "step 197, train_loss 3.5935e-04, test_loss 8.3194e-04\n",
      "step 198, train_loss 8.2348e-04, test_loss 1.5338e-03\n",
      "step 199, train_loss 1.5358e-03, test_loss 1.8845e-03\n",
      "step 200, train_loss 1.8746e-03, test_loss 1.0905e-03\n",
      "step 201, train_loss 1.0910e-03, test_loss 1.0684e-04\n",
      "step 202, train_loss 1.0039e-04, test_loss 3.3561e-04\n",
      "step 203, train_loss 3.2795e-04, test_loss 1.0391e-03\n",
      "step 204, train_loss 1.0393e-03, test_loss 7.7958e-04\n",
      "step 205, train_loss 7.7066e-04, test_loss 7.9622e-05\n",
      "step 206, train_loss 7.5197e-05, test_loss 2.7442e-04\n",
      "step 207, train_loss 2.7142e-04, test_loss 7.2545e-04\n",
      "step 208, train_loss 7.1656e-04, test_loss 3.8985e-04\n",
      "step 209, train_loss 3.8746e-04, test_loss 3.2133e-05\n",
      "step 210, train_loss 2.6689e-05, test_loss 3.3216e-04\n",
      "step 211, train_loss 3.2442e-04, test_loss 4.7684e-04\n",
      "step 212, train_loss 4.7500e-04, test_loss 1.3998e-04\n",
      "step 213, train_loss 1.3327e-04, test_loss 7.5212e-05\n",
      "step 214, train_loss 6.9097e-05, test_loss 3.2683e-04\n",
      "step 215, train_loss 3.2453e-04, test_loss 2.6161e-04\n",
      "step 216, train_loss 2.5453e-04, test_loss 3.8394e-05\n",
      "step 217, train_loss 3.3864e-05, test_loss 1.3553e-04\n",
      "step 218, train_loss 1.3226e-04, test_loss 2.5802e-04\n",
      "step 219, train_loss 2.5117e-04, test_loss 1.0990e-04\n",
      "step 220, train_loss 1.0652e-04, test_loss 3.7432e-05\n",
      "step 221, train_loss 3.3095e-05, test_loss 1.5980e-04\n",
      "step 222, train_loss 1.5353e-04, test_loss 1.6047e-04\n",
      "step 223, train_loss 1.5758e-04, test_loss 4.6627e-05\n",
      "step 224, train_loss 4.1377e-05, test_loss 6.2496e-05\n",
      "step 225, train_loss 5.7007e-05, test_loss 1.3685e-04\n",
      "step 226, train_loss 1.3375e-04, test_loss 9.3903e-05\n",
      "step 227, train_loss 8.8061e-05, test_loss 3.1076e-05\n",
      "step 228, train_loss 2.6383e-05, test_loss 7.2875e-05\n",
      "step 229, train_loss 6.9088e-05, test_loss 1.0654e-04\n",
      "step 230, train_loss 1.0052e-04, test_loss 5.4897e-05\n",
      "step 231, train_loss 5.0802e-05, test_loss 3.3057e-05\n",
      "step 232, train_loss 2.8406e-05, test_loss 7.2646e-05\n",
      "step 233, train_loss 6.6844e-05, test_loss 7.6389e-05\n",
      "step 234, train_loss 7.2513e-05, test_loss 4.0507e-05\n",
      "step 235, train_loss 3.5144e-05, test_loss 3.6633e-05\n",
      "step 236, train_loss 3.1364e-05, test_loss 6.2219e-05\n",
      "step 237, train_loss 5.8134e-05, test_loss 6.0156e-05\n",
      "step 238, train_loss 5.4457e-05, test_loss 3.4276e-05\n",
      "step 239, train_loss 2.9620e-05, test_loss 3.6173e-05\n",
      "step 240, train_loss 3.1597e-05, test_loss 5.4583e-05\n",
      "step 241, train_loss 4.8990e-05, test_loss 4.8416e-05\n",
      "step 242, train_loss 4.4160e-05, test_loss 3.3040e-05\n",
      "step 243, train_loss 2.7965e-05, test_loss 3.5193e-05\n",
      "step 244, train_loss 3.0046e-05, test_loss 4.5734e-05\n",
      "step 245, train_loss 4.1481e-05, test_loss 4.3896e-05\n",
      "step 246, train_loss 3.8566e-05, test_loss 3.2291e-05\n",
      "step 247, train_loss 2.7673e-05, test_loss 3.2633e-05\n",
      "step 248, train_loss 2.8050e-05, test_loss 4.1032e-05\n",
      "step 249, train_loss 3.5800e-05, test_loss 3.9602e-05\n",
      "step 250, train_loss 3.5280e-05, test_loss 3.2990e-05\n",
      "step 251, train_loss 2.8015e-05, test_loss 3.1413e-05\n",
      "step 252, train_loss 2.6537e-05, test_loss 3.5879e-05\n",
      "step 253, train_loss 3.1461e-05, test_loss 3.8074e-05\n",
      "step 254, train_loss 3.2928e-05, test_loss 3.3145e-05\n",
      "step 255, train_loss 2.8616e-05, test_loss 3.0700e-05\n",
      "step 256, train_loss 2.5932e-05, test_loss 3.3291e-05\n",
      "step 257, train_loss 2.8289e-05, test_loss 3.5130e-05\n",
      "step 258, train_loss 3.0665e-05, test_loss 3.4115e-05\n",
      "step 259, train_loss 2.9068e-05, test_loss 3.0989e-05\n",
      "step 260, train_loss 2.6284e-05, test_loss 3.1064e-05\n",
      "step 261, train_loss 2.6363e-05, test_loss 3.3407e-05\n",
      "step 262, train_loss 2.8374e-05, test_loss 3.3355e-05\n",
      "step 263, train_loss 2.8797e-05, test_loss 3.2093e-05\n",
      "step 264, train_loss 2.7122e-05, test_loss 3.0660e-05\n",
      "step 265, train_loss 2.5869e-05, test_loss 3.1195e-05\n",
      "step 266, train_loss 2.6505e-05, test_loss 3.2650e-05\n",
      "step 267, train_loss 2.7651e-05, test_loss 3.2137e-05\n",
      "step 268, train_loss 2.7525e-05, test_loss 3.1322e-05\n",
      "step 269, train_loss 2.6412e-05, test_loss 3.0594e-05\n",
      "step 270, train_loss 2.5801e-05, test_loss 3.0953e-05\n",
      "step 271, train_loss 2.6263e-05, test_loss 3.1863e-05\n",
      "step 272, train_loss 2.6925e-05, test_loss 3.1469e-05\n",
      "step 273, train_loss 2.6841e-05, test_loss 3.1050e-05\n",
      "step 274, train_loss 2.6183e-05, test_loss 3.0510e-05\n",
      "step 275, train_loss 2.5753e-05, test_loss 3.0639e-05\n",
      "step 276, train_loss 2.5940e-05, test_loss 3.1232e-05\n",
      "step 277, train_loss 2.6357e-05, test_loss 3.1071e-05\n",
      "step 278, train_loss 2.6436e-05, test_loss 3.0963e-05\n",
      "step 279, train_loss 2.6115e-05, test_loss 3.0476e-05\n",
      "step 280, train_loss 2.5760e-05, test_loss 3.0439e-05\n",
      "step 281, train_loss 2.5710e-05, test_loss 3.0743e-05\n",
      "step 282, train_loss 2.5920e-05, test_loss 3.0751e-05\n",
      "step 283, train_loss 2.6094e-05, test_loss 3.0886e-05\n",
      "step 284, train_loss 2.6046e-05, test_loss 3.0518e-05\n",
      "step 285, train_loss 2.5829e-05, test_loss 3.0428e-05\n",
      "step 286, train_loss 2.5657e-05, test_loss 3.0422e-05\n",
      "step 287, train_loss 2.5649e-05, test_loss 3.0456e-05\n",
      "step 288, train_loss 2.5759e-05, test_loss 3.0675e-05\n",
      "step 289, train_loss 2.5854e-05, test_loss 3.0513e-05\n",
      "step 290, train_loss 2.5833e-05, test_loss 3.0528e-05\n",
      "step 291, train_loss 2.5727e-05, test_loss 3.0334e-05\n",
      "step 292, train_loss 2.5613e-05, test_loss 3.0312e-05\n",
      "step 293, train_loss 2.5569e-05, test_loss 3.0372e-05\n",
      "step 294, train_loss 2.5599e-05, test_loss 3.0349e-05\n",
      "step 295, train_loss 2.5653e-05, test_loss 3.0475e-05\n",
      "step 296, train_loss 2.5681e-05, test_loss 3.0342e-05\n",
      "step 297, train_loss 2.5654e-05, test_loss 3.0370e-05\n",
      "step 298, train_loss 2.5595e-05, test_loss 3.0244e-05\n",
      "step 299, train_loss 2.5533e-05, test_loss 3.0234e-05\n",
      "step 300, train_loss 2.5500e-05, test_loss 3.0241e-05\n",
      "step 301, train_loss 2.5498e-05, test_loss 3.0215e-05\n",
      "step 302, train_loss 2.5516e-05, test_loss 3.0294e-05\n",
      "step 303, train_loss 2.5534e-05, test_loss 3.0217e-05\n",
      "step 304, train_loss 2.5534e-05, test_loss 3.0275e-05\n",
      "step 305, train_loss 2.5517e-05, test_loss 3.0174e-05\n",
      "step 306, train_loss 2.5486e-05, test_loss 3.0192e-05\n",
      "step 307, train_loss 2.5454e-05, test_loss 3.0130e-05\n",
      "step 308, train_loss 2.5426e-05, test_loss 3.0125e-05\n",
      "step 309, train_loss 2.5410e-05, test_loss 3.0125e-05\n",
      "step 310, train_loss 2.5404e-05, test_loss 3.0099e-05\n",
      "step 311, train_loss 2.5404e-05, test_loss 3.0138e-05\n",
      "step 312, train_loss 2.5406e-05, test_loss 3.0087e-05\n",
      "step 313, train_loss 2.5405e-05, test_loss 3.0136e-05\n",
      "step 314, train_loss 2.5401e-05, test_loss 3.0069e-05\n",
      "step 315, train_loss 2.5391e-05, test_loss 3.0110e-05\n",
      "step 316, train_loss 2.5379e-05, test_loss 3.0042e-05\n",
      "step 317, train_loss 2.5363e-05, test_loss 3.0072e-05\n",
      "step 318, train_loss 2.5348e-05, test_loss 3.0013e-05\n",
      "step 319, train_loss 2.5332e-05, test_loss 3.0032e-05\n",
      "step 320, train_loss 2.5318e-05, test_loss 2.9988e-05\n",
      "step 321, train_loss 2.5303e-05, test_loss 2.9996e-05\n",
      "step 322, train_loss 2.5291e-05, test_loss 2.9965e-05\n",
      "step 323, train_loss 2.5279e-05, test_loss 2.9965e-05\n",
      "step 324, train_loss 2.5268e-05, test_loss 2.9944e-05\n",
      "step 325, train_loss 2.5258e-05, test_loss 2.9938e-05\n",
      "step 326, train_loss 2.5248e-05, test_loss 2.9924e-05\n",
      "step 327, train_loss 2.5238e-05, test_loss 2.9912e-05\n",
      "step 328, train_loss 2.5229e-05, test_loss 2.9904e-05\n",
      "step 329, train_loss 2.5219e-05, test_loss 2.9888e-05\n",
      "step 330, train_loss 2.5210e-05, test_loss 2.9884e-05\n",
      "step 331, train_loss 2.5201e-05, test_loss 2.9864e-05\n",
      "step 332, train_loss 2.5192e-05, test_loss 2.9866e-05\n",
      "step 333, train_loss 2.5183e-05, test_loss 2.9841e-05\n",
      "step 334, train_loss 2.5175e-05, test_loss 2.9852e-05\n",
      "step 335, train_loss 2.5169e-05, test_loss 2.9820e-05\n",
      "step 336, train_loss 2.5163e-05, test_loss 2.9849e-05\n",
      "step 337, train_loss 2.5161e-05, test_loss 2.9808e-05\n",
      "step 338, train_loss 2.5163e-05, test_loss 2.9875e-05\n",
      "step 339, train_loss 2.5177e-05, test_loss 2.9830e-05\n",
      "step 340, train_loss 2.5207e-05, test_loss 2.9996e-05\n",
      "step 341, train_loss 2.5276e-05, test_loss 2.9994e-05\n",
      "step 342, train_loss 2.5410e-05, test_loss 3.0456e-05\n",
      "step 343, train_loss 2.5688e-05, test_loss 3.0747e-05\n",
      "step 344, train_loss 2.6238e-05, test_loss 3.2237e-05\n",
      "step 345, train_loss 2.7371e-05, test_loss 3.4034e-05\n",
      "step 346, train_loss 2.9679e-05, test_loss 3.9599e-05\n",
      "step 347, train_loss 3.4525e-05, test_loss 4.8754e-05\n",
      "step 348, train_loss 4.4730e-05, test_loss 7.2163e-05\n",
      "step 349, train_loss 6.6649e-05, test_loss 1.1725e-04\n",
      "step 350, train_loss 1.1397e-04, test_loss 2.2320e-04\n",
      "step 351, train_loss 2.1678e-04, test_loss 4.3913e-04\n",
      "step 352, train_loss 4.3758e-04, test_loss 9.0188e-04\n",
      "step 353, train_loss 8.9378e-04, test_loss 1.7427e-03\n",
      "step 354, train_loss 1.7450e-03, test_loss 2.9955e-03\n",
      "step 355, train_loss 2.9853e-03, test_loss 3.9088e-03\n",
      "step 356, train_loss 3.9153e-03, test_loss 3.1995e-03\n",
      "step 357, train_loss 3.1887e-03, test_loss 1.0452e-03\n",
      "step 358, train_loss 1.0448e-03, test_loss 3.9150e-05\n",
      "step 359, train_loss 3.3686e-05, test_loss 1.1168e-03\n",
      "step 360, train_loss 1.1069e-03, test_loss 2.0864e-03\n",
      "step 361, train_loss 2.0882e-03, test_loss 1.2455e-03\n",
      "step 362, train_loss 1.2353e-03, test_loss 8.2212e-05\n",
      "step 363, train_loss 7.7012e-05, test_loss 4.9672e-04\n",
      "step 364, train_loss 4.9393e-04, test_loss 1.3101e-03\n",
      "step 365, train_loss 1.3000e-03, test_loss 8.2480e-04\n",
      "step 366, train_loss 8.2348e-04, test_loss 5.7715e-05\n",
      "step 367, train_loss 5.1352e-05, test_loss 3.8738e-04\n",
      "step 368, train_loss 3.7956e-04, test_loss 8.7371e-04\n",
      "step 369, train_loss 8.7319e-04, test_loss 4.6421e-04\n",
      "step 370, train_loss 4.5663e-04, test_loss 2.9992e-05\n",
      "step 371, train_loss 2.5264e-05, test_loss 3.5400e-04\n",
      "step 372, train_loss 3.5215e-04, test_loss 5.9040e-04\n",
      "step 373, train_loss 5.8306e-04, test_loss 2.1952e-04\n",
      "step 374, train_loss 2.1724e-04, test_loss 4.1890e-05\n",
      "step 375, train_loss 3.8123e-05, test_loss 3.2451e-04\n",
      "step 376, train_loss 3.1810e-04, test_loss 3.6934e-04\n",
      "step 377, train_loss 3.6793e-04, test_loss 9.5996e-05\n",
      "step 378, train_loss 9.0647e-05, test_loss 7.0986e-05\n",
      "step 379, train_loss 6.5803e-05, test_loss 2.6519e-04\n",
      "step 380, train_loss 2.6312e-04, test_loss 2.2388e-04\n",
      "step 381, train_loss 2.1760e-04, test_loss 4.3067e-05\n",
      "step 382, train_loss 3.9029e-05, test_loss 8.8070e-05\n",
      "step 383, train_loss 8.4527e-05, test_loss 2.0682e-04\n",
      "step 384, train_loss 2.0035e-04, test_loss 1.2780e-04\n",
      "step 385, train_loss 1.2444e-04, test_loss 3.0693e-05\n",
      "step 386, train_loss 2.5695e-05, test_loss 9.3742e-05\n",
      "step 387, train_loss 8.7757e-05, test_loss 1.4797e-04\n",
      "step 388, train_loss 1.4464e-04, test_loss 7.9350e-05\n",
      "step 389, train_loss 7.3458e-05, test_loss 3.0830e-05\n",
      "step 390, train_loss 2.5763e-05, test_loss 8.3544e-05\n",
      "step 391, train_loss 7.9697e-05, test_loss 1.0895e-04\n",
      "step 392, train_loss 1.0290e-04, test_loss 5.2407e-05\n",
      "step 393, train_loss 4.8261e-05, test_loss 3.2176e-05\n",
      "step 394, train_loss 2.7622e-05, test_loss 7.2910e-05\n",
      "step 395, train_loss 6.7303e-05, test_loss 7.8568e-05\n",
      "step 396, train_loss 7.4909e-05, test_loss 4.1915e-05\n",
      "step 397, train_loss 3.6811e-05, test_loss 3.2931e-05\n",
      "step 398, train_loss 2.8092e-05, test_loss 5.8945e-05\n",
      "step 399, train_loss 5.5174e-05, test_loss 6.2709e-05\n",
      "step 400, train_loss 5.7407e-05, test_loss 3.5991e-05\n",
      "step 401, train_loss 3.1844e-05, test_loss 3.1599e-05\n",
      "step 402, train_loss 2.7306e-05, test_loss 5.0422e-05\n",
      "step 403, train_loss 4.5292e-05, test_loss 5.0484e-05\n",
      "step 404, train_loss 4.6619e-05, test_loss 3.4658e-05\n",
      "step 405, train_loss 2.9806e-05, test_loss 3.0864e-05\n",
      "step 406, train_loss 2.6137e-05, test_loss 4.1896e-05\n",
      "step 407, train_loss 3.7817e-05, test_loss 4.4993e-05\n",
      "step 408, train_loss 3.9855e-05, test_loss 3.3375e-05\n",
      "step 409, train_loss 2.9029e-05, test_loss 2.9755e-05\n",
      "step 410, train_loss 2.5191e-05, test_loss 3.7488e-05\n",
      "step 411, train_loss 3.2440e-05, test_loss 3.9496e-05\n",
      "step 412, train_loss 3.5268e-05, test_loss 3.3754e-05\n",
      "step 413, train_loss 2.8789e-05, test_loss 2.9471e-05\n",
      "step 414, train_loss 2.4759e-05, test_loss 3.3082e-05\n",
      "step 415, train_loss 2.8666e-05, test_loss 3.6921e-05\n",
      "step 416, train_loss 3.1871e-05, test_loss 3.3014e-05\n",
      "step 417, train_loss 2.8611e-05, test_loss 2.9572e-05\n",
      "step 418, train_loss 2.4853e-05, test_loss 3.1059e-05\n",
      "step 419, train_loss 2.6236e-05, test_loss 3.3464e-05\n",
      "step 420, train_loss 2.9118e-05, test_loss 3.3127e-05\n",
      "step 421, train_loss 2.8245e-05, test_loss 2.9812e-05\n",
      "step 422, train_loss 2.5311e-05, test_loss 2.9475e-05\n",
      "step 423, train_loss 2.4950e-05, test_loss 3.1729e-05\n",
      "step 424, train_loss 2.6933e-05, test_loss 3.1852e-05\n",
      "step 425, train_loss 2.7503e-05, test_loss 3.0558e-05\n",
      "step 426, train_loss 2.5831e-05, test_loss 2.9189e-05\n",
      "step 427, train_loss 2.4623e-05, test_loss 2.9851e-05\n",
      "step 428, train_loss 2.5398e-05, test_loss 3.1227e-05\n",
      "step 429, train_loss 2.6465e-05, test_loss 3.0457e-05\n",
      "step 430, train_loss 2.6043e-05, test_loss 2.9549e-05\n",
      "step 431, train_loss 2.4890e-05, test_loss 2.9289e-05\n",
      "step 432, train_loss 2.4662e-05, test_loss 2.9862e-05\n",
      "step 433, train_loss 2.5392e-05, test_loss 3.0521e-05\n",
      "step 434, train_loss 2.5774e-05, test_loss 2.9731e-05\n",
      "step 435, train_loss 2.5241e-05, test_loss 2.9260e-05\n",
      "step 436, train_loss 2.4621e-05, test_loss 2.9353e-05\n",
      "step 437, train_loss 2.4694e-05, test_loss 2.9660e-05\n",
      "step 438, train_loss 2.5159e-05, test_loss 2.9986e-05\n",
      "step 439, train_loss 2.5262e-05, test_loss 2.9399e-05\n",
      "step 440, train_loss 2.4871e-05, test_loss 2.9162e-05\n",
      "step 441, train_loss 2.4541e-05, test_loss 2.9280e-05\n",
      "step 442, train_loss 2.4633e-05, test_loss 2.9415e-05\n",
      "step 443, train_loss 2.4904e-05, test_loss 2.9622e-05\n",
      "step 444, train_loss 2.4940e-05, test_loss 2.9224e-05\n",
      "step 445, train_loss 2.4697e-05, test_loss 2.9094e-05\n",
      "step 446, train_loss 2.4496e-05, test_loss 2.9151e-05\n",
      "step 447, train_loss 2.4538e-05, test_loss 2.9206e-05\n",
      "step 448, train_loss 2.4695e-05, test_loss 2.9378e-05\n",
      "step 449, train_loss 2.4735e-05, test_loss 2.9120e-05\n",
      "step 450, train_loss 2.4603e-05, test_loss 2.9051e-05\n",
      "step 451, train_loss 2.4465e-05, test_loss 2.9039e-05\n",
      "step 452, train_loss 2.4455e-05, test_loss 2.9061e-05\n",
      "step 453, train_loss 2.4541e-05, test_loss 2.9211e-05\n",
      "step 454, train_loss 2.4591e-05, test_loss 2.9055e-05\n",
      "step 455, train_loss 2.4538e-05, test_loss 2.9036e-05\n",
      "step 456, train_loss 2.4445e-05, test_loss 2.8969e-05\n",
      "step 457, train_loss 2.4403e-05, test_loss 2.8971e-05\n",
      "step 458, train_loss 2.4432e-05, test_loss 2.9081e-05\n",
      "step 459, train_loss 2.4477e-05, test_loss 2.8998e-05\n",
      "step 460, train_loss 2.4474e-05, test_loss 2.9022e-05\n",
      "step 461, train_loss 2.4427e-05, test_loss 2.8928e-05\n",
      "step 462, train_loss 2.4376e-05, test_loss 2.8920e-05\n",
      "step 463, train_loss 2.4363e-05, test_loss 2.8968e-05\n",
      "step 464, train_loss 2.4382e-05, test_loss 2.8929e-05\n",
      "step 465, train_loss 2.4399e-05, test_loss 2.8980e-05\n",
      "step 466, train_loss 2.4390e-05, test_loss 2.8893e-05\n",
      "step 467, train_loss 2.4358e-05, test_loss 2.8893e-05\n",
      "step 468, train_loss 2.4329e-05, test_loss 2.8876e-05\n",
      "step 469, train_loss 2.4318e-05, test_loss 2.8858e-05\n",
      "step 470, train_loss 2.4324e-05, test_loss 2.8902e-05\n",
      "step 471, train_loss 2.4331e-05, test_loss 2.8848e-05\n",
      "step 472, train_loss 2.4324e-05, test_loss 2.8870e-05\n",
      "step 473, train_loss 2.4306e-05, test_loss 2.8818e-05\n",
      "step 474, train_loss 2.4285e-05, test_loss 2.8815e-05\n",
      "step 475, train_loss 2.4273e-05, test_loss 2.8818e-05\n",
      "step 476, train_loss 2.4269e-05, test_loss 2.8794e-05\n",
      "step 477, train_loss 2.4270e-05, test_loss 2.8823e-05\n",
      "step 478, train_loss 2.4268e-05, test_loss 2.8779e-05\n",
      "step 479, train_loss 2.4258e-05, test_loss 2.8793e-05\n",
      "step 480, train_loss 2.4245e-05, test_loss 2.8761e-05\n",
      "step 481, train_loss 2.4232e-05, test_loss 2.8756e-05\n",
      "step 482, train_loss 2.4223e-05, test_loss 2.8757e-05\n",
      "step 483, train_loss 2.4218e-05, test_loss 2.8737e-05\n",
      "step 484, train_loss 2.4215e-05, test_loss 2.8754e-05\n",
      "step 485, train_loss 2.4211e-05, test_loss 2.8721e-05\n",
      "step 486, train_loss 2.4203e-05, test_loss 2.8732e-05\n",
      "step 487, train_loss 2.4194e-05, test_loss 2.8704e-05\n",
      "step 488, train_loss 2.4183e-05, test_loss 2.8703e-05\n",
      "step 489, train_loss 2.4174e-05, test_loss 2.8694e-05\n",
      "step 490, train_loss 2.4167e-05, test_loss 2.8680e-05\n",
      "step 491, train_loss 2.4161e-05, test_loss 2.8685e-05\n",
      "step 492, train_loss 2.4156e-05, test_loss 2.8662e-05\n",
      "step 493, train_loss 2.4150e-05, test_loss 2.8671e-05\n",
      "step 494, train_loss 2.4143e-05, test_loss 2.8645e-05\n",
      "step 495, train_loss 2.4135e-05, test_loss 2.8648e-05\n",
      "step 496, train_loss 2.4127e-05, test_loss 2.8630e-05\n",
      "step 497, train_loss 2.4118e-05, test_loss 2.8625e-05\n",
      "step 498, train_loss 2.4111e-05, test_loss 2.8617e-05\n",
      "step 499, train_loss 2.4104e-05, test_loss 2.8605e-05\n",
      "step 500, train_loss 2.4097e-05, test_loss 2.8605e-05\n",
      "step 501, train_loss 2.4091e-05, test_loss 2.8587e-05\n",
      "step 502, train_loss 2.4085e-05, test_loss 2.8591e-05\n",
      "step 503, train_loss 2.4078e-05, test_loss 2.8571e-05\n",
      "step 504, train_loss 2.4071e-05, test_loss 2.8573e-05\n",
      "step 505, train_loss 2.4064e-05, test_loss 2.8555e-05\n",
      "step 506, train_loss 2.4056e-05, test_loss 2.8554e-05\n",
      "step 507, train_loss 2.4049e-05, test_loss 2.8541e-05\n",
      "step 508, train_loss 2.4042e-05, test_loss 2.8535e-05\n",
      "step 509, train_loss 2.4035e-05, test_loss 2.8527e-05\n",
      "step 510, train_loss 2.4028e-05, test_loss 2.8517e-05\n",
      "step 511, train_loss 2.4021e-05, test_loss 2.8513e-05\n",
      "step 512, train_loss 2.4015e-05, test_loss 2.8500e-05\n",
      "step 513, train_loss 2.4008e-05, test_loss 2.8498e-05\n",
      "step 514, train_loss 2.4002e-05, test_loss 2.8483e-05\n",
      "step 515, train_loss 2.3995e-05, test_loss 2.8483e-05\n",
      "step 516, train_loss 2.3988e-05, test_loss 2.8467e-05\n",
      "step 517, train_loss 2.3982e-05, test_loss 2.8467e-05\n",
      "step 518, train_loss 2.3975e-05, test_loss 2.8451e-05\n",
      "step 519, train_loss 2.3968e-05, test_loss 2.8451e-05\n",
      "step 520, train_loss 2.3961e-05, test_loss 2.8434e-05\n",
      "step 521, train_loss 2.3954e-05, test_loss 2.8434e-05\n",
      "step 522, train_loss 2.3948e-05, test_loss 2.8418e-05\n",
      "step 523, train_loss 2.3941e-05, test_loss 2.8419e-05\n",
      "step 524, train_loss 2.3934e-05, test_loss 2.8402e-05\n",
      "step 525, train_loss 2.3928e-05, test_loss 2.8403e-05\n",
      "step 526, train_loss 2.3921e-05, test_loss 2.8386e-05\n",
      "step 527, train_loss 2.3915e-05, test_loss 2.8389e-05\n",
      "step 528, train_loss 2.3908e-05, test_loss 2.8370e-05\n",
      "step 529, train_loss 2.3902e-05, test_loss 2.8375e-05\n",
      "step 530, train_loss 2.3896e-05, test_loss 2.8354e-05\n",
      "step 531, train_loss 2.3890e-05, test_loss 2.8364e-05\n",
      "step 532, train_loss 2.3885e-05, test_loss 2.8338e-05\n",
      "step 533, train_loss 2.3880e-05, test_loss 2.8357e-05\n",
      "step 534, train_loss 2.3877e-05, test_loss 2.8325e-05\n",
      "step 535, train_loss 2.3875e-05, test_loss 2.8361e-05\n",
      "step 536, train_loss 2.3876e-05, test_loss 2.8321e-05\n",
      "step 537, train_loss 2.3881e-05, test_loss 2.8388e-05\n",
      "step 538, train_loss 2.3895e-05, test_loss 2.8344e-05\n",
      "step 539, train_loss 2.3921e-05, test_loss 2.8480e-05\n",
      "step 540, train_loss 2.3971e-05, test_loss 2.8453e-05\n",
      "step 541, train_loss 2.4057e-05, test_loss 2.8756e-05\n",
      "step 542, train_loss 2.4217e-05, test_loss 2.8845e-05\n",
      "step 543, train_loss 2.4496e-05, test_loss 2.9601e-05\n",
      "step 544, train_loss 2.5006e-05, test_loss 3.0185e-05\n",
      "step 545, train_loss 2.5921e-05, test_loss 3.2318e-05\n",
      "step 546, train_loss 2.7616e-05, test_loss 3.4849e-05\n",
      "step 547, train_loss 3.0741e-05, test_loss 4.1544e-05\n",
      "step 548, train_loss 3.6641e-05, test_loss 5.1612e-05\n",
      "step 549, train_loss 4.7808e-05, test_loss 7.4583e-05\n",
      "step 550, train_loss 6.9298e-05, test_loss 1.1403e-04\n",
      "step 551, train_loss 1.1084e-04, test_loss 1.9781e-04\n",
      "step 552, train_loss 1.9181e-04, test_loss 3.5114e-04\n",
      "step 553, train_loss 3.4922e-04, test_loss 6.5900e-04\n",
      "step 554, train_loss 6.5175e-04, test_loss 1.2115e-03\n",
      "step 555, train_loss 1.2122e-03, test_loss 2.1767e-03\n",
      "step 556, train_loss 2.1677e-03, test_loss 3.5215e-03\n",
      "step 557, train_loss 3.5269e-03, test_loss 4.7906e-03\n",
      "step 558, train_loss 4.7801e-03, test_loss 4.7175e-03\n",
      "step 559, train_loss 4.7243e-03, test_loss 2.7303e-03\n",
      "step 560, train_loss 2.7196e-03, test_loss 4.6107e-04\n",
      "step 561, train_loss 4.5779e-04, test_loss 2.3782e-04\n",
      "step 562, train_loss 2.3327e-04, test_loss 1.7103e-03\n",
      "step 563, train_loss 1.6994e-03, test_loss 2.4579e-03\n",
      "step 564, train_loss 2.4594e-03, test_loss 1.3770e-03\n",
      "step 565, train_loss 1.3665e-03, test_loss 1.1242e-04\n",
      "step 566, train_loss 1.0719e-04, test_loss 4.2602e-04\n",
      "step 567, train_loss 4.2274e-04, test_loss 1.3873e-03\n",
      "step 568, train_loss 1.3776e-03, test_loss 1.2128e-03\n",
      "step 569, train_loss 1.2127e-03, test_loss 2.6912e-04\n",
      "step 570, train_loss 2.6215e-04, test_loss 1.1965e-04\n",
      "step 571, train_loss 1.1369e-04, test_loss 7.5842e-04\n",
      "step 572, train_loss 7.5801e-04, test_loss 8.7802e-04\n",
      "step 573, train_loss 8.7061e-04, test_loss 2.7367e-04\n",
      "step 574, train_loss 2.7187e-04, test_loss 4.8097e-05\n",
      "step 575, train_loss 4.4791e-05, test_loss 4.4857e-04\n",
      "step 576, train_loss 4.4234e-04, test_loss 5.9448e-04\n",
      "step 577, train_loss 5.9414e-04, test_loss 2.2976e-04\n",
      "step 578, train_loss 2.2412e-04, test_loss 3.3266e-05\n",
      "step 579, train_loss 2.8931e-05, test_loss 2.7564e-04\n",
      "step 580, train_loss 2.7371e-04, test_loss 4.0874e-04\n",
      "step 581, train_loss 4.0213e-04, test_loss 1.7425e-04\n",
      "step 582, train_loss 1.7145e-04, test_loss 2.9528e-05\n",
      "step 583, train_loss 2.5017e-05, test_loss 1.8327e-04\n",
      "step 584, train_loss 1.7696e-04, test_loss 2.7706e-04\n",
      "step 585, train_loss 2.7444e-04, test_loss 1.3676e-04\n",
      "step 586, train_loss 1.3052e-04, test_loss 2.9192e-05\n",
      "step 587, train_loss 2.4161e-05, test_loss 1.2089e-04\n",
      "step 588, train_loss 1.1723e-04, test_loss 1.9653e-04\n",
      "step 589, train_loss 1.8999e-04, test_loss 1.0564e-04\n",
      "step 590, train_loss 1.0196e-04, test_loss 2.9040e-05\n",
      "step 591, train_loss 2.4156e-05, test_loss 8.4099e-05\n",
      "step 592, train_loss 7.8429e-05, test_loss 1.3657e-04\n",
      "step 593, train_loss 1.3339e-04, test_loss 8.8259e-05\n",
      "step 594, train_loss 8.2746e-05, test_loss 2.9337e-05\n",
      "step 595, train_loss 2.5018e-05, test_loss 5.6785e-05\n",
      "step 596, train_loss 5.3126e-05, test_loss 1.0036e-04\n",
      "step 597, train_loss 9.4970e-05, test_loss 7.2771e-05\n",
      "step 598, train_loss 6.9390e-05, test_loss 3.1291e-05\n",
      "step 599, train_loss 2.6784e-05, test_loss 4.2158e-05\n",
      "step 600, train_loss 3.7400e-05, test_loss 7.1743e-05\n",
      "step 601, train_loss 6.8346e-05, test_loss 6.4374e-05\n",
      "step 602, train_loss 5.9285e-05, test_loss 3.3061e-05\n",
      "step 603, train_loss 2.8989e-05, test_loss 3.2656e-05\n",
      "step 604, train_loss 2.8525e-05, test_loss 5.4988e-05\n",
      "step 605, train_loss 4.9871e-05, test_loss 5.4598e-05\n",
      "step 606, train_loss 5.0785e-05, test_loss 3.5997e-05\n",
      "step 607, train_loss 3.1097e-05, test_loss 2.9272e-05\n",
      "step 608, train_loss 2.4575e-05, test_loss 4.1403e-05\n",
      "step 609, train_loss 3.7289e-05, test_loss 4.8396e-05\n",
      "step 610, train_loss 4.3218e-05, test_loss 3.6651e-05\n",
      "step 611, train_loss 3.2425e-05, test_loss 2.8472e-05\n",
      "step 612, train_loss 2.3837e-05, test_loss 3.4219e-05\n",
      "step 613, train_loss 2.9324e-05, test_loss 4.0438e-05\n",
      "step 614, train_loss 3.6339e-05, test_loss 3.7430e-05\n",
      "step 615, train_loss 3.2506e-05, test_loss 2.9222e-05\n",
      "step 616, train_loss 2.4843e-05, test_loss 2.9406e-05\n",
      "step 617, train_loss 2.5068e-05, test_loss 3.5347e-05\n",
      "step 618, train_loss 3.0547e-05, test_loss 3.5263e-05\n",
      "step 619, train_loss 3.1180e-05, test_loss 3.0928e-05\n",
      "step 620, train_loss 2.6293e-05, test_loss 2.8146e-05\n",
      "step 621, train_loss 2.3712e-05, test_loss 3.0553e-05\n",
      "step 622, train_loss 2.6355e-05, test_loss 3.3546e-05\n",
      "step 623, train_loss 2.8842e-05, test_loss 3.1273e-05\n",
      "step 624, train_loss 2.7098e-05, test_loss 2.8636e-05\n",
      "step 625, train_loss 2.4123e-05, test_loss 2.8669e-05\n",
      "step 626, train_loss 2.4143e-05, test_loss 3.0502e-05\n",
      "step 627, train_loss 2.6263e-05, test_loss 3.1468e-05\n",
      "step 628, train_loss 2.6779e-05, test_loss 2.9330e-05\n",
      "step 629, train_loss 2.5007e-05, test_loss 2.8183e-05\n",
      "step 630, train_loss 2.3681e-05, test_loss 2.8983e-05\n",
      "step 631, train_loss 2.4381e-05, test_loss 2.9885e-05\n",
      "step 632, train_loss 2.5568e-05, test_loss 3.0023e-05\n",
      "step 633, train_loss 2.5356e-05, test_loss 2.8554e-05\n",
      "step 634, train_loss 2.4147e-05, test_loss 2.8134e-05\n",
      "step 635, train_loss 2.3654e-05, test_loss 2.8878e-05\n",
      "step 636, train_loss 2.4285e-05, test_loss 2.9207e-05\n",
      "step 637, train_loss 2.4870e-05, test_loss 2.9145e-05\n",
      "step 638, train_loss 2.4547e-05, test_loss 2.8224e-05\n",
      "step 639, train_loss 2.3818e-05, test_loss 2.8070e-05\n",
      "step 640, train_loss 2.3636e-05, test_loss 2.8596e-05\n",
      "step 641, train_loss 2.4060e-05, test_loss 2.8688e-05\n",
      "step 642, train_loss 2.4359e-05, test_loss 2.8652e-05\n",
      "step 643, train_loss 2.4121e-05, test_loss 2.8080e-05\n",
      "step 644, train_loss 2.3688e-05, test_loss 2.8008e-05\n",
      "step 645, train_loss 2.3595e-05, test_loss 2.8347e-05\n",
      "step 646, train_loss 2.3847e-05, test_loss 2.8371e-05\n",
      "step 647, train_loss 2.4026e-05, test_loss 2.8406e-05\n",
      "step 648, train_loss 2.3896e-05, test_loss 2.8036e-05\n",
      "step 649, train_loss 2.3636e-05, test_loss 2.7986e-05\n",
      "step 650, train_loss 2.3555e-05, test_loss 2.8179e-05\n",
      "step 651, train_loss 2.3688e-05, test_loss 2.8190e-05\n",
      "step 652, train_loss 2.3811e-05, test_loss 2.8273e-05\n",
      "step 653, train_loss 2.3764e-05, test_loss 2.8022e-05\n",
      "step 654, train_loss 2.3608e-05, test_loss 2.7977e-05\n",
      "step 655, train_loss 2.3526e-05, test_loss 2.8056e-05\n",
      "step 656, train_loss 2.3577e-05, test_loss 2.8059e-05\n",
      "step 657, train_loss 2.3660e-05, test_loss 2.8160e-05\n",
      "step 658, train_loss 2.3665e-05, test_loss 2.7989e-05\n",
      "step 659, train_loss 2.3582e-05, test_loss 2.7958e-05\n",
      "step 660, train_loss 2.3506e-05, test_loss 2.7953e-05\n",
      "step 661, train_loss 2.3503e-05, test_loss 2.7950e-05\n",
      "step 662, train_loss 2.3549e-05, test_loss 2.8045e-05\n",
      "step 663, train_loss 2.3576e-05, test_loss 2.7939e-05\n",
      "step 664, train_loss 2.3546e-05, test_loss 2.7937e-05\n",
      "step 665, train_loss 2.3493e-05, test_loss 2.7885e-05\n",
      "step 666, train_loss 2.3463e-05, test_loss 2.7878e-05\n",
      "step 667, train_loss 2.3473e-05, test_loss 2.7945e-05\n",
      "step 668, train_loss 2.3498e-05, test_loss 2.7890e-05\n",
      "step 669, train_loss 2.3500e-05, test_loss 2.7919e-05\n",
      "step 670, train_loss 2.3476e-05, test_loss 2.7852e-05\n",
      "step 671, train_loss 2.3445e-05, test_loss 2.7849e-05\n",
      "step 672, train_loss 2.3431e-05, test_loss 2.7871e-05\n",
      "step 673, train_loss 2.3438e-05, test_loss 2.7846e-05\n",
      "step 674, train_loss 2.3448e-05, test_loss 2.7887e-05\n",
      "step 675, train_loss 2.3446e-05, test_loss 2.7831e-05\n",
      "step 676, train_loss 2.3430e-05, test_loss 2.7839e-05\n",
      "step 677, train_loss 2.3411e-05, test_loss 2.7819e-05\n",
      "step 678, train_loss 2.3401e-05, test_loss 2.7808e-05\n",
      "step 679, train_loss 2.3401e-05, test_loss 2.7834e-05\n",
      "step 680, train_loss 2.3404e-05, test_loss 2.7799e-05\n",
      "step 681, train_loss 2.3401e-05, test_loss 2.7818e-05\n",
      "step 682, train_loss 2.3392e-05, test_loss 2.7780e-05\n",
      "step 683, train_loss 2.3378e-05, test_loss 2.7779e-05\n",
      "step 684, train_loss 2.3369e-05, test_loss 2.7776e-05\n",
      "step 685, train_loss 2.3364e-05, test_loss 2.7759e-05\n",
      "step 686, train_loss 2.3363e-05, test_loss 2.7776e-05\n",
      "step 687, train_loss 2.3361e-05, test_loss 2.7746e-05\n",
      "step 688, train_loss 2.3355e-05, test_loss 2.7756e-05\n",
      "step 689, train_loss 2.3347e-05, test_loss 2.7733e-05\n",
      "step 690, train_loss 2.3338e-05, test_loss 2.7730e-05\n",
      "step 691, train_loss 2.3331e-05, test_loss 2.7729e-05\n",
      "step 692, train_loss 2.3327e-05, test_loss 2.7714e-05\n",
      "step 693, train_loss 2.3324e-05, test_loss 2.7725e-05\n",
      "step 694, train_loss 2.3320e-05, test_loss 2.7702e-05\n",
      "step 695, train_loss 2.3314e-05, test_loss 2.7709e-05\n",
      "step 696, train_loss 2.3308e-05, test_loss 2.7692e-05\n",
      "step 697, train_loss 2.3301e-05, test_loss 2.7689e-05\n",
      "step 698, train_loss 2.3295e-05, test_loss 2.7685e-05\n",
      "step 699, train_loss 2.3290e-05, test_loss 2.7673e-05\n",
      "step 700, train_loss 2.3286e-05, test_loss 2.7678e-05\n",
      "step 701, train_loss 2.3282e-05, test_loss 2.7660e-05\n",
      "step 702, train_loss 2.3277e-05, test_loss 2.7665e-05\n",
      "step 703, train_loss 2.3271e-05, test_loss 2.7648e-05\n",
      "step 704, train_loss 2.3265e-05, test_loss 2.7647e-05\n",
      "step 705, train_loss 2.3259e-05, test_loss 2.7638e-05\n",
      "step 706, train_loss 2.3253e-05, test_loss 2.7630e-05\n",
      "step 707, train_loss 2.3248e-05, test_loss 2.7629e-05\n",
      "step 708, train_loss 2.3244e-05, test_loss 2.7616e-05\n",
      "step 709, train_loss 2.3239e-05, test_loss 2.7617e-05\n",
      "step 710, train_loss 2.3234e-05, test_loss 2.7603e-05\n",
      "step 711, train_loss 2.3228e-05, test_loss 2.7603e-05\n",
      "step 712, train_loss 2.3223e-05, test_loss 2.7592e-05\n",
      "step 713, train_loss 2.3217e-05, test_loss 2.7588e-05\n",
      "step 714, train_loss 2.3212e-05, test_loss 2.7582e-05\n",
      "step 715, train_loss 2.3207e-05, test_loss 2.7574e-05\n",
      "step 716, train_loss 2.3202e-05, test_loss 2.7572e-05\n",
      "step 717, train_loss 2.3197e-05, test_loss 2.7561e-05\n",
      "step 718, train_loss 2.3192e-05, test_loss 2.7561e-05\n",
      "step 719, train_loss 2.3187e-05, test_loss 2.7549e-05\n",
      "step 720, train_loss 2.3182e-05, test_loss 2.7548e-05\n",
      "step 721, train_loss 2.3177e-05, test_loss 2.7537e-05\n",
      "step 722, train_loss 2.3172e-05, test_loss 2.7534e-05\n",
      "step 723, train_loss 2.3167e-05, test_loss 2.7526e-05\n",
      "step 724, train_loss 2.3161e-05, test_loss 2.7521e-05\n",
      "step 725, train_loss 2.3156e-05, test_loss 2.7515e-05\n",
      "step 726, train_loss 2.3151e-05, test_loss 2.7507e-05\n",
      "step 727, train_loss 2.3146e-05, test_loss 2.7503e-05\n",
      "step 728, train_loss 2.3141e-05, test_loss 2.7494e-05\n",
      "step 729, train_loss 2.3136e-05, test_loss 2.7491e-05\n",
      "step 730, train_loss 2.3131e-05, test_loss 2.7482e-05\n",
      "step 731, train_loss 2.3126e-05, test_loss 2.7479e-05\n",
      "step 732, train_loss 2.3121e-05, test_loss 2.7470e-05\n",
      "step 733, train_loss 2.3116e-05, test_loss 2.7467e-05\n",
      "step 734, train_loss 2.3111e-05, test_loss 2.7458e-05\n",
      "step 735, train_loss 2.3106e-05, test_loss 2.7454e-05\n",
      "step 736, train_loss 2.3101e-05, test_loss 2.7446e-05\n",
      "step 737, train_loss 2.3096e-05, test_loss 2.7441e-05\n",
      "step 738, train_loss 2.3091e-05, test_loss 2.7435e-05\n",
      "step 739, train_loss 2.3085e-05, test_loss 2.7429e-05\n",
      "step 740, train_loss 2.3081e-05, test_loss 2.7423e-05\n",
      "step 741, train_loss 2.3076e-05, test_loss 2.7417e-05\n",
      "step 742, train_loss 2.3070e-05, test_loss 2.7411e-05\n",
      "step 743, train_loss 2.3066e-05, test_loss 2.7404e-05\n",
      "step 744, train_loss 2.3061e-05, test_loss 2.7400e-05\n",
      "step 745, train_loss 2.3056e-05, test_loss 2.7392e-05\n",
      "step 746, train_loss 2.3051e-05, test_loss 2.7388e-05\n",
      "step 747, train_loss 2.3046e-05, test_loss 2.7380e-05\n",
      "step 748, train_loss 2.3041e-05, test_loss 2.7376e-05\n",
      "step 749, train_loss 2.3036e-05, test_loss 2.7368e-05\n",
      "step 750, train_loss 2.3031e-05, test_loss 2.7364e-05\n",
      "step 751, train_loss 2.3026e-05, test_loss 2.7355e-05\n",
      "step 752, train_loss 2.3021e-05, test_loss 2.7353e-05\n",
      "step 753, train_loss 2.3016e-05, test_loss 2.7343e-05\n",
      "step 754, train_loss 2.3011e-05, test_loss 2.7341e-05\n",
      "step 755, train_loss 2.3006e-05, test_loss 2.7331e-05\n",
      "step 756, train_loss 2.3001e-05, test_loss 2.7330e-05\n",
      "step 757, train_loss 2.2996e-05, test_loss 2.7318e-05\n",
      "step 758, train_loss 2.2992e-05, test_loss 2.7320e-05\n",
      "step 759, train_loss 2.2987e-05, test_loss 2.7306e-05\n",
      "step 760, train_loss 2.2982e-05, test_loss 2.7310e-05\n",
      "step 761, train_loss 2.2978e-05, test_loss 2.7293e-05\n",
      "step 762, train_loss 2.2974e-05, test_loss 2.7303e-05\n",
      "step 763, train_loss 2.2971e-05, test_loss 2.7282e-05\n",
      "step 764, train_loss 2.2967e-05, test_loss 2.7300e-05\n",
      "step 765, train_loss 2.2966e-05, test_loss 2.7273e-05\n",
      "step 766, train_loss 2.2966e-05, test_loss 2.7308e-05\n",
      "step 767, train_loss 2.2969e-05, test_loss 2.7274e-05\n",
      "step 768, train_loss 2.2977e-05, test_loss 2.7343e-05\n",
      "step 769, train_loss 2.2995e-05, test_loss 2.7306e-05\n",
      "step 770, train_loss 2.3026e-05, test_loss 2.7449e-05\n",
      "step 771, train_loss 2.3085e-05, test_loss 2.7438e-05\n",
      "step 772, train_loss 2.3185e-05, test_loss 2.7762e-05\n",
      "step 773, train_loss 2.3366e-05, test_loss 2.7889e-05\n",
      "step 774, train_loss 2.3682e-05, test_loss 2.8705e-05\n",
      "step 775, train_loss 2.4253e-05, test_loss 2.9392e-05\n",
      "step 776, train_loss 2.5268e-05, test_loss 3.1676e-05\n",
      "step 777, train_loss 2.7121e-05, test_loss 3.4463e-05\n",
      "step 778, train_loss 3.0491e-05, test_loss 4.1486e-05\n",
      "step 779, train_loss 3.6738e-05, test_loss 5.2027e-05\n",
      "step 780, train_loss 4.8342e-05, test_loss 7.5299e-05\n",
      "step 781, train_loss 7.0193e-05, test_loss 1.1460e-04\n",
      "step 782, train_loss 1.1148e-04, test_loss 1.9585e-04\n",
      "step 783, train_loss 1.9009e-04, test_loss 3.4155e-04\n",
      "step 784, train_loss 3.3958e-04, test_loss 6.2902e-04\n",
      "step 785, train_loss 6.2213e-04, test_loss 1.1431e-03\n",
      "step 786, train_loss 1.1435e-03, test_loss 2.0649e-03\n",
      "step 787, train_loss 2.0564e-03, test_loss 3.4777e-03\n",
      "step 788, train_loss 3.4826e-03, test_loss 5.2380e-03\n",
      "step 789, train_loss 5.2279e-03, test_loss 6.3143e-03\n",
      "step 790, train_loss 6.3229e-03, test_loss 5.3335e-03\n",
      "step 791, train_loss 5.3223e-03, test_loss 2.3590e-03\n",
      "step 792, train_loss 2.3599e-03, test_loss 1.6092e-04\n",
      "step 793, train_loss 1.5246e-04, test_loss 7.1193e-04\n",
      "step 794, train_loss 7.0177e-04, test_loss 2.5525e-03\n",
      "step 795, train_loss 2.5531e-03, test_loss 2.8712e-03\n",
      "step 796, train_loss 2.8593e-03, test_loss 1.1897e-03\n",
      "step 797, train_loss 1.1878e-03, test_loss 3.6507e-05\n",
      "step 798, train_loss 2.9714e-05, test_loss 8.0213e-04\n",
      "step 799, train_loss 7.9319e-04, test_loss 1.7739e-03\n",
      "step 800, train_loss 1.7748e-03, test_loss 1.2458e-03\n",
      "step 801, train_loss 1.2374e-03, test_loss 1.5961e-04\n",
      "step 802, train_loss 1.5667e-04, test_loss 2.5418e-04\n",
      "step 803, train_loss 2.5215e-04, test_loss 1.0265e-03\n",
      "step 804, train_loss 1.0196e-03, test_loss 9.3906e-04\n",
      "step 805, train_loss 9.3988e-04, test_loss 2.0789e-04\n",
      "step 806, train_loss 2.0285e-04, test_loss 1.0590e-04\n",
      "step 807, train_loss 1.0133e-04, test_loss 6.0749e-04\n",
      "step 808, train_loss 6.0726e-04, test_loss 6.5837e-04\n",
      "step 809, train_loss 6.5187e-04, test_loss 1.7827e-04\n",
      "step 810, train_loss 1.7587e-04, test_loss 6.0382e-05\n",
      "step 811, train_loss 5.6823e-05, test_loss 3.9036e-04\n",
      "step 812, train_loss 3.8367e-04, test_loss 4.4305e-04\n",
      "step 813, train_loss 4.4113e-04, test_loss 1.3947e-04\n",
      "step 814, train_loss 1.3327e-04, test_loss 4.7595e-05\n",
      "step 815, train_loss 4.1978e-05, test_loss 2.5800e-04\n",
      "step 816, train_loss 2.5494e-04, test_loss 3.0640e-04\n",
      "step 817, train_loss 2.9934e-04, test_loss 1.0202e-04\n",
      "step 818, train_loss 9.8069e-05, test_loss 3.9235e-05\n",
      "step 819, train_loss 3.4667e-05, test_loss 1.8038e-04\n",
      "step 820, train_loss 1.7407e-04, test_loss 2.0868e-04\n",
      "step 821, train_loss 2.0581e-04, test_loss 7.9617e-05\n",
      "step 822, train_loss 7.4199e-05, test_loss 3.4412e-05\n",
      "step 823, train_loss 2.9689e-05, test_loss 1.2348e-04\n",
      "step 824, train_loss 1.2051e-04, test_loss 1.5031e-04\n",
      "step 825, train_loss 1.4483e-04, test_loss 6.2741e-05\n",
      "step 826, train_loss 5.9411e-05, test_loss 3.0191e-05\n",
      "step 827, train_loss 2.6335e-05, test_loss 8.9690e-05\n",
      "step 828, train_loss 8.4665e-05, test_loss 1.0762e-04\n",
      "step 829, train_loss 1.0469e-04, test_loss 5.5022e-05\n",
      "step 830, train_loss 5.0214e-05, test_loss 2.8641e-05\n",
      "step 831, train_loss 2.4262e-05, test_loss 6.4220e-05\n",
      "step 832, train_loss 6.0689e-05, test_loss 8.3280e-05\n",
      "step 833, train_loss 7.7979e-05, test_loss 4.8139e-05\n",
      "step 834, train_loss 4.4246e-05, test_loss 2.7846e-05\n",
      "step 835, train_loss 2.3348e-05, test_loss 5.0177e-05\n",
      "step 836, train_loss 4.5011e-05, test_loss 6.3702e-05\n",
      "step 837, train_loss 5.9870e-05, test_loss 4.5308e-05\n",
      "step 838, train_loss 4.0176e-05, test_loss 2.7848e-05\n",
      "step 839, train_loss 2.3260e-05, test_loss 3.8992e-05\n",
      "step 840, train_loss 3.4843e-05, test_loss 5.2432e-05\n",
      "step 841, train_loss 4.7286e-05, test_loss 4.1029e-05\n",
      "step 842, train_loss 3.7006e-05, test_loss 2.8236e-05\n",
      "step 843, train_loss 2.3692e-05, test_loss 3.3225e-05\n",
      "step 844, train_loss 2.8533e-05, test_loss 4.2199e-05\n",
      "step 845, train_loss 3.8337e-05, test_loss 3.9073e-05\n",
      "step 846, train_loss 3.4333e-05, test_loss 2.8616e-05\n",
      "step 847, train_loss 2.4457e-05, test_loss 2.9120e-05\n",
      "step 848, train_loss 2.5001e-05, test_loss 3.6702e-05\n",
      "step 849, train_loss 3.2043e-05, test_loss 3.5767e-05\n",
      "step 850, train_loss 3.1842e-05, test_loss 2.9757e-05\n",
      "step 851, train_loss 2.5257e-05, test_loss 2.7837e-05\n",
      "step 852, train_loss 2.3425e-05, test_loss 3.1821e-05\n",
      "step 853, train_loss 2.7729e-05, test_loss 3.4175e-05\n",
      "step 854, train_loss 2.9473e-05, test_loss 2.9993e-05\n",
      "step 855, train_loss 2.5786e-05, test_loss 2.7532e-05\n",
      "step 856, train_loss 2.3090e-05, test_loss 2.9650e-05\n",
      "step 857, train_loss 2.5029e-05, test_loss 3.1461e-05\n",
      "step 858, train_loss 2.7262e-05, test_loss 3.0537e-05\n",
      "step 859, train_loss 2.5872e-05, test_loss 2.7767e-05\n",
      "step 860, train_loss 2.3381e-05, test_loss 2.7935e-05\n",
      "step 861, train_loss 2.3578e-05, test_loss 3.0001e-05\n",
      "step 862, train_loss 2.5381e-05, test_loss 2.9684e-05\n",
      "step 863, train_loss 2.5461e-05, test_loss 2.8316e-05\n",
      "step 864, train_loss 2.3807e-05, test_loss 2.7460e-05\n",
      "step 865, train_loss 2.3058e-05, test_loss 2.8245e-05\n",
      "step 866, train_loss 2.3997e-05, test_loss 2.9252e-05\n",
      "step 867, train_loss 2.4731e-05, test_loss 2.8273e-05\n",
      "step 868, train_loss 2.4047e-05, test_loss 2.7492e-05\n",
      "step 869, train_loss 2.3107e-05, test_loss 2.7634e-05\n",
      "step 870, train_loss 2.3229e-05, test_loss 2.8156e-05\n",
      "step 871, train_loss 2.3927e-05, test_loss 2.8455e-05\n",
      "step 872, train_loss 2.3980e-05, test_loss 2.7631e-05\n",
      "step 873, train_loss 2.3343e-05, test_loss 2.7362e-05\n",
      "step 874, train_loss 2.2997e-05, test_loss 2.7761e-05\n",
      "step 875, train_loss 2.3316e-05, test_loss 2.7935e-05\n",
      "step 876, train_loss 2.3654e-05, test_loss 2.7950e-05\n",
      "step 877, train_loss 2.3476e-05, test_loss 2.7431e-05\n",
      "step 878, train_loss 2.3077e-05, test_loss 2.7387e-05\n",
      "step 879, train_loss 2.3015e-05, test_loss 2.7730e-05\n",
      "step 880, train_loss 2.3270e-05, test_loss 2.7699e-05\n",
      "step 881, train_loss 2.3387e-05, test_loss 2.7643e-05\n",
      "step 882, train_loss 2.3197e-05, test_loss 2.7347e-05\n",
      "step 883, train_loss 2.2982e-05, test_loss 2.7358e-05\n",
      "step 884, train_loss 2.3009e-05, test_loss 2.7594e-05\n",
      "step 885, train_loss 2.3167e-05, test_loss 2.7493e-05\n",
      "step 886, train_loss 2.3189e-05, test_loss 2.7450e-05\n",
      "step 887, train_loss 2.3050e-05, test_loss 2.7288e-05\n",
      "step 888, train_loss 2.2939e-05, test_loss 2.7304e-05\n",
      "step 889, train_loss 2.2978e-05, test_loss 2.7465e-05\n",
      "step 890, train_loss 2.3068e-05, test_loss 2.7367e-05\n",
      "step 891, train_loss 2.3064e-05, test_loss 2.7354e-05\n",
      "step 892, train_loss 2.2975e-05, test_loss 2.7264e-05\n",
      "step 893, train_loss 2.2915e-05, test_loss 2.7274e-05\n",
      "step 894, train_loss 2.2943e-05, test_loss 2.7386e-05\n",
      "step 895, train_loss 2.2995e-05, test_loss 2.7309e-05\n",
      "step 896, train_loss 2.2988e-05, test_loss 2.7315e-05\n",
      "step 897, train_loss 2.2934e-05, test_loss 2.7254e-05\n",
      "step 898, train_loss 2.2896e-05, test_loss 2.7254e-05\n",
      "step 899, train_loss 2.2910e-05, test_loss 2.7327e-05\n",
      "step 900, train_loss 2.2939e-05, test_loss 2.7267e-05\n",
      "step 901, train_loss 2.2936e-05, test_loss 2.7279e-05\n",
      "step 902, train_loss 2.2903e-05, test_loss 2.7227e-05\n",
      "step 903, train_loss 2.2875e-05, test_loss 2.7219e-05\n",
      "step 904, train_loss 2.2878e-05, test_loss 2.7263e-05\n",
      "step 905, train_loss 2.2893e-05, test_loss 2.7218e-05\n",
      "step 906, train_loss 2.2893e-05, test_loss 2.7235e-05\n",
      "step 907, train_loss 2.2874e-05, test_loss 2.7190e-05\n",
      "step 908, train_loss 2.2853e-05, test_loss 2.7183e-05\n",
      "step 909, train_loss 2.2849e-05, test_loss 2.7208e-05\n",
      "step 910, train_loss 2.2856e-05, test_loss 2.7178e-05\n",
      "step 911, train_loss 2.2857e-05, test_loss 2.7199e-05\n",
      "step 912, train_loss 2.2848e-05, test_loss 2.7162e-05\n",
      "step 913, train_loss 2.2833e-05, test_loss 2.7161e-05\n",
      "step 914, train_loss 2.2825e-05, test_loss 2.7171e-05\n",
      "step 915, train_loss 2.2826e-05, test_loss 2.7152e-05\n",
      "step 916, train_loss 2.2828e-05, test_loss 2.7173e-05\n",
      "step 917, train_loss 2.2824e-05, test_loss 2.7142e-05\n",
      "step 918, train_loss 2.2814e-05, test_loss 2.7144e-05\n",
      "step 919, train_loss 2.2805e-05, test_loss 2.7141e-05\n",
      "step 920, train_loss 2.2802e-05, test_loss 2.7127e-05\n",
      "step 921, train_loss 2.2801e-05, test_loss 2.7142e-05\n",
      "step 922, train_loss 2.2799e-05, test_loss 2.7116e-05\n",
      "step 923, train_loss 2.2792e-05, test_loss 2.7121e-05\n",
      "step 924, train_loss 2.2785e-05, test_loss 2.7108e-05\n",
      "step 925, train_loss 2.2779e-05, test_loss 2.7099e-05\n",
      "step 926, train_loss 2.2775e-05, test_loss 2.7106e-05\n",
      "step 927, train_loss 2.2773e-05, test_loss 2.7086e-05\n",
      "step 928, train_loss 2.2769e-05, test_loss 2.7093e-05\n",
      "step 929, train_loss 2.2764e-05, test_loss 2.7076e-05\n",
      "step 930, train_loss 2.2757e-05, test_loss 2.7073e-05\n",
      "step 931, train_loss 2.2753e-05, test_loss 2.7072e-05\n",
      "step 932, train_loss 2.2749e-05, test_loss 2.7060e-05\n",
      "step 933, train_loss 2.2746e-05, test_loss 2.7066e-05\n",
      "step 934, train_loss 2.2742e-05, test_loss 2.7051e-05\n",
      "step 935, train_loss 2.2737e-05, test_loss 2.7052e-05\n",
      "step 936, train_loss 2.2732e-05, test_loss 2.7044e-05\n",
      "step 937, train_loss 2.2727e-05, test_loss 2.7038e-05\n",
      "step 938, train_loss 2.2723e-05, test_loss 2.7039e-05\n",
      "step 939, train_loss 2.2720e-05, test_loss 2.7026e-05\n",
      "step 940, train_loss 2.2716e-05, test_loss 2.7029e-05\n",
      "step 941, train_loss 2.2711e-05, test_loss 2.7017e-05\n",
      "step 942, train_loss 2.2707e-05, test_loss 2.7014e-05\n",
      "step 943, train_loss 2.2702e-05, test_loss 2.7010e-05\n",
      "step 944, train_loss 2.2698e-05, test_loss 2.7001e-05\n",
      "step 945, train_loss 2.2694e-05, test_loss 2.7001e-05\n",
      "step 946, train_loss 2.2690e-05, test_loss 2.6990e-05\n",
      "step 947, train_loss 2.2685e-05, test_loss 2.6989e-05\n",
      "step 948, train_loss 2.2681e-05, test_loss 2.6980e-05\n",
      "step 949, train_loss 2.2676e-05, test_loss 2.6976e-05\n",
      "step 950, train_loss 2.2672e-05, test_loss 2.6972e-05\n",
      "step 951, train_loss 2.2668e-05, test_loss 2.6964e-05\n",
      "step 952, train_loss 2.2664e-05, test_loss 2.6963e-05\n",
      "step 953, train_loss 2.2660e-05, test_loss 2.6954e-05\n",
      "step 954, train_loss 2.2656e-05, test_loss 2.6952e-05\n",
      "step 955, train_loss 2.2651e-05, test_loss 2.6945e-05\n",
      "step 956, train_loss 2.2647e-05, test_loss 2.6940e-05\n",
      "step 957, train_loss 2.2643e-05, test_loss 2.6936e-05\n",
      "step 958, train_loss 2.2639e-05, test_loss 2.6929e-05\n",
      "step 959, train_loss 2.2635e-05, test_loss 2.6927e-05\n",
      "step 960, train_loss 2.2630e-05, test_loss 2.6919e-05\n",
      "step 961, train_loss 2.2626e-05, test_loss 2.6916e-05\n",
      "step 962, train_loss 2.2622e-05, test_loss 2.6909e-05\n",
      "step 963, train_loss 2.2618e-05, test_loss 2.6905e-05\n",
      "step 964, train_loss 2.2613e-05, test_loss 2.6900e-05\n",
      "step 965, train_loss 2.2609e-05, test_loss 2.6893e-05\n",
      "step 966, train_loss 2.2605e-05, test_loss 2.6890e-05\n",
      "step 967, train_loss 2.2601e-05, test_loss 2.6883e-05\n",
      "step 968, train_loss 2.2597e-05, test_loss 2.6879e-05\n",
      "step 969, train_loss 2.2592e-05, test_loss 2.6873e-05\n",
      "step 970, train_loss 2.2588e-05, test_loss 2.6868e-05\n",
      "step 971, train_loss 2.2584e-05, test_loss 2.6863e-05\n",
      "step 972, train_loss 2.2580e-05, test_loss 2.6858e-05\n",
      "step 973, train_loss 2.2576e-05, test_loss 2.6853e-05\n",
      "step 974, train_loss 2.2572e-05, test_loss 2.6847e-05\n",
      "step 975, train_loss 2.2567e-05, test_loss 2.6843e-05\n",
      "step 976, train_loss 2.2563e-05, test_loss 2.6837e-05\n",
      "step 977, train_loss 2.2559e-05, test_loss 2.6833e-05\n",
      "step 978, train_loss 2.2555e-05, test_loss 2.6827e-05\n",
      "step 979, train_loss 2.2551e-05, test_loss 2.6823e-05\n",
      "step 980, train_loss 2.2547e-05, test_loss 2.6818e-05\n",
      "step 981, train_loss 2.2542e-05, test_loss 2.6812e-05\n",
      "step 982, train_loss 2.2538e-05, test_loss 2.6808e-05\n",
      "step 983, train_loss 2.2534e-05, test_loss 2.6802e-05\n",
      "step 984, train_loss 2.2530e-05, test_loss 2.6797e-05\n",
      "step 985, train_loss 2.2526e-05, test_loss 2.6791e-05\n",
      "step 986, train_loss 2.2522e-05, test_loss 2.6787e-05\n",
      "step 987, train_loss 2.2517e-05, test_loss 2.6781e-05\n",
      "step 988, train_loss 2.2513e-05, test_loss 2.6777e-05\n",
      "step 989, train_loss 2.2509e-05, test_loss 2.6771e-05\n",
      "step 990, train_loss 2.2505e-05, test_loss 2.6766e-05\n",
      "step 991, train_loss 2.2501e-05, test_loss 2.6761e-05\n",
      "step 992, train_loss 2.2497e-05, test_loss 2.6756e-05\n",
      "step 993, train_loss 2.2493e-05, test_loss 2.6751e-05\n",
      "step 994, train_loss 2.2488e-05, test_loss 2.6746e-05\n",
      "step 995, train_loss 2.2484e-05, test_loss 2.6741e-05\n",
      "step 996, train_loss 2.2480e-05, test_loss 2.6736e-05\n",
      "step 997, train_loss 2.2476e-05, test_loss 2.6731e-05\n",
      "step 998, train_loss 2.2472e-05, test_loss 2.6726e-05\n",
      "step 999, train_loss 2.2468e-05, test_loss 2.6721e-05\n",
      "step 1000, train_loss 2.2464e-05, test_loss 2.6716e-05\n",
      "step 1001, train_loss 2.2460e-05, test_loss 2.6711e-05\n",
      "step 1002, train_loss 2.2455e-05, test_loss 2.6706e-05\n",
      "step 1003, train_loss 2.2451e-05, test_loss 2.6701e-05\n",
      "step 1004, train_loss 2.2447e-05, test_loss 2.6696e-05\n",
      "step 1005, train_loss 2.2443e-05, test_loss 2.6691e-05\n",
      "step 1006, train_loss 2.2439e-05, test_loss 2.6686e-05\n",
      "step 1007, train_loss 2.2435e-05, test_loss 2.6680e-05\n",
      "step 1008, train_loss 2.2431e-05, test_loss 2.6676e-05\n",
      "step 1009, train_loss 2.2427e-05, test_loss 2.6670e-05\n",
      "step 1010, train_loss 2.2423e-05, test_loss 2.6666e-05\n",
      "step 1011, train_loss 2.2418e-05, test_loss 2.6660e-05\n",
      "step 1012, train_loss 2.2414e-05, test_loss 2.6656e-05\n",
      "step 1013, train_loss 2.2410e-05, test_loss 2.6650e-05\n",
      "step 1014, train_loss 2.2406e-05, test_loss 2.6646e-05\n",
      "step 1015, train_loss 2.2402e-05, test_loss 2.6640e-05\n",
      "step 1016, train_loss 2.2398e-05, test_loss 2.6635e-05\n",
      "step 1017, train_loss 2.2394e-05, test_loss 2.6630e-05\n",
      "step 1018, train_loss 2.2390e-05, test_loss 2.6625e-05\n",
      "step 1019, train_loss 2.2386e-05, test_loss 2.6620e-05\n",
      "step 1020, train_loss 2.2382e-05, test_loss 2.6615e-05\n",
      "step 1021, train_loss 2.2378e-05, test_loss 2.6610e-05\n",
      "step 1022, train_loss 2.2373e-05, test_loss 2.6605e-05\n",
      "step 1023, train_loss 2.2369e-05, test_loss 2.6600e-05\n",
      "step 1024, train_loss 2.2365e-05, test_loss 2.6596e-05\n",
      "step 1025, train_loss 2.2361e-05, test_loss 2.6590e-05\n",
      "step 1026, train_loss 2.2357e-05, test_loss 2.6586e-05\n",
      "step 1027, train_loss 2.2353e-05, test_loss 2.6580e-05\n",
      "step 1028, train_loss 2.2349e-05, test_loss 2.6576e-05\n",
      "step 1029, train_loss 2.2345e-05, test_loss 2.6570e-05\n",
      "step 1030, train_loss 2.2341e-05, test_loss 2.6566e-05\n",
      "step 1031, train_loss 2.2337e-05, test_loss 2.6560e-05\n",
      "step 1032, train_loss 2.2333e-05, test_loss 2.6556e-05\n",
      "step 1033, train_loss 2.2329e-05, test_loss 2.6550e-05\n",
      "step 1034, train_loss 2.2325e-05, test_loss 2.6546e-05\n",
      "step 1035, train_loss 2.2320e-05, test_loss 2.6540e-05\n",
      "step 1036, train_loss 2.2316e-05, test_loss 2.6536e-05\n",
      "step 1037, train_loss 2.2312e-05, test_loss 2.6530e-05\n",
      "step 1038, train_loss 2.2308e-05, test_loss 2.6526e-05\n",
      "step 1039, train_loss 2.2304e-05, test_loss 2.6520e-05\n",
      "step 1040, train_loss 2.2300e-05, test_loss 2.6516e-05\n",
      "step 1041, train_loss 2.2296e-05, test_loss 2.6510e-05\n",
      "step 1042, train_loss 2.2292e-05, test_loss 2.6507e-05\n",
      "step 1043, train_loss 2.2288e-05, test_loss 2.6500e-05\n",
      "step 1044, train_loss 2.2284e-05, test_loss 2.6498e-05\n",
      "step 1045, train_loss 2.2280e-05, test_loss 2.6489e-05\n",
      "step 1046, train_loss 2.2276e-05, test_loss 2.6489e-05\n",
      "step 1047, train_loss 2.2272e-05, test_loss 2.6479e-05\n",
      "step 1048, train_loss 2.2268e-05, test_loss 2.6481e-05\n",
      "step 1049, train_loss 2.2265e-05, test_loss 2.6468e-05\n",
      "step 1050, train_loss 2.2261e-05, test_loss 2.6476e-05\n",
      "step 1051, train_loss 2.2259e-05, test_loss 2.6458e-05\n",
      "step 1052, train_loss 2.2257e-05, test_loss 2.6476e-05\n",
      "step 1053, train_loss 2.2256e-05, test_loss 2.6452e-05\n",
      "step 1054, train_loss 2.2258e-05, test_loss 2.6490e-05\n",
      "step 1055, train_loss 2.2265e-05, test_loss 2.6461e-05\n",
      "step 1056, train_loss 2.2279e-05, test_loss 2.6546e-05\n",
      "step 1057, train_loss 2.2309e-05, test_loss 2.6525e-05\n",
      "step 1058, train_loss 2.2363e-05, test_loss 2.6727e-05\n",
      "step 1059, train_loss 2.2467e-05, test_loss 2.6783e-05\n",
      "step 1060, train_loss 2.2656e-05, test_loss 2.7315e-05\n",
      "step 1061, train_loss 2.3012e-05, test_loss 2.7731e-05\n",
      "step 1062, train_loss 2.3669e-05, test_loss 2.9294e-05\n",
      "step 1063, train_loss 2.4908e-05, test_loss 3.1174e-05\n",
      "step 1064, train_loss 2.7234e-05, test_loss 3.6216e-05\n",
      "step 1065, train_loss 3.1672e-05, test_loss 4.3847e-05\n",
      "step 1066, train_loss 4.0144e-05, test_loss 6.1354e-05\n",
      "step 1067, train_loss 5.6510e-05, test_loss 9.1449e-05\n",
      "step 1068, train_loss 8.8218e-05, test_loss 1.5553e-04\n",
      "step 1069, train_loss 1.5012e-04, test_loss 2.7327e-04\n",
      "step 1070, train_loss 2.7102e-04, test_loss 5.1336e-04\n",
      "step 1071, train_loss 5.0694e-04, test_loss 9.6119e-04\n",
      "step 1072, train_loss 9.6104e-04, test_loss 1.8168e-03\n",
      "step 1073, train_loss 1.8089e-03, test_loss 3.2779e-03\n",
      "step 1074, train_loss 3.2821e-03, test_loss 5.4961e-03\n",
      "step 1075, train_loss 5.4865e-03, test_loss 7.8108e-03\n",
      "step 1076, train_loss 7.8209e-03, test_loss 8.4453e-03\n",
      "step 1077, train_loss 8.4343e-03, test_loss 5.6358e-03\n",
      "step 1078, train_loss 5.6412e-03, test_loss 1.4244e-03\n",
      "step 1079, train_loss 1.4129e-03, test_loss 1.3723e-04\n",
      "step 1080, train_loss 1.2760e-04, test_loss 2.3651e-03\n",
      "step 1081, train_loss 2.3639e-03, test_loss 4.1179e-03\n",
      "step 1082, train_loss 4.1047e-03, test_loss 2.5566e-03\n",
      "step 1083, train_loss 2.5565e-03, test_loss 2.5302e-04\n",
      "step 1084, train_loss 2.4414e-04, test_loss 6.3343e-04\n",
      "step 1085, train_loss 6.2444e-04, test_loss 2.2727e-03\n",
      "step 1086, train_loss 2.2743e-03, test_loss 1.9415e-03\n",
      "step 1087, train_loss 1.9328e-03, test_loss 3.1444e-04\n",
      "step 1088, train_loss 3.1251e-04, test_loss 2.9374e-04\n",
      "step 1089, train_loss 2.9230e-04, test_loss 1.4156e-03\n",
      "step 1090, train_loss 1.4089e-03, test_loss 1.2371e-03\n",
      "step 1091, train_loss 1.2390e-03, test_loss 1.8644e-04\n",
      "step 1092, train_loss 1.8199e-04, test_loss 2.5258e-04\n",
      "step 1093, train_loss 2.4769e-04, test_loss 9.6644e-04\n",
      "step 1094, train_loss 9.6726e-04, test_loss 7.2659e-04\n",
      "step 1095, train_loss 7.2000e-04, test_loss 6.8527e-05\n",
      "step 1096, train_loss 6.4995e-05, test_loss 2.6998e-04\n",
      "step 1097, train_loss 2.6736e-04, test_loss 6.8777e-04\n",
      "step 1098, train_loss 6.8005e-04, test_loss 3.7230e-04\n",
      "step 1099, train_loss 3.6948e-04, test_loss 3.1379e-05\n",
      "step 1100, train_loss 2.5858e-05, test_loss 2.9057e-04\n",
      "step 1101, train_loss 2.8323e-04, test_loss 4.5675e-04\n",
      "step 1102, train_loss 4.5412e-04, test_loss 1.6767e-04\n",
      "step 1103, train_loss 1.6103e-04, test_loss 4.6522e-05\n",
      "step 1104, train_loss 4.0916e-05, test_loss 2.6674e-04\n",
      "step 1105, train_loss 2.6396e-04, test_loss 2.8258e-04\n",
      "step 1106, train_loss 2.7623e-04, test_loss 6.4341e-05\n",
      "step 1107, train_loss 6.0740e-05, test_loss 7.3009e-05\n",
      "step 1108, train_loss 6.9757e-05, test_loss 2.2158e-04\n",
      "step 1109, train_loss 2.1604e-04, test_loss 1.5536e-04\n",
      "step 1110, train_loss 1.5294e-04, test_loss 3.1756e-05\n",
      "step 1111, train_loss 2.7710e-05, test_loss 9.2345e-05\n",
      "step 1112, train_loss 8.7521e-05, test_loss 1.6101e-04\n",
      "step 1113, train_loss 1.5855e-04, test_loss 8.4314e-05\n",
      "step 1114, train_loss 7.9370e-05, test_loss 2.9799e-05\n",
      "step 1115, train_loss 2.5419e-05, test_loss 9.2052e-05\n",
      "step 1116, train_loss 8.8725e-05, test_loss 1.1325e-04\n",
      "step 1117, train_loss 1.0768e-04, test_loss 4.6670e-05\n",
      "step 1118, train_loss 4.2569e-05, test_loss 3.6385e-05\n",
      "step 1119, train_loss 3.2049e-05, test_loss 8.4430e-05\n",
      "step 1120, train_loss 7.8798e-05, test_loss 7.4417e-05\n",
      "step 1121, train_loss 7.0531e-05, test_loss 3.2886e-05\n",
      "step 1122, train_loss 2.7938e-05, test_loss 4.2183e-05\n",
      "step 1123, train_loss 3.7068e-05, test_loss 6.8130e-05\n",
      "step 1124, train_loss 6.4368e-05, test_loss 5.2146e-05\n",
      "step 1125, train_loss 4.7082e-05, test_loss 2.8236e-05\n",
      "step 1126, train_loss 2.3870e-05, test_loss 4.1920e-05\n",
      "step 1127, train_loss 3.8090e-05, test_loss 5.5766e-05\n",
      "step 1128, train_loss 5.0882e-05, test_loss 3.7931e-05\n",
      "step 1129, train_loss 3.4119e-05, test_loss 2.7863e-05\n",
      "step 1130, train_loss 2.3751e-05, test_loss 4.1031e-05\n",
      "step 1131, train_loss 3.6396e-05, test_loss 4.4241e-05\n",
      "step 1132, train_loss 4.0553e-05, test_loss 3.2213e-05\n",
      "step 1133, train_loss 2.7717e-05, test_loss 2.8803e-05\n",
      "step 1134, train_loss 2.4371e-05, test_loss 3.7488e-05\n",
      "step 1135, train_loss 3.3553e-05, test_loss 3.8356e-05\n",
      "step 1136, train_loss 3.3570e-05, test_loss 2.9134e-05\n",
      "step 1137, train_loss 2.4846e-05, test_loss 2.9047e-05\n",
      "step 1138, train_loss 2.4737e-05, test_loss 3.5557e-05\n",
      "step 1139, train_loss 3.0722e-05, test_loss 3.3368e-05\n",
      "step 1140, train_loss 2.9175e-05, test_loss 2.8237e-05\n",
      "step 1141, train_loss 2.3658e-05, test_loss 2.9308e-05\n",
      "step 1142, train_loss 2.4669e-05, test_loss 3.2460e-05\n",
      "step 1143, train_loss 2.8301e-05, test_loss 3.1165e-05\n",
      "step 1144, train_loss 2.6516e-05, test_loss 2.7489e-05\n",
      "step 1145, train_loss 2.3144e-05, test_loss 2.8527e-05\n",
      "step 1146, train_loss 2.4321e-05, test_loss 3.1042e-05\n",
      "step 1147, train_loss 2.6476e-05, test_loss 2.9088e-05\n",
      "step 1148, train_loss 2.4953e-05, test_loss 2.7255e-05\n",
      "step 1149, train_loss 2.2932e-05, test_loss 2.8352e-05\n",
      "step 1150, train_loss 2.3922e-05, test_loss 2.9303e-05\n",
      "step 1151, train_loss 2.5195e-05, test_loss 2.8523e-05\n",
      "step 1152, train_loss 2.4072e-05, test_loss 2.7158e-05\n",
      "step 1153, train_loss 2.2838e-05, test_loss 2.7799e-05\n",
      "step 1154, train_loss 2.3564e-05, test_loss 2.8864e-05\n",
      "step 1155, train_loss 2.4344e-05, test_loss 2.7835e-05\n",
      "step 1156, train_loss 2.3565e-05, test_loss 2.7191e-05\n",
      "step 1157, train_loss 2.2793e-05, test_loss 2.7771e-05\n",
      "step 1158, train_loss 2.3280e-05, test_loss 2.8045e-05\n",
      "step 1159, train_loss 2.3770e-05, test_loss 2.7753e-05\n",
      "step 1160, train_loss 2.3263e-05, test_loss 2.7138e-05\n",
      "step 1161, train_loss 2.2749e-05, test_loss 2.7363e-05\n",
      "step 1162, train_loss 2.3049e-05, test_loss 2.7853e-05\n",
      "step 1163, train_loss 2.3376e-05, test_loss 2.7343e-05\n",
      "step 1164, train_loss 2.3056e-05, test_loss 2.7064e-05\n",
      "step 1165, train_loss 2.2705e-05, test_loss 2.7271e-05\n",
      "step 1166, train_loss 2.2875e-05, test_loss 2.7351e-05\n",
      "step 1167, train_loss 2.3102e-05, test_loss 2.7311e-05\n",
      "step 1168, train_loss 2.2920e-05, test_loss 2.6985e-05\n",
      "step 1169, train_loss 2.2672e-05, test_loss 2.7043e-05\n",
      "step 1170, train_loss 2.2757e-05, test_loss 2.7316e-05\n",
      "step 1171, train_loss 2.2921e-05, test_loss 2.7106e-05\n",
      "step 1172, train_loss 2.2827e-05, test_loss 2.7010e-05\n",
      "step 1173, train_loss 2.2655e-05, test_loss 2.7055e-05\n",
      "step 1174, train_loss 2.2683e-05, test_loss 2.7095e-05\n",
      "step 1175, train_loss 2.2797e-05, test_loss 2.7163e-05\n",
      "step 1176, train_loss 2.2762e-05, test_loss 2.6978e-05\n",
      "step 1177, train_loss 2.2640e-05, test_loss 2.6974e-05\n",
      "step 1178, train_loss 2.2634e-05, test_loss 2.7105e-05\n",
      "step 1179, train_loss 2.2709e-05, test_loss 2.7016e-05\n",
      "step 1180, train_loss 2.2703e-05, test_loss 2.6994e-05\n",
      "step 1181, train_loss 2.2624e-05, test_loss 2.6949e-05\n",
      "step 1182, train_loss 2.2597e-05, test_loss 2.6951e-05\n",
      "step 1183, train_loss 2.2640e-05, test_loss 2.7021e-05\n",
      "step 1184, train_loss 2.2652e-05, test_loss 2.6911e-05\n",
      "step 1185, train_loss 2.2602e-05, test_loss 2.6898e-05\n",
      "step 1186, train_loss 2.2571e-05, test_loss 2.6935e-05\n",
      "step 1187, train_loss 2.2591e-05, test_loss 2.6903e-05\n",
      "step 1188, train_loss 2.2608e-05, test_loss 2.6928e-05\n",
      "step 1189, train_loss 2.2583e-05, test_loss 2.6872e-05\n",
      "step 1190, train_loss 2.2554e-05, test_loss 2.6871e-05\n",
      "step 1191, train_loss 2.2558e-05, test_loss 2.6921e-05\n",
      "step 1192, train_loss 2.2573e-05, test_loss 2.6872e-05\n",
      "step 1193, train_loss 2.2564e-05, test_loss 2.6879e-05\n",
      "step 1194, train_loss 2.2542e-05, test_loss 2.6869e-05\n",
      "step 1195, train_loss 2.2535e-05, test_loss 2.6859e-05\n",
      "step 1196, train_loss 2.2544e-05, test_loss 2.6890e-05\n",
      "step 1197, train_loss 2.2544e-05, test_loss 2.6845e-05\n",
      "step 1198, train_loss 2.2528e-05, test_loss 2.6844e-05\n",
      "step 1199, train_loss 2.2517e-05, test_loss 2.6852e-05\n",
      "step 1200, train_loss 2.2518e-05, test_loss 2.6828e-05\n",
      "step 1201, train_loss 2.2520e-05, test_loss 2.6843e-05\n",
      "step 1202, train_loss 2.2512e-05, test_loss 2.6813e-05\n",
      "step 1203, train_loss 2.2500e-05, test_loss 2.6807e-05\n",
      "step 1204, train_loss 2.2496e-05, test_loss 2.6820e-05\n",
      "step 1205, train_loss 2.2497e-05, test_loss 2.6795e-05\n",
      "step 1206, train_loss 2.2494e-05, test_loss 2.6803e-05\n",
      "step 1207, train_loss 2.2485e-05, test_loss 2.6789e-05\n",
      "step 1208, train_loss 2.2479e-05, test_loss 2.6781e-05\n",
      "step 1209, train_loss 2.2478e-05, test_loss 2.6794e-05\n",
      "step 1210, train_loss 2.2476e-05, test_loss 2.6773e-05\n",
      "step 1211, train_loss 2.2471e-05, test_loss 2.6777e-05\n",
      "step 1212, train_loss 2.2464e-05, test_loss 2.6772e-05\n",
      "step 1213, train_loss 2.2460e-05, test_loss 2.6762e-05\n",
      "step 1214, train_loss 2.2459e-05, test_loss 2.6770e-05\n",
      "step 1215, train_loss 2.2455e-05, test_loss 2.6752e-05\n",
      "step 1216, train_loss 2.2450e-05, test_loss 2.6752e-05\n",
      "step 1217, train_loss 2.2445e-05, test_loss 2.6749e-05\n",
      "step 1218, train_loss 2.2441e-05, test_loss 2.6737e-05\n",
      "step 1219, train_loss 2.2438e-05, test_loss 2.6741e-05\n",
      "step 1220, train_loss 2.2434e-05, test_loss 2.6727e-05\n",
      "step 1221, train_loss 2.2429e-05, test_loss 2.6724e-05\n",
      "step 1222, train_loss 2.2425e-05, test_loss 2.6722e-05\n",
      "step 1223, train_loss 2.2421e-05, test_loss 2.6710e-05\n",
      "step 1224, train_loss 2.2418e-05, test_loss 2.6713e-05\n",
      "step 1225, train_loss 2.2414e-05, test_loss 2.6702e-05\n",
      "step 1226, train_loss 2.2409e-05, test_loss 2.6698e-05\n",
      "step 1227, train_loss 2.2405e-05, test_loss 2.6698e-05\n",
      "step 1228, train_loss 2.2402e-05, test_loss 2.6687e-05\n",
      "step 1229, train_loss 2.2398e-05, test_loss 2.6689e-05\n",
      "step 1230, train_loss 2.2394e-05, test_loss 2.6680e-05\n",
      "step 1231, train_loss 2.2390e-05, test_loss 2.6676e-05\n",
      "step 1232, train_loss 2.2386e-05, test_loss 2.6675e-05\n",
      "step 1233, train_loss 2.2383e-05, test_loss 2.6665e-05\n",
      "step 1234, train_loss 2.2379e-05, test_loss 2.6665e-05\n",
      "step 1235, train_loss 2.2375e-05, test_loss 2.6657e-05\n",
      "step 1236, train_loss 2.2371e-05, test_loss 2.6652e-05\n",
      "step 1237, train_loss 2.2367e-05, test_loss 2.6650e-05\n",
      "step 1238, train_loss 2.2363e-05, test_loss 2.6641e-05\n",
      "step 1239, train_loss 2.2359e-05, test_loss 2.6639e-05\n",
      "step 1240, train_loss 2.2355e-05, test_loss 2.6632e-05\n",
      "step 1241, train_loss 2.2351e-05, test_loss 2.6627e-05\n",
      "step 1242, train_loss 2.2347e-05, test_loss 2.6624e-05\n",
      "step 1243, train_loss 2.2344e-05, test_loss 2.6617e-05\n",
      "step 1244, train_loss 2.2340e-05, test_loss 2.6615e-05\n",
      "step 1245, train_loss 2.2336e-05, test_loss 2.6608e-05\n",
      "step 1246, train_loss 2.2332e-05, test_loss 2.6604e-05\n",
      "step 1247, train_loss 2.2328e-05, test_loss 2.6601e-05\n",
      "step 1248, train_loss 2.2324e-05, test_loss 2.6594e-05\n",
      "step 1249, train_loss 2.2321e-05, test_loss 2.6591e-05\n",
      "step 1250, train_loss 2.2317e-05, test_loss 2.6585e-05\n",
      "step 1251, train_loss 2.2313e-05, test_loss 2.6581e-05\n",
      "step 1252, train_loss 2.2309e-05, test_loss 2.6577e-05\n",
      "step 1253, train_loss 2.2305e-05, test_loss 2.6571e-05\n",
      "step 1254, train_loss 2.2301e-05, test_loss 2.6567e-05\n",
      "step 1255, train_loss 2.2298e-05, test_loss 2.6561e-05\n",
      "step 1256, train_loss 2.2294e-05, test_loss 2.6557e-05\n",
      "step 1257, train_loss 2.2290e-05, test_loss 2.6552e-05\n",
      "step 1258, train_loss 2.2286e-05, test_loss 2.6547e-05\n",
      "step 1259, train_loss 2.2282e-05, test_loss 2.6543e-05\n",
      "step 1260, train_loss 2.2278e-05, test_loss 2.6537e-05\n",
      "step 1261, train_loss 2.2275e-05, test_loss 2.6533e-05\n",
      "step 1262, train_loss 2.2271e-05, test_loss 2.6528e-05\n",
      "step 1263, train_loss 2.2267e-05, test_loss 2.6523e-05\n",
      "step 1264, train_loss 2.2263e-05, test_loss 2.6519e-05\n",
      "step 1265, train_loss 2.2259e-05, test_loss 2.6513e-05\n",
      "step 1266, train_loss 2.2255e-05, test_loss 2.6509e-05\n",
      "step 1267, train_loss 2.2252e-05, test_loss 2.6505e-05\n",
      "step 1268, train_loss 2.2248e-05, test_loss 2.6500e-05\n",
      "step 1269, train_loss 2.2244e-05, test_loss 2.6496e-05\n",
      "step 1270, train_loss 2.2240e-05, test_loss 2.6490e-05\n",
      "step 1271, train_loss 2.2236e-05, test_loss 2.6486e-05\n",
      "step 1272, train_loss 2.2233e-05, test_loss 2.6481e-05\n",
      "step 1273, train_loss 2.2229e-05, test_loss 2.6476e-05\n",
      "step 1274, train_loss 2.2225e-05, test_loss 2.6472e-05\n",
      "step 1275, train_loss 2.2221e-05, test_loss 2.6466e-05\n",
      "step 1276, train_loss 2.2217e-05, test_loss 2.6462e-05\n",
      "step 1277, train_loss 2.2213e-05, test_loss 2.6457e-05\n",
      "step 1278, train_loss 2.2210e-05, test_loss 2.6452e-05\n",
      "step 1279, train_loss 2.2206e-05, test_loss 2.6448e-05\n",
      "step 1280, train_loss 2.2202e-05, test_loss 2.6443e-05\n",
      "step 1281, train_loss 2.2198e-05, test_loss 2.6438e-05\n",
      "step 1282, train_loss 2.2194e-05, test_loss 2.6433e-05\n",
      "step 1283, train_loss 2.2191e-05, test_loss 2.6429e-05\n",
      "step 1284, train_loss 2.2187e-05, test_loss 2.6424e-05\n",
      "step 1285, train_loss 2.2183e-05, test_loss 2.6419e-05\n",
      "step 1286, train_loss 2.2179e-05, test_loss 2.6415e-05\n",
      "step 1287, train_loss 2.2175e-05, test_loss 2.6410e-05\n",
      "step 1288, train_loss 2.2172e-05, test_loss 2.6406e-05\n",
      "step 1289, train_loss 2.2168e-05, test_loss 2.6401e-05\n",
      "step 1290, train_loss 2.2164e-05, test_loss 2.6396e-05\n",
      "step 1291, train_loss 2.2160e-05, test_loss 2.6391e-05\n",
      "step 1292, train_loss 2.2156e-05, test_loss 2.6386e-05\n",
      "step 1293, train_loss 2.2153e-05, test_loss 2.6382e-05\n",
      "step 1294, train_loss 2.2149e-05, test_loss 2.6377e-05\n",
      "step 1295, train_loss 2.2145e-05, test_loss 2.6373e-05\n",
      "step 1296, train_loss 2.2141e-05, test_loss 2.6368e-05\n",
      "step 1297, train_loss 2.2138e-05, test_loss 2.6363e-05\n",
      "step 1298, train_loss 2.2134e-05, test_loss 2.6358e-05\n",
      "step 1299, train_loss 2.2130e-05, test_loss 2.6353e-05\n",
      "step 1300, train_loss 2.2126e-05, test_loss 2.6349e-05\n",
      "step 1301, train_loss 2.2122e-05, test_loss 2.6344e-05\n",
      "step 1302, train_loss 2.2119e-05, test_loss 2.6340e-05\n",
      "step 1303, train_loss 2.2115e-05, test_loss 2.6335e-05\n",
      "step 1304, train_loss 2.2111e-05, test_loss 2.6330e-05\n",
      "step 1305, train_loss 2.2107e-05, test_loss 2.6325e-05\n",
      "step 1306, train_loss 2.2103e-05, test_loss 2.6321e-05\n",
      "step 1307, train_loss 2.2100e-05, test_loss 2.6316e-05\n",
      "step 1308, train_loss 2.2096e-05, test_loss 2.6311e-05\n",
      "step 1309, train_loss 2.2092e-05, test_loss 2.6307e-05\n",
      "step 1310, train_loss 2.2088e-05, test_loss 2.6302e-05\n",
      "step 1311, train_loss 2.2084e-05, test_loss 2.6297e-05\n",
      "step 1312, train_loss 2.2081e-05, test_loss 2.6293e-05\n",
      "step 1313, train_loss 2.2077e-05, test_loss 2.6288e-05\n",
      "step 1314, train_loss 2.2073e-05, test_loss 2.6283e-05\n",
      "step 1315, train_loss 2.2069e-05, test_loss 2.6279e-05\n",
      "step 1316, train_loss 2.2066e-05, test_loss 2.6274e-05\n",
      "step 1317, train_loss 2.2062e-05, test_loss 2.6269e-05\n",
      "step 1318, train_loss 2.2058e-05, test_loss 2.6265e-05\n",
      "step 1319, train_loss 2.2054e-05, test_loss 2.6260e-05\n",
      "step 1320, train_loss 2.2050e-05, test_loss 2.6255e-05\n",
      "step 1321, train_loss 2.2047e-05, test_loss 2.6251e-05\n",
      "step 1322, train_loss 2.2043e-05, test_loss 2.6246e-05\n",
      "step 1323, train_loss 2.2039e-05, test_loss 2.6241e-05\n",
      "step 1324, train_loss 2.2035e-05, test_loss 2.6237e-05\n",
      "step 1325, train_loss 2.2032e-05, test_loss 2.6232e-05\n",
      "step 1326, train_loss 2.2028e-05, test_loss 2.6227e-05\n",
      "step 1327, train_loss 2.2024e-05, test_loss 2.6223e-05\n",
      "step 1328, train_loss 2.2020e-05, test_loss 2.6218e-05\n",
      "step 1329, train_loss 2.2016e-05, test_loss 2.6213e-05\n",
      "step 1330, train_loss 2.2013e-05, test_loss 2.6209e-05\n",
      "step 1331, train_loss 2.2009e-05, test_loss 2.6204e-05\n",
      "step 1332, train_loss 2.2005e-05, test_loss 2.6199e-05\n",
      "step 1333, train_loss 2.2001e-05, test_loss 2.6195e-05\n",
      "step 1334, train_loss 2.1998e-05, test_loss 2.6190e-05\n",
      "step 1335, train_loss 2.1994e-05, test_loss 2.6185e-05\n",
      "step 1336, train_loss 2.1990e-05, test_loss 2.6181e-05\n",
      "step 1337, train_loss 2.1986e-05, test_loss 2.6176e-05\n",
      "step 1338, train_loss 2.1983e-05, test_loss 2.6171e-05\n",
      "step 1339, train_loss 2.1979e-05, test_loss 2.6167e-05\n",
      "step 1340, train_loss 2.1975e-05, test_loss 2.6162e-05\n",
      "step 1341, train_loss 2.1971e-05, test_loss 2.6157e-05\n",
      "step 1342, train_loss 2.1968e-05, test_loss 2.6153e-05\n",
      "step 1343, train_loss 2.1964e-05, test_loss 2.6148e-05\n",
      "step 1344, train_loss 2.1960e-05, test_loss 2.6144e-05\n",
      "step 1345, train_loss 2.1956e-05, test_loss 2.6139e-05\n",
      "step 1346, train_loss 2.1952e-05, test_loss 2.6134e-05\n",
      "step 1347, train_loss 2.1949e-05, test_loss 2.6130e-05\n",
      "step 1348, train_loss 2.1945e-05, test_loss 2.6125e-05\n",
      "step 1349, train_loss 2.1941e-05, test_loss 2.6120e-05\n",
      "step 1350, train_loss 2.1937e-05, test_loss 2.6116e-05\n",
      "step 1351, train_loss 2.1934e-05, test_loss 2.6111e-05\n",
      "step 1352, train_loss 2.1930e-05, test_loss 2.6106e-05\n",
      "step 1353, train_loss 2.1926e-05, test_loss 2.6102e-05\n",
      "step 1354, train_loss 2.1922e-05, test_loss 2.6097e-05\n",
      "step 1355, train_loss 2.1919e-05, test_loss 2.6092e-05\n",
      "step 1356, train_loss 2.1915e-05, test_loss 2.6088e-05\n",
      "step 1357, train_loss 2.1911e-05, test_loss 2.6083e-05\n",
      "step 1358, train_loss 2.1907e-05, test_loss 2.6079e-05\n",
      "step 1359, train_loss 2.1904e-05, test_loss 2.6074e-05\n",
      "step 1360, train_loss 2.1900e-05, test_loss 2.6069e-05\n",
      "step 1361, train_loss 2.1896e-05, test_loss 2.6065e-05\n",
      "step 1362, train_loss 2.1892e-05, test_loss 2.6060e-05\n",
      "step 1363, train_loss 2.1889e-05, test_loss 2.6055e-05\n",
      "step 1364, train_loss 2.1885e-05, test_loss 2.6051e-05\n",
      "step 1365, train_loss 2.1881e-05, test_loss 2.6046e-05\n",
      "step 1366, train_loss 2.1877e-05, test_loss 2.6042e-05\n",
      "step 1367, train_loss 2.1874e-05, test_loss 2.6037e-05\n",
      "step 1368, train_loss 2.1870e-05, test_loss 2.6032e-05\n",
      "step 1369, train_loss 2.1866e-05, test_loss 2.6028e-05\n",
      "step 1370, train_loss 2.1863e-05, test_loss 2.6023e-05\n",
      "step 1371, train_loss 2.1859e-05, test_loss 2.6019e-05\n",
      "step 1372, train_loss 2.1855e-05, test_loss 2.6014e-05\n",
      "step 1373, train_loss 2.1851e-05, test_loss 2.6009e-05\n",
      "step 1374, train_loss 2.1848e-05, test_loss 2.6005e-05\n",
      "step 1375, train_loss 2.1844e-05, test_loss 2.6000e-05\n",
      "step 1376, train_loss 2.1840e-05, test_loss 2.5995e-05\n",
      "step 1377, train_loss 2.1836e-05, test_loss 2.5991e-05\n",
      "step 1378, train_loss 2.1833e-05, test_loss 2.5986e-05\n",
      "step 1379, train_loss 2.1829e-05, test_loss 2.5982e-05\n",
      "step 1380, train_loss 2.1825e-05, test_loss 2.5977e-05\n",
      "step 1381, train_loss 2.1821e-05, test_loss 2.5972e-05\n",
      "step 1382, train_loss 2.1818e-05, test_loss 2.5968e-05\n",
      "step 1383, train_loss 2.1814e-05, test_loss 2.5963e-05\n",
      "step 1384, train_loss 2.1810e-05, test_loss 2.5959e-05\n",
      "step 1385, train_loss 2.1806e-05, test_loss 2.5954e-05\n",
      "step 1386, train_loss 2.1803e-05, test_loss 2.5949e-05\n",
      "step 1387, train_loss 2.1799e-05, test_loss 2.5945e-05\n",
      "step 1388, train_loss 2.1795e-05, test_loss 2.5940e-05\n",
      "step 1389, train_loss 2.1792e-05, test_loss 2.5936e-05\n",
      "step 1390, train_loss 2.1788e-05, test_loss 2.5931e-05\n",
      "step 1391, train_loss 2.1784e-05, test_loss 2.5926e-05\n",
      "step 1392, train_loss 2.1780e-05, test_loss 2.5922e-05\n",
      "step 1393, train_loss 2.1777e-05, test_loss 2.5917e-05\n",
      "step 1394, train_loss 2.1773e-05, test_loss 2.5913e-05\n",
      "step 1395, train_loss 2.1769e-05, test_loss 2.5908e-05\n",
      "step 1396, train_loss 2.1765e-05, test_loss 2.5903e-05\n",
      "step 1397, train_loss 2.1762e-05, test_loss 2.5899e-05\n",
      "step 1398, train_loss 2.1758e-05, test_loss 2.5894e-05\n",
      "step 1399, train_loss 2.1754e-05, test_loss 2.5890e-05\n",
      "step 1400, train_loss 2.1751e-05, test_loss 2.5885e-05\n",
      "step 1401, train_loss 2.1747e-05, test_loss 2.5880e-05\n",
      "step 1402, train_loss 2.1743e-05, test_loss 2.5876e-05\n",
      "step 1403, train_loss 2.1739e-05, test_loss 2.5871e-05\n",
      "step 1404, train_loss 2.1736e-05, test_loss 2.5867e-05\n",
      "step 1405, train_loss 2.1732e-05, test_loss 2.5862e-05\n",
      "step 1406, train_loss 2.1728e-05, test_loss 2.5858e-05\n",
      "step 1407, train_loss 2.1724e-05, test_loss 2.5853e-05\n",
      "step 1408, train_loss 2.1721e-05, test_loss 2.5849e-05\n",
      "step 1409, train_loss 2.1717e-05, test_loss 2.5844e-05\n",
      "step 1410, train_loss 2.1713e-05, test_loss 2.5839e-05\n",
      "step 1411, train_loss 2.1710e-05, test_loss 2.5834e-05\n",
      "step 1412, train_loss 2.1706e-05, test_loss 2.5830e-05\n",
      "step 1413, train_loss 2.1702e-05, test_loss 2.5825e-05\n",
      "step 1414, train_loss 2.1699e-05, test_loss 2.5821e-05\n",
      "step 1415, train_loss 2.1695e-05, test_loss 2.5816e-05\n",
      "step 1416, train_loss 2.1691e-05, test_loss 2.5813e-05\n",
      "step 1417, train_loss 2.1688e-05, test_loss 2.5807e-05\n",
      "step 1418, train_loss 2.1684e-05, test_loss 2.5804e-05\n",
      "step 1419, train_loss 2.1681e-05, test_loss 2.5798e-05\n",
      "step 1420, train_loss 2.1678e-05, test_loss 2.5797e-05\n",
      "step 1421, train_loss 2.1674e-05, test_loss 2.5790e-05\n",
      "step 1422, train_loss 2.1672e-05, test_loss 2.5792e-05\n",
      "step 1423, train_loss 2.1670e-05, test_loss 2.5786e-05\n",
      "step 1424, train_loss 2.1670e-05, test_loss 2.5794e-05\n",
      "step 1425, train_loss 2.1673e-05, test_loss 2.5791e-05\n",
      "step 1426, train_loss 2.1679e-05, test_loss 2.5815e-05\n",
      "step 1427, train_loss 2.1693e-05, test_loss 2.5825e-05\n",
      "step 1428, train_loss 2.1719e-05, test_loss 2.5893e-05\n",
      "step 1429, train_loss 2.1767e-05, test_loss 2.5953e-05\n",
      "step 1430, train_loss 2.1856e-05, test_loss 2.6145e-05\n",
      "step 1431, train_loss 2.2012e-05, test_loss 2.6379e-05\n",
      "step 1432, train_loss 2.2296e-05, test_loss 2.6948e-05\n",
      "step 1433, train_loss 2.2801e-05, test_loss 2.7783e-05\n",
      "step 1434, train_loss 2.3723e-05, test_loss 2.9563e-05\n",
      "step 1435, train_loss 2.5389e-05, test_loss 3.2469e-05\n",
      "step 1436, train_loss 2.8453e-05, test_loss 3.8299e-05\n",
      "step 1437, train_loss 3.4075e-05, test_loss 4.8452e-05\n",
      "step 1438, train_loss 4.4516e-05, test_loss 6.8253e-05\n",
      "step 1439, train_loss 6.3939e-05, test_loss 1.0413e-04\n",
      "step 1440, train_loss 1.0035e-04, test_loss 1.7315e-04\n",
      "step 1441, train_loss 1.6867e-04, test_loss 3.0055e-04\n",
      "step 1442, train_loss 2.9711e-04, test_loss 5.4149e-04\n",
      "step 1443, train_loss 5.3678e-04, test_loss 9.7984e-04\n",
      "step 1444, train_loss 9.7713e-04, test_loss 1.7603e-03\n",
      "step 1445, train_loss 1.7553e-03, test_loss 3.0304e-03\n",
      "step 1446, train_loss 3.0293e-03, test_loss 4.8123e-03\n",
      "step 1447, train_loss 4.8072e-03, test_loss 6.5642e-03\n",
      "step 1448, train_loss 6.5652e-03, test_loss 6.9639e-03\n",
      "step 1449, train_loss 6.9583e-03, test_loss 4.8814e-03\n",
      "step 1450, train_loss 4.8808e-03, test_loss 1.5678e-03\n",
      "step 1451, train_loss 1.5606e-03, test_loss 3.5308e-05\n",
      "step 1452, train_loss 2.9277e-05, test_loss 1.2961e-03\n",
      "step 1453, train_loss 1.2917e-03, test_loss 3.0853e-03\n",
      "step 1454, train_loss 3.0784e-03, test_loss 2.8174e-03\n",
      "step 1455, train_loss 2.8147e-03, test_loss 9.1881e-04\n",
      "step 1456, train_loss 9.1304e-04, test_loss 6.3022e-05\n",
      "step 1457, train_loss 5.7502e-05, test_loss 1.0701e-03\n",
      "step 1458, train_loss 1.0678e-03, test_loss 1.9323e-03\n",
      "step 1459, train_loss 1.9269e-03, test_loss 1.1963e-03\n",
      "step 1460, train_loss 1.1948e-03, test_loss 1.4682e-04\n",
      "step 1461, train_loss 1.4230e-04, test_loss 3.6386e-04\n",
      "step 1462, train_loss 3.6043e-04, test_loss 1.1394e-03\n",
      "step 1463, train_loss 1.1367e-03, test_loss 9.9179e-04\n",
      "step 1464, train_loss 9.8810e-04, test_loss 2.4168e-04\n",
      "step 1465, train_loss 2.3767e-04, test_loss 1.7932e-04\n",
      "step 1466, train_loss 1.7663e-04, test_loss 7.0624e-04\n",
      "step 1467, train_loss 7.0064e-04, test_loss 7.2969e-04\n",
      "step 1468, train_loss 7.2754e-04, test_loss 2.4605e-04\n",
      "step 1469, train_loss 2.4030e-04, test_loss 1.3611e-04\n",
      "step 1470, train_loss 1.3208e-04, test_loss 4.7606e-04\n",
      "step 1471, train_loss 4.7135e-04, test_loss 5.3137e-04\n",
      "step 1472, train_loss 5.2682e-04, test_loss 2.1749e-04\n",
      "step 1473, train_loss 2.1233e-04, test_loss 1.2681e-04\n",
      "step 1474, train_loss 1.2333e-04, test_loss 3.5007e-04\n",
      "step 1475, train_loss 3.4421e-04, test_loss 3.9176e-04\n",
      "step 1476, train_loss 3.8919e-04, test_loss 1.8909e-04\n",
      "step 1477, train_loss 1.8366e-04, test_loss 1.2655e-04\n",
      "step 1478, train_loss 1.2328e-04, test_loss 2.7519e-04\n",
      "step 1479, train_loss 2.7073e-04, test_loss 3.0673e-04\n",
      "step 1480, train_loss 3.0331e-04, test_loss 1.7528e-04\n",
      "step 1481, train_loss 1.7065e-04, test_loss 1.3750e-04\n",
      "step 1482, train_loss 1.3480e-04, test_loss 2.4116e-04\n",
      "step 1483, train_loss 2.3587e-04, test_loss 2.6252e-04\n",
      "step 1484, train_loss 2.6018e-04, test_loss 1.8215e-04\n",
      "step 1485, train_loss 1.7680e-04, test_loss 1.6231e-04\n",
      "step 1486, train_loss 1.5925e-04, test_loss 2.3704e-04\n",
      "step 1487, train_loss 2.3196e-04, test_loss 2.5676e-04\n",
      "step 1488, train_loss 2.5338e-04, test_loss 2.1011e-04\n",
      "step 1489, train_loss 2.0469e-04, test_loss 2.0333e-04\n",
      "step 1490, train_loss 2.0044e-04, test_loss 2.6170e-04\n",
      "step 1491, train_loss 2.5577e-04, test_loss 2.7929e-04\n",
      "step 1492, train_loss 2.7678e-04, test_loss 2.5715e-04\n",
      "step 1493, train_loss 2.5127e-04, test_loss 2.5723e-04\n",
      "step 1494, train_loss 2.5447e-04, test_loss 3.0175e-04\n",
      "step 1495, train_loss 2.9619e-04, test_loss 3.1647e-04\n",
      "step 1496, train_loss 3.1371e-04, test_loss 3.0336e-04\n",
      "step 1497, train_loss 2.9773e-04, test_loss 2.9949e-04\n",
      "step 1498, train_loss 2.9718e-04, test_loss 3.2470e-04\n",
      "step 1499, train_loss 3.1883e-04, test_loss 3.2286e-04\n",
      "step 1500, train_loss 3.2075e-04, test_loss 3.0169e-04\n",
      "step 1501, train_loss 2.9590e-04, test_loss 2.7925e-04\n",
      "step 1502, train_loss 2.7674e-04, test_loss 2.7529e-04\n",
      "step 1503, train_loss 2.6975e-04, test_loss 2.5145e-04\n",
      "step 1504, train_loss 2.4860e-04, test_loss 2.1475e-04\n",
      "step 1505, train_loss 2.0927e-04, test_loss 1.7774e-04\n",
      "step 1506, train_loss 1.7482e-04, test_loss 1.5774e-04\n",
      "step 1507, train_loss 1.5229e-04, test_loss 1.2899e-04\n",
      "step 1508, train_loss 1.2588e-04, test_loss 9.7689e-05\n",
      "step 1509, train_loss 9.2552e-05, test_loss 7.0714e-05\n",
      "step 1510, train_loss 6.7150e-05, test_loss 5.9324e-05\n",
      "step 1511, train_loss 5.4672e-05, test_loss 4.7978e-05\n",
      "step 1512, train_loss 4.4070e-05, test_loss 3.5412e-05\n",
      "step 1513, train_loss 3.1061e-05, test_loss 2.7719e-05\n",
      "step 1514, train_loss 2.3710e-05, test_loss 2.9330e-05\n",
      "step 1515, train_loss 2.5124e-05, test_loss 3.1921e-05\n",
      "step 1516, train_loss 2.7805e-05, test_loss 3.1512e-05\n",
      "step 1517, train_loss 2.7526e-05, test_loss 3.3299e-05\n",
      "step 1518, train_loss 2.8922e-05, test_loss 3.8518e-05\n",
      "step 1519, train_loss 3.4789e-05, test_loss 4.5561e-05\n",
      "step 1520, train_loss 4.0960e-05, test_loss 4.7843e-05\n",
      "step 1521, train_loss 4.4212e-05, test_loss 5.2014e-05\n",
      "step 1522, train_loss 4.7338e-05, test_loss 5.6634e-05\n",
      "step 1523, train_loss 5.2984e-05, test_loss 6.4008e-05\n",
      "step 1524, train_loss 5.9285e-05, test_loss 6.7453e-05\n",
      "step 1525, train_loss 6.3867e-05, test_loss 7.3157e-05\n",
      "step 1526, train_loss 6.8301e-05, test_loss 7.8237e-05\n",
      "step 1527, train_loss 7.4819e-05, test_loss 8.7966e-05\n",
      "step 1528, train_loss 8.2972e-05, test_loss 9.4442e-05\n",
      "step 1529, train_loss 9.1161e-05, test_loss 1.0529e-04\n",
      "step 1530, train_loss 1.0023e-04, test_loss 1.1522e-04\n",
      "step 1531, train_loss 1.1203e-04, test_loss 1.3224e-04\n",
      "step 1532, train_loss 1.2711e-04, test_loss 1.4776e-04\n",
      "step 1533, train_loss 1.4472e-04, test_loss 1.7089e-04\n",
      "step 1534, train_loss 1.6559e-04, test_loss 1.9411e-04\n",
      "step 1535, train_loss 1.9133e-04, test_loss 2.2880e-04\n",
      "step 1536, train_loss 2.2325e-04, test_loss 2.6372e-04\n",
      "step 1537, train_loss 2.6124e-04, test_loss 3.1162e-04\n",
      "step 1538, train_loss 3.0582e-04, test_loss 3.5974e-04\n",
      "step 1539, train_loss 3.5754e-04, test_loss 4.2258e-04\n",
      "step 1540, train_loss 4.1653e-04, test_loss 4.8227e-04\n",
      "step 1541, train_loss 4.8037e-04, test_loss 5.5179e-04\n",
      "step 1542, train_loss 5.4546e-04, test_loss 6.0746e-04\n",
      "step 1543, train_loss 6.0587e-04, test_loss 6.6090e-04\n",
      "step 1544, train_loss 6.5431e-04, test_loss 6.8200e-04\n",
      "step 1545, train_loss 6.8056e-04, test_loss 6.8211e-04\n",
      "step 1546, train_loss 6.7541e-04, test_loss 6.3373e-04\n",
      "step 1547, train_loss 6.3209e-04, test_loss 5.5785e-04\n",
      "step 1548, train_loss 5.5131e-04, test_loss 4.4307e-04\n",
      "step 1549, train_loss 4.4085e-04, test_loss 3.2268e-04\n",
      "step 1550, train_loss 3.1663e-04, test_loss 2.0095e-04\n",
      "step 1551, train_loss 1.9793e-04, test_loss 1.0846e-04\n",
      "step 1552, train_loss 1.0321e-04, test_loss 4.7675e-05\n",
      "step 1553, train_loss 4.3872e-05, test_loss 2.6683e-05\n",
      "step 1554, train_loss 2.2417e-05, test_loss 3.7429e-05\n",
      "step 1555, train_loss 3.3000e-05, test_loss 6.7946e-05\n",
      "step 1556, train_loss 6.4594e-05, test_loss 1.0928e-04\n",
      "step 1557, train_loss 1.0442e-04, test_loss 1.4335e-04\n",
      "step 1558, train_loss 1.4057e-04, test_loss 1.6961e-04\n",
      "step 1559, train_loss 1.6449e-04, test_loss 1.7434e-04\n",
      "step 1560, train_loss 1.7164e-04, test_loss 1.6736e-04\n",
      "step 1561, train_loss 1.6215e-04, test_loss 1.4235e-04\n",
      "step 1562, train_loss 1.3933e-04, test_loss 1.1423e-04\n",
      "step 1563, train_loss 1.0909e-04, test_loss 8.1237e-05\n",
      "step 1564, train_loss 7.7707e-05, test_loss 5.5810e-05\n",
      "step 1565, train_loss 5.0929e-05, test_loss 3.6384e-05\n",
      "step 1566, train_loss 3.2353e-05, test_loss 2.7770e-05\n",
      "step 1567, train_loss 2.3304e-05, test_loss 2.7298e-05\n",
      "step 1568, train_loss 2.2901e-05, test_loss 3.2877e-05\n",
      "step 1569, train_loss 2.8883e-05, test_loss 4.2988e-05\n",
      "step 1570, train_loss 3.8384e-05, test_loss 5.2136e-05\n",
      "step 1571, train_loss 4.8535e-05, test_loss 6.1800e-05\n",
      "step 1572, train_loss 5.7118e-05, test_loss 6.6023e-05\n",
      "step 1573, train_loss 6.2633e-05, test_loss 6.9286e-05\n",
      "step 1574, train_loss 6.4597e-05, test_loss 6.6480e-05\n",
      "step 1575, train_loss 6.3095e-05, test_loss 6.3538e-05\n",
      "step 1576, train_loss 5.8871e-05, test_loss 5.6318e-05\n",
      "step 1577, train_loss 5.2786e-05, test_loss 5.0551e-05\n",
      "step 1578, train_loss 4.5926e-05, test_loss 4.2888e-05\n",
      "step 1579, train_loss 3.9137e-05, test_loss 3.7707e-05\n",
      "step 1580, train_loss 3.3161e-05, test_loss 3.2340e-05\n",
      "step 1581, train_loss 2.8370e-05, test_loss 2.9390e-05\n",
      "step 1582, train_loss 2.4973e-05, test_loss 2.7068e-05\n",
      "step 1583, train_loss 2.2926e-05, test_loss 2.6330e-05\n",
      "step 1584, train_loss 2.2082e-05, test_loss 2.6437e-05\n",
      "step 1585, train_loss 2.2189e-05, test_loss 2.7052e-05\n",
      "step 1586, train_loss 2.2976e-05, test_loss 2.8506e-05\n",
      "step 1587, train_loss 2.4203e-05, test_loss 2.9589e-05\n",
      "step 1588, train_loss 2.5655e-05, test_loss 3.1537e-05\n",
      "step 1589, train_loss 2.7198e-05, test_loss 3.2539e-05\n",
      "step 1590, train_loss 2.8701e-05, test_loss 3.4518e-05\n",
      "step 1591, train_loss 3.0136e-05, test_loss 3.5241e-05\n",
      "step 1592, train_loss 3.1452e-05, test_loss 3.7139e-05\n",
      "step 1593, train_loss 3.2697e-05, test_loss 3.7639e-05\n",
      "step 1594, train_loss 3.3865e-05, test_loss 3.9546e-05\n",
      "step 1595, train_loss 3.5040e-05, test_loss 4.0007e-05\n",
      "step 1596, train_loss 3.6236e-05, test_loss 4.2131e-05\n",
      "step 1597, train_loss 3.7566e-05, test_loss 4.2819e-05\n",
      "step 1598, train_loss 3.9064e-05, test_loss 4.5483e-05\n",
      "step 1599, train_loss 4.0871e-05, test_loss 4.6755e-05\n",
      "step 1600, train_loss 4.3046e-05, test_loss 5.0439e-05\n",
      "step 1601, train_loss 4.5784e-05, test_loss 5.2829e-05\n",
      "step 1602, train_loss 4.9202e-05, test_loss 5.8302e-05\n",
      "step 1603, train_loss 5.3594e-05, test_loss 6.2705e-05\n",
      "step 1604, train_loss 5.9193e-05, test_loss 7.1259e-05\n",
      "step 1605, train_loss 6.6470e-05, test_loss 7.9242e-05\n",
      "step 1606, train_loss 7.5876e-05, test_loss 9.3129e-05\n",
      "step 1607, train_loss 8.8211e-05, test_loss 1.0750e-04\n",
      "step 1608, train_loss 1.0432e-04, test_loss 1.3069e-04\n",
      "step 1609, train_loss 1.2558e-04, test_loss 1.5643e-04\n",
      "step 1610, train_loss 1.5350e-04, test_loss 1.9575e-04\n",
      "step 1611, train_loss 1.9037e-04, test_loss 2.4125e-04\n",
      "step 1612, train_loss 2.3866e-04, test_loss 3.0749e-04\n",
      "step 1613, train_loss 3.0176e-04, test_loss 3.8499e-04\n",
      "step 1614, train_loss 3.8288e-04, test_loss 4.9165e-04\n",
      "step 1615, train_loss 4.8549e-04, test_loss 6.1247e-04\n",
      "step 1616, train_loss 6.1096e-04, test_loss 7.6455e-04\n",
      "step 1617, train_loss 7.5790e-04, test_loss 9.1833e-04\n",
      "step 1618, train_loss 9.1747e-04, test_loss 1.0793e-03\n",
      "step 1619, train_loss 1.0722e-03, test_loss 1.1920e-03\n",
      "step 1620, train_loss 1.1916e-03, test_loss 1.2464e-03\n",
      "step 1621, train_loss 1.2390e-03, test_loss 1.1795e-03\n",
      "step 1622, train_loss 1.1788e-03, test_loss 1.0075e-03\n",
      "step 1623, train_loss 1.0001e-03, test_loss 7.3001e-04\n",
      "step 1624, train_loss 7.2827e-04, test_loss 4.3536e-04\n",
      "step 1625, train_loss 4.2874e-04, test_loss 1.8390e-04\n",
      "step 1626, train_loss 1.8051e-04, test_loss 4.8209e-05\n",
      "step 1627, train_loss 4.3157e-05, test_loss 3.6100e-05\n",
      "step 1628, train_loss 3.1377e-05, test_loss 1.1795e-04\n",
      "step 1629, train_loss 1.1477e-04, test_loss 2.4146e-04\n",
      "step 1630, train_loss 2.3608e-04, test_loss 3.3739e-04\n",
      "step 1631, train_loss 3.3547e-04, test_loss 3.7737e-04\n",
      "step 1632, train_loss 3.7187e-04, test_loss 3.3592e-04\n",
      "step 1633, train_loss 3.3406e-04, test_loss 2.4759e-04\n",
      "step 1634, train_loss 2.4232e-04, test_loss 1.3870e-04\n",
      "step 1635, train_loss 1.3585e-04, test_loss 5.9494e-05\n",
      "step 1636, train_loss 5.4807e-05, test_loss 2.6592e-05\n",
      "step 1637, train_loss 2.2414e-05, test_loss 4.2101e-05\n",
      "step 1638, train_loss 3.8177e-05, test_loss 8.7472e-05\n",
      "step 1639, train_loss 8.2317e-05, test_loss 1.3092e-04\n",
      "step 1640, train_loss 1.2759e-04, test_loss 1.5753e-04\n",
      "step 1641, train_loss 1.5202e-04, test_loss 1.4957e-04\n",
      "step 1642, train_loss 1.4639e-04, test_loss 1.2128e-04\n",
      "step 1643, train_loss 1.1601e-04, test_loss 7.8909e-05\n",
      "step 1644, train_loss 7.5404e-05, test_loss 4.5610e-05\n",
      "step 1645, train_loss 4.0974e-05, test_loss 2.7486e-05\n",
      "step 1646, train_loss 2.3471e-05, test_loss 2.8848e-05\n",
      "step 1647, train_loss 2.4945e-05, test_loss 4.4077e-05\n",
      "step 1648, train_loss 3.9622e-05, test_loss 6.1236e-05\n",
      "step 1649, train_loss 5.7844e-05, test_loss 7.5460e-05\n",
      "step 1650, train_loss 7.0759e-05, test_loss 7.6628e-05\n",
      "step 1651, train_loss 7.3335e-05, test_loss 7.0418e-05\n",
      "step 1652, train_loss 6.5686e-05, test_loss 5.5252e-05\n",
      "step 1653, train_loss 5.1685e-05, test_loss 4.1545e-05\n",
      "step 1654, train_loss 3.6976e-05, test_loss 3.0296e-05\n",
      "step 1655, train_loss 2.6284e-05, test_loss 2.6328e-05\n",
      "step 1656, train_loss 2.2048e-05, test_loss 2.8338e-05\n",
      "step 1657, train_loss 2.3934e-05, test_loss 3.3584e-05\n",
      "step 1658, train_loss 2.9609e-05, test_loss 4.0632e-05\n",
      "step 1659, train_loss 3.6019e-05, test_loss 4.4271e-05\n",
      "step 1660, train_loss 4.0503e-05, test_loss 4.6322e-05\n",
      "step 1661, train_loss 4.1699e-05, test_loss 4.3253e-05\n",
      "step 1662, train_loss 3.9534e-05, test_loss 3.9601e-05\n",
      "step 1663, train_loss 3.5113e-05, test_loss 3.3757e-05\n",
      "step 1664, train_loss 2.9940e-05, test_loss 2.9793e-05\n",
      "step 1665, train_loss 2.5506e-05, test_loss 2.6735e-05\n",
      "step 1666, train_loss 2.2731e-05, test_loss 2.6007e-05\n",
      "step 1667, train_loss 2.1910e-05, test_loss 2.6937e-05\n",
      "step 1668, train_loss 2.2731e-05, test_loss 2.8482e-05\n",
      "step 1669, train_loss 2.4518e-05, test_loss 3.0882e-05\n",
      "step 1670, train_loss 2.6522e-05, test_loss 3.1991e-05\n",
      "step 1671, train_loss 2.8085e-05, test_loss 3.3291e-05\n",
      "step 1672, train_loss 2.8857e-05, test_loss 3.2627e-05\n",
      "step 1673, train_loss 2.8715e-05, test_loss 3.2259e-05\n",
      "step 1674, train_loss 2.7835e-05, test_loss 3.0435e-05\n",
      "step 1675, train_loss 2.6475e-05, test_loss 2.9336e-05\n",
      "step 1676, train_loss 2.4989e-05, test_loss 2.7666e-05\n",
      "step 1677, train_loss 2.3639e-05, test_loss 2.6871e-05\n",
      "step 1678, train_loss 2.2635e-05, test_loss 2.6143e-05\n",
      "step 1679, train_loss 2.2047e-05, test_loss 2.5998e-05\n",
      "step 1680, train_loss 2.1871e-05, test_loss 2.6183e-05\n",
      "step 1681, train_loss 2.2023e-05, test_loss 2.6429e-05\n",
      "step 1682, train_loss 2.2386e-05, test_loss 2.7063e-05\n",
      "step 1683, train_loss 2.2847e-05, test_loss 2.7290e-05\n",
      "step 1684, train_loss 2.3294e-05, test_loss 2.7922e-05\n",
      "step 1685, train_loss 2.3665e-05, test_loss 2.7887e-05\n",
      "step 1686, train_loss 2.3905e-05, test_loss 2.8298e-05\n",
      "step 1687, train_loss 2.4016e-05, test_loss 2.7984e-05\n",
      "step 1688, train_loss 2.3993e-05, test_loss 2.8161e-05\n",
      "step 1689, train_loss 2.3876e-05, test_loss 2.7685e-05\n",
      "step 1690, train_loss 2.3676e-05, test_loss 2.7713e-05\n",
      "step 1691, train_loss 2.3442e-05, test_loss 2.7208e-05\n",
      "step 1692, train_loss 2.3183e-05, test_loss 2.7179e-05\n",
      "step 1693, train_loss 2.2936e-05, test_loss 2.6740e-05\n",
      "step 1694, train_loss 2.2701e-05, test_loss 2.6711e-05\n",
      "step 1695, train_loss 2.2500e-05, test_loss 2.6376e-05\n",
      "step 1696, train_loss 2.2325e-05, test_loss 2.6367e-05\n",
      "step 1697, train_loss 2.2186e-05, test_loss 2.6137e-05\n",
      "step 1698, train_loss 2.2073e-05, test_loss 2.6146e-05\n",
      "step 1699, train_loss 2.1988e-05, test_loss 2.6001e-05\n",
      "step 1700, train_loss 2.1922e-05, test_loss 2.6019e-05\n",
      "step 1701, train_loss 2.1876e-05, test_loss 2.5934e-05\n",
      "step 1702, train_loss 2.1841e-05, test_loss 2.5953e-05\n",
      "step 1703, train_loss 2.1817e-05, test_loss 2.5907e-05\n",
      "step 1704, train_loss 2.1799e-05, test_loss 2.5918e-05\n",
      "step 1705, train_loss 2.1788e-05, test_loss 2.5896e-05\n",
      "step 1706, train_loss 2.1779e-05, test_loss 2.5897e-05\n",
      "step 1707, train_loss 2.1773e-05, test_loss 2.5889e-05\n",
      "step 1708, train_loss 2.1769e-05, test_loss 2.5881e-05\n",
      "step 1709, train_loss 2.1765e-05, test_loss 2.5884e-05\n",
      "step 1710, train_loss 2.1763e-05, test_loss 2.5868e-05\n",
      "step 1711, train_loss 2.1761e-05, test_loss 2.5880e-05\n",
      "step 1712, train_loss 2.1760e-05, test_loss 2.5858e-05\n",
      "step 1713, train_loss 2.1760e-05, test_loss 2.5882e-05\n",
      "step 1714, train_loss 2.1762e-05, test_loss 2.5855e-05\n",
      "step 1715, train_loss 2.1765e-05, test_loss 2.5896e-05\n",
      "step 1716, train_loss 2.1772e-05, test_loss 2.5864e-05\n",
      "step 1717, train_loss 2.1782e-05, test_loss 2.5929e-05\n",
      "step 1718, train_loss 2.1799e-05, test_loss 2.5895e-05\n",
      "step 1719, train_loss 2.1822e-05, test_loss 2.6000e-05\n",
      "step 1720, train_loss 2.1859e-05, test_loss 2.5972e-05\n",
      "step 1721, train_loss 2.1911e-05, test_loss 2.6149e-05\n",
      "step 1722, train_loss 2.1992e-05, test_loss 2.6151e-05\n",
      "step 1723, train_loss 2.2110e-05, test_loss 2.6472e-05\n",
      "step 1724, train_loss 2.2292e-05, test_loss 2.6573e-05\n",
      "step 1725, train_loss 2.2564e-05, test_loss 2.7197e-05\n",
      "step 1726, train_loss 2.2985e-05, test_loss 2.7585e-05\n",
      "step 1727, train_loss 2.3625e-05, test_loss 2.8894e-05\n",
      "step 1728, train_loss 2.4628e-05, test_loss 3.0067e-05\n",
      "step 1729, train_loss 2.6184e-05, test_loss 3.3006e-05\n",
      "step 1730, train_loss 2.8653e-05, test_loss 3.6315e-05\n",
      "step 1731, train_loss 3.2554e-05, test_loss 4.3322e-05\n",
      "step 1732, train_loss 3.8825e-05, test_loss 5.2467e-05\n",
      "step 1733, train_loss 4.8906e-05, test_loss 7.0040e-05\n",
      "step 1734, train_loss 6.5312e-05, test_loss 9.5283e-05\n",
      "step 1735, train_loss 9.2056e-05, test_loss 1.4111e-04\n",
      "step 1736, train_loss 1.3601e-04, test_loss 2.1089e-04\n",
      "step 1737, train_loss 2.0824e-04, test_loss 3.3281e-04\n",
      "step 1738, train_loss 3.2712e-04, test_loss 5.2282e-04\n",
      "step 1739, train_loss 5.2118e-04, test_loss 8.4025e-04\n",
      "step 1740, train_loss 8.3369e-04, test_loss 1.3207e-03\n",
      "step 1741, train_loss 1.3207e-03, test_loss 2.0462e-03\n",
      "step 1742, train_loss 2.0386e-03, test_loss 2.9849e-03\n",
      "step 1743, train_loss 2.9874e-03, test_loss 4.0202e-03\n",
      "step 1744, train_loss 4.0114e-03, test_loss 4.6699e-03\n",
      "step 1745, train_loss 4.6741e-03, test_loss 4.3961e-03\n",
      "step 1746, train_loss 4.3862e-03, test_loss 2.9372e-03\n",
      "step 1747, train_loss 2.9379e-03, test_loss 1.0905e-03\n",
      "step 1748, train_loss 1.0812e-03, test_loss 7.1542e-05\n",
      "step 1749, train_loss 6.5285e-05, test_loss 4.1746e-04\n",
      "step 1750, train_loss 4.1341e-04, test_loss 1.4374e-03\n",
      "step 1751, train_loss 1.4286e-03, test_loss 1.9314e-03\n",
      "step 1752, train_loss 1.9319e-03, test_loss 1.4025e-03\n",
      "step 1753, train_loss 1.3951e-03, test_loss 4.2954e-04\n",
      "step 1754, train_loss 4.2763e-04, test_loss 4.3447e-05\n",
      "step 1755, train_loss 4.0144e-05, test_loss 4.6260e-04\n",
      "step 1756, train_loss 4.5725e-04, test_loss 9.7178e-04\n",
      "step 1757, train_loss 9.7239e-04, test_loss 9.0110e-04\n",
      "step 1758, train_loss 8.9523e-04, test_loss 3.5748e-04\n",
      "step 1759, train_loss 3.5589e-04, test_loss 3.9949e-05\n",
      "step 1760, train_loss 3.6008e-05, test_loss 2.4144e-04\n",
      "step 1761, train_loss 2.3569e-04, test_loss 5.5686e-04\n",
      "step 1762, train_loss 5.5516e-04, test_loss 5.2499e-04\n",
      "step 1763, train_loss 5.1804e-04, test_loss 1.9914e-04\n",
      "step 1764, train_loss 1.9559e-04, test_loss 3.1181e-05\n",
      "step 1765, train_loss 2.6145e-05, test_loss 1.7889e-04\n",
      "step 1766, train_loss 1.7256e-04, test_loss 3.5562e-04\n",
      "step 1767, train_loss 3.5300e-04, test_loss 3.0058e-04\n",
      "step 1768, train_loss 2.9425e-04, test_loss 9.7951e-05\n",
      "step 1769, train_loss 9.4515e-05, test_loss 3.0254e-05\n",
      "step 1770, train_loss 2.6281e-05, test_loss 1.4194e-04\n",
      "step 1771, train_loss 1.3684e-04, test_loss 2.2835e-04\n",
      "step 1772, train_loss 2.2622e-04, test_loss 1.6793e-04\n",
      "step 1773, train_loss 1.6291e-04, test_loss 5.1177e-05\n",
      "step 1774, train_loss 4.7964e-05, test_loss 3.7968e-05\n",
      "step 1775, train_loss 3.4418e-05, test_loss 1.1425e-04\n",
      "step 1776, train_loss 1.0932e-04, test_loss 1.4604e-04\n",
      "step 1777, train_loss 1.4318e-04, test_loss 9.3670e-05\n",
      "step 1778, train_loss 8.8515e-05, test_loss 3.2754e-05\n",
      "step 1779, train_loss 2.8615e-05, test_loss 4.3244e-05\n",
      "step 1780, train_loss 3.9119e-05, test_loss 9.1348e-05\n",
      "step 1781, train_loss 8.6000e-05, test_loss 9.6190e-05\n",
      "step 1782, train_loss 9.2560e-05, test_loss 5.6891e-05\n",
      "step 1783, train_loss 5.1817e-05, test_loss 2.6993e-05\n",
      "step 1784, train_loss 2.2635e-05, test_loss 4.1726e-05\n",
      "step 1785, train_loss 3.7808e-05, test_loss 6.9693e-05\n",
      "step 1786, train_loss 6.4808e-05, test_loss 6.5352e-05\n",
      "step 1787, train_loss 6.1877e-05, test_loss 4.0020e-05\n",
      "step 1788, train_loss 3.5583e-05, test_loss 2.6541e-05\n",
      "step 1789, train_loss 2.2452e-05, test_loss 3.8353e-05\n",
      "step 1790, train_loss 3.4710e-05, test_loss 5.3488e-05\n",
      "step 1791, train_loss 4.8881e-05, test_loss 4.7400e-05\n",
      "step 1792, train_loss 4.3794e-05, test_loss 3.2468e-05\n",
      "step 1793, train_loss 2.8058e-05, test_loss 2.7079e-05\n",
      "step 1794, train_loss 2.2767e-05, test_loss 3.5393e-05\n",
      "step 1795, train_loss 3.1457e-05, test_loss 4.3623e-05\n",
      "step 1796, train_loss 3.8852e-05, test_loss 3.8295e-05\n",
      "step 1797, train_loss 3.4340e-05, test_loss 2.9396e-05\n",
      "step 1798, train_loss 2.4864e-05, test_loss 2.6921e-05\n",
      "step 1799, train_loss 2.2514e-05, test_loss 3.2110e-05\n",
      "step 1800, train_loss 2.8079e-05, test_loss 3.6848e-05\n",
      "step 1801, train_loss 3.2233e-05, test_loss 3.3226e-05\n",
      "step 1802, train_loss 2.9303e-05, test_loss 2.8063e-05\n",
      "step 1803, train_loss 2.3727e-05, test_loss 2.6622e-05\n",
      "step 1804, train_loss 2.2413e-05, test_loss 2.9588e-05\n",
      "step 1805, train_loss 2.5638e-05, test_loss 3.2438e-05\n",
      "step 1806, train_loss 2.8035e-05, test_loss 3.0271e-05\n",
      "step 1807, train_loss 2.6348e-05, test_loss 2.7358e-05\n",
      "step 1808, train_loss 2.3077e-05, test_loss 2.6432e-05\n",
      "step 1809, train_loss 2.2216e-05, test_loss 2.8155e-05\n",
      "step 1810, train_loss 2.4085e-05, test_loss 3.0075e-05\n",
      "step 1811, train_loss 2.5651e-05, test_loss 2.8907e-05\n",
      "step 1812, train_loss 2.4830e-05, test_loss 2.7190e-05\n",
      "step 1813, train_loss 2.2843e-05, test_loss 2.6342e-05\n",
      "step 1814, train_loss 2.2067e-05, test_loss 2.7156e-05\n",
      "step 1815, train_loss 2.3008e-05, test_loss 2.8457e-05\n",
      "step 1816, train_loss 2.4067e-05, test_loss 2.7916e-05\n",
      "step 1817, train_loss 2.3829e-05, test_loss 2.6996e-05\n",
      "step 1818, train_loss 2.2705e-05, test_loss 2.6248e-05\n",
      "step 1819, train_loss 2.2052e-05, test_loss 2.6546e-05\n",
      "step 1820, train_loss 2.2435e-05, test_loss 2.7411e-05\n",
      "step 1821, train_loss 2.3117e-05, test_loss 2.7222e-05\n",
      "step 1822, train_loss 2.3166e-05, test_loss 2.6826e-05\n",
      "step 1823, train_loss 2.2566e-05, test_loss 2.6201e-05\n",
      "step 1824, train_loss 2.2041e-05, test_loss 2.6258e-05\n",
      "step 1825, train_loss 2.2104e-05, test_loss 2.6799e-05\n",
      "step 1826, train_loss 2.2520e-05, test_loss 2.6823e-05\n",
      "step 1827, train_loss 2.2710e-05, test_loss 2.6759e-05\n",
      "step 1828, train_loss 2.2470e-05, test_loss 2.6278e-05\n",
      "step 1829, train_loss 2.2103e-05, test_loss 2.6206e-05\n",
      "step 1830, train_loss 2.1998e-05, test_loss 2.6439e-05\n",
      "step 1831, train_loss 2.2183e-05, test_loss 2.6509e-05\n",
      "step 1832, train_loss 2.2367e-05, test_loss 2.6587e-05\n",
      "step 1833, train_loss 2.2325e-05, test_loss 2.6263e-05\n",
      "step 1834, train_loss 2.2111e-05, test_loss 2.6159e-05\n",
      "step 1835, train_loss 2.1962e-05, test_loss 2.6202e-05\n",
      "step 1836, train_loss 2.1998e-05, test_loss 2.6262e-05\n",
      "step 1837, train_loss 2.2126e-05, test_loss 2.6407e-05\n",
      "step 1838, train_loss 2.2180e-05, test_loss 2.6238e-05\n",
      "step 1839, train_loss 2.2100e-05, test_loss 2.6180e-05\n",
      "step 1840, train_loss 2.1981e-05, test_loss 2.6123e-05\n",
      "step 1841, train_loss 2.1936e-05, test_loss 2.6142e-05\n",
      "step 1842, train_loss 2.1983e-05, test_loss 2.6271e-05\n",
      "step 1843, train_loss 2.2046e-05, test_loss 2.6196e-05\n",
      "step 1844, train_loss 2.2046e-05, test_loss 2.6203e-05\n",
      "step 1845, train_loss 2.1986e-05, test_loss 2.6101e-05\n",
      "step 1846, train_loss 2.1924e-05, test_loss 2.6092e-05\n",
      "step 1847, train_loss 2.1913e-05, test_loss 2.6150e-05\n",
      "step 1848, train_loss 2.1945e-05, test_loss 2.6123e-05\n",
      "step 1849, train_loss 2.1972e-05, test_loss 2.6168e-05\n",
      "step 1850, train_loss 2.1963e-05, test_loss 2.6079e-05\n",
      "step 1851, train_loss 2.1925e-05, test_loss 2.6072e-05\n",
      "step 1852, train_loss 2.1893e-05, test_loss 2.6064e-05\n",
      "step 1853, train_loss 2.1889e-05, test_loss 2.6059e-05\n",
      "step 1854, train_loss 2.1905e-05, test_loss 2.6105e-05\n",
      "step 1855, train_loss 2.1917e-05, test_loss 2.6058e-05\n",
      "step 1856, train_loss 2.1908e-05, test_loss 2.6069e-05\n",
      "step 1857, train_loss 2.1887e-05, test_loss 2.6034e-05\n",
      "step 1858, train_loss 2.1868e-05, test_loss 2.6029e-05\n",
      "step 1859, train_loss 2.1864e-05, test_loss 2.6053e-05\n",
      "step 1860, train_loss 2.1870e-05, test_loss 2.6029e-05\n",
      "step 1861, train_loss 2.1875e-05, test_loss 2.6053e-05\n",
      "step 1862, train_loss 2.1870e-05, test_loss 2.6013e-05\n",
      "step 1863, train_loss 2.1856e-05, test_loss 2.6014e-05\n",
      "step 1864, train_loss 2.1844e-05, test_loss 2.6004e-05\n",
      "step 1865, train_loss 2.1838e-05, test_loss 2.5992e-05\n",
      "step 1866, train_loss 2.1839e-05, test_loss 2.6011e-05\n",
      "step 1867, train_loss 2.1840e-05, test_loss 2.5983e-05\n",
      "step 1868, train_loss 2.1837e-05, test_loss 2.5996e-05\n",
      "step 1869, train_loss 2.1829e-05, test_loss 2.5971e-05\n",
      "step 1870, train_loss 2.1820e-05, test_loss 2.5971e-05\n",
      "step 1871, train_loss 2.1814e-05, test_loss 2.5971e-05\n",
      "step 1872, train_loss 2.1812e-05, test_loss 2.5960e-05\n",
      "step 1873, train_loss 2.1811e-05, test_loss 2.5971e-05\n",
      "step 1874, train_loss 2.1809e-05, test_loss 2.5952e-05\n",
      "step 1875, train_loss 2.1804e-05, test_loss 2.5956e-05\n",
      "step 1876, train_loss 2.1798e-05, test_loss 2.5944e-05\n",
      "step 1877, train_loss 2.1792e-05, test_loss 2.5938e-05\n",
      "step 1878, train_loss 2.1788e-05, test_loss 2.5941e-05\n",
      "step 1879, train_loss 2.1785e-05, test_loss 2.5925e-05\n",
      "step 1880, train_loss 2.1783e-05, test_loss 2.5934e-05\n",
      "step 1881, train_loss 2.1779e-05, test_loss 2.5915e-05\n",
      "step 1882, train_loss 2.1775e-05, test_loss 2.5919e-05\n",
      "step 1883, train_loss 2.1770e-05, test_loss 2.5906e-05\n",
      "step 1884, train_loss 2.1765e-05, test_loss 2.5905e-05\n",
      "step 1885, train_loss 2.1762e-05, test_loss 2.5902e-05\n",
      "step 1886, train_loss 2.1759e-05, test_loss 2.5896e-05\n",
      "step 1887, train_loss 2.1757e-05, test_loss 2.5897e-05\n",
      "step 1888, train_loss 2.1754e-05, test_loss 2.5891e-05\n",
      "step 1889, train_loss 2.1751e-05, test_loss 2.5888e-05\n",
      "step 1890, train_loss 2.1749e-05, test_loss 2.5889e-05\n",
      "step 1891, train_loss 2.1748e-05, test_loss 2.5881e-05\n",
      "step 1892, train_loss 2.1748e-05, test_loss 2.5894e-05\n",
      "step 1893, train_loss 2.1750e-05, test_loss 2.5882e-05\n",
      "step 1894, train_loss 2.1755e-05, test_loss 2.5908e-05\n",
      "step 1895, train_loss 2.1763e-05, test_loss 2.5899e-05\n",
      "step 1896, train_loss 2.1777e-05, test_loss 2.5943e-05\n",
      "step 1897, train_loss 2.1799e-05, test_loss 2.5952e-05\n",
      "step 1898, train_loss 2.1834e-05, test_loss 2.6033e-05\n",
      "step 1899, train_loss 2.1888e-05, test_loss 2.6087e-05\n",
      "step 1900, train_loss 2.1975e-05, test_loss 2.6256e-05\n",
      "step 1901, train_loss 2.2107e-05, test_loss 2.6417e-05\n",
      "step 1902, train_loss 2.2315e-05, test_loss 2.6795e-05\n",
      "step 1903, train_loss 2.2637e-05, test_loss 2.7233e-05\n",
      "step 1904, train_loss 2.3148e-05, test_loss 2.8128e-05\n",
      "step 1905, train_loss 2.3952e-05, test_loss 2.9299e-05\n",
      "step 1906, train_loss 2.5242e-05, test_loss 3.1507e-05\n",
      "step 1907, train_loss 2.7302e-05, test_loss 3.4662e-05\n",
      "step 1908, train_loss 3.0648e-05, test_loss 4.0332e-05\n",
      "step 1909, train_loss 3.6080e-05, test_loss 4.8950e-05\n",
      "step 1910, train_loss 4.5007e-05, test_loss 6.4031e-05\n",
      "step 1911, train_loss 5.9704e-05, test_loss 8.7940e-05\n",
      "step 1912, train_loss 8.4121e-05, test_loss 1.2918e-04\n",
      "step 1913, train_loss 1.2474e-04, test_loss 1.9622e-04\n",
      "step 1914, train_loss 1.9262e-04, test_loss 3.1035e-04\n",
      "step 1915, train_loss 3.0572e-04, test_loss 4.9652e-04\n",
      "step 1916, train_loss 4.9332e-04, test_loss 8.0391e-04\n",
      "step 1917, train_loss 7.9904e-04, test_loss 1.2853e-03\n",
      "step 1918, train_loss 1.2828e-03, test_loss 2.0078e-03\n",
      "step 1919, train_loss 2.0027e-03, test_loss 2.9667e-03\n",
      "step 1920, train_loss 2.9655e-03, test_loss 4.0068e-03\n",
      "step 1921, train_loss 4.0015e-03, test_loss 4.6600e-03\n",
      "step 1922, train_loss 4.6596e-03, test_loss 4.3175e-03\n",
      "step 1923, train_loss 4.3115e-03, test_loss 2.7965e-03\n",
      "step 1924, train_loss 2.7942e-03, test_loss 9.4589e-04\n",
      "step 1925, train_loss 9.3953e-04, test_loss 4.2234e-05\n",
      "step 1926, train_loss 3.6577e-05, test_loss 5.1748e-04\n",
      "step 1927, train_loss 5.1331e-04, test_loss 1.5559e-03\n",
      "step 1928, train_loss 1.5498e-03, test_loss 1.9480e-03\n",
      "step 1929, train_loss 1.9457e-03, test_loss 1.2871e-03\n",
      "step 1930, train_loss 1.2820e-03, test_loss 3.2128e-04\n",
      "step 1931, train_loss 3.1763e-04, test_loss 5.9817e-05\n",
      "step 1932, train_loss 5.6446e-05, test_loss 5.7058e-04\n",
      "step 1933, train_loss 5.6601e-04, test_loss 1.0333e-03\n",
      "step 1934, train_loss 1.0314e-03, test_loss 8.3847e-04\n",
      "step 1935, train_loss 8.3408e-04, test_loss 2.6788e-04\n",
      "step 1936, train_loss 2.6455e-04, test_loss 3.8673e-05\n",
      "step 1937, train_loss 3.5083e-05, test_loss 3.1953e-04\n",
      "step 1938, train_loss 3.1449e-04, test_loss 6.0251e-04\n",
      "step 1939, train_loss 5.9971e-04, test_loss 4.7931e-04\n",
      "step 1940, train_loss 4.7400e-04, test_loss 1.3958e-04\n",
      "step 1941, train_loss 1.3547e-04, test_loss 3.8548e-05\n",
      "step 1942, train_loss 3.4214e-05, test_loss 2.3349e-04\n",
      "step 1943, train_loss 2.2813e-04, test_loss 3.7665e-04\n",
      "step 1944, train_loss 3.7332e-04, test_loss 2.6182e-04\n",
      "step 1945, train_loss 2.5662e-04, test_loss 6.4047e-05\n",
      "step 1946, train_loss 6.0102e-05, test_loss 4.7165e-05\n",
      "step 1947, train_loss 4.3144e-05, test_loss 1.7926e-04\n",
      "step 1948, train_loss 1.7463e-04, test_loss 2.3251e-04\n",
      "step 1949, train_loss 2.2935e-04, test_loss 1.3599e-04\n",
      "step 1950, train_loss 1.3148e-04, test_loss 3.4198e-05\n",
      "step 1951, train_loss 3.0510e-05, test_loss 5.6949e-05\n",
      "step 1952, train_loss 5.3148e-05, test_loss 1.3737e-04\n",
      "step 1953, train_loss 1.3301e-04, test_loss 1.4219e-04\n",
      "step 1954, train_loss 1.3866e-04, test_loss 7.1100e-05\n",
      "step 1955, train_loss 6.6663e-05, test_loss 2.6607e-05\n",
      "step 1956, train_loss 2.2473e-05, test_loss 5.8392e-05\n",
      "step 1957, train_loss 5.4321e-05, test_loss 1.0219e-04\n",
      "step 1958, train_loss 9.7600e-05, test_loss 8.8928e-05\n",
      "step 1959, train_loss 8.4912e-05, test_loss 4.3114e-05\n",
      "step 1960, train_loss 3.8669e-05, test_loss 2.7777e-05\n",
      "step 1961, train_loss 2.3391e-05, test_loss 5.3438e-05\n",
      "step 1962, train_loss 4.9430e-05, test_loss 7.3918e-05\n",
      "step 1963, train_loss 6.9430e-05, test_loss 5.7822e-05\n",
      "step 1964, train_loss 5.3882e-05, test_loss 3.1647e-05\n",
      "step 1965, train_loss 2.7483e-05, test_loss 2.9420e-05\n",
      "step 1966, train_loss 2.5200e-05, test_loss 4.6751e-05\n",
      "step 1967, train_loss 4.2962e-05, test_loss 5.5048e-05\n",
      "step 1968, train_loss 5.0725e-05, test_loss 4.1676e-05\n",
      "step 1969, train_loss 3.7823e-05, test_loss 2.7549e-05\n",
      "step 1970, train_loss 2.3414e-05, test_loss 2.9452e-05\n",
      "step 1971, train_loss 2.5244e-05, test_loss 4.0268e-05\n",
      "step 1972, train_loss 3.6340e-05, test_loss 4.3397e-05\n",
      "step 1973, train_loss 3.9008e-05, test_loss 3.4212e-05\n",
      "step 1974, train_loss 3.0193e-05, test_loss 2.6815e-05\n",
      "step 1975, train_loss 2.2541e-05, test_loss 2.9081e-05\n",
      "step 1976, train_loss 2.4819e-05, test_loss 3.5340e-05\n",
      "step 1977, train_loss 3.1255e-05, test_loss 3.6213e-05\n",
      "step 1978, train_loss 3.1877e-05, test_loss 3.0334e-05\n",
      "step 1979, train_loss 2.6256e-05, test_loss 2.6334e-05\n",
      "step 1980, train_loss 2.2142e-05, test_loss 2.8124e-05\n",
      "step 1981, train_loss 2.3946e-05, test_loss 3.1786e-05\n",
      "step 1982, train_loss 2.7749e-05, test_loss 3.2073e-05\n",
      "step 1983, train_loss 2.7883e-05, test_loss 2.8513e-05\n",
      "step 1984, train_loss 2.4460e-05, test_loss 2.6144e-05\n",
      "step 1985, train_loss 2.2051e-05, test_loss 2.7282e-05\n",
      "step 1986, train_loss 2.3119e-05, test_loss 2.9380e-05\n",
      "step 1987, train_loss 2.5355e-05, test_loss 2.9687e-05\n",
      "step 1988, train_loss 2.5483e-05, test_loss 2.7599e-05\n",
      "step 1989, train_loss 2.3511e-05, test_loss 2.6182e-05\n",
      "step 1990, train_loss 2.2040e-05, test_loss 2.6793e-05\n",
      "step 1991, train_loss 2.2589e-05, test_loss 2.8012e-05\n",
      "step 1992, train_loss 2.3937e-05, test_loss 2.8381e-05\n",
      "step 1993, train_loss 2.4142e-05, test_loss 2.7124e-05\n",
      "step 1994, train_loss 2.3030e-05, test_loss 2.6212e-05\n",
      "step 1995, train_loss 2.2040e-05, test_loss 2.6360e-05\n",
      "step 1996, train_loss 2.2201e-05, test_loss 2.7077e-05\n",
      "step 1997, train_loss 2.2989e-05, test_loss 2.7428e-05\n",
      "step 1998, train_loss 2.3248e-05, test_loss 2.6765e-05\n",
      "step 1999, train_loss 2.2690e-05, test_loss 2.6176e-05\n",
      "step 2000, train_loss 2.2038e-05, test_loss 2.6113e-05\n",
      "best test loss at step 1423, train_loss 2.1670e-05, test_loss 2.5786e-05\n"
     ]
    }
   ],
   "source": [
    "print_results(stats_baseline, 1)\n",
    "print_best(stats_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KARHNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
