{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import torch\n",
    "from kar_hnn import KARHNN\n",
    "from data import get_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print squared loss at specific steps for comparison with HNN\n",
    "print_every = 200\n",
    "def print_results(results, print_every=200):\n",
    "    for step in range(0, len(results[\"train_loss\"]), print_every):\n",
    "        print(\n",
    "            \"step {}, train_loss {:.4e}, test_loss {:.4e}\".format(\n",
    "                step,\n",
    "                results[\"train_loss\"][step],\n",
    "                results[\"test_loss\"][step],\n",
    "            )\n",
    "        )\n",
    "    print('Final train loss {:.4e} +/- {:.4e}\\nFinal test loss {:.4e} +/- {:.4e}'\n",
    "        .format(results[\"train_loss\"][-1], results[\"train_std\"][-1],\n",
    "                results[\"test_loss\"][-1], results[\"test_std\"][-1]))\n",
    "\n",
    "def print_best(results):\n",
    "    curr_min = 0\n",
    "\n",
    "    for step in range(0, len(results[\"train_loss\"])):\n",
    "        if results[\"test_loss\"][step] < results[\"test_loss\"][curr_min]:\n",
    "            curr_min = step\n",
    "    print(\n",
    "        \"best test loss at step {}, train_loss {:.4e}, test_loss {:.4e}\".format(\n",
    "            curr_min,\n",
    "            results[\"train_loss\"][curr_min],\n",
    "            results[\"test_loss\"][curr_min],\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "data = get_dataset(seed=0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.tensor(data[\"x\"], requires_grad=True, dtype=torch.float32).to(device)\n",
    "test_x = torch.tensor(data[\"test_x\"], requires_grad=True, dtype=torch.float32).to(device)\n",
    "dxdt = torch.Tensor(data[\"dx\"]).to(device)\n",
    "test_dxdt = torch.Tensor(data[\"test_dx\"]).to(device)\n",
    "\n",
    "# dataset['train_input'], dataset['train_label'],dataset['test_input'], dataset['test_label']\n",
    "dataset = {\n",
    "    \"train_input\": x,\n",
    "    \"train_label\": dxdt,\n",
    "    \"test_input\": test_x,\n",
    "    \"test_label\": test_dxdt,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([750, 2]), torch.Size([750, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train_input\"].shape, dataset[\"train_label\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.52e-02 | test_loss: 2.86e-02 | reg: 5.70e+00 | : 100%|â–ˆ| 170/170 [00:10<00:00, 16.07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "step 0, train_loss 4.4342e-02, test_loss 7.4276e-02\n",
      "step 1, train_loss 2.2120e-02, test_loss 5.3855e-02\n",
      "step 2, train_loss 3.1496e-02, test_loss 4.1798e-02\n",
      "step 3, train_loss 3.2065e-02, test_loss 4.3065e-02\n",
      "step 4, train_loss 2.7892e-02, test_loss 4.2625e-02\n",
      "step 5, train_loss 3.1776e-02, test_loss 4.3396e-02\n",
      "step 6, train_loss 2.5734e-02, test_loss 3.5492e-02\n",
      "step 7, train_loss 2.3912e-02, test_loss 4.0744e-02\n",
      "step 8, train_loss 3.1598e-02, test_loss 3.8487e-02\n",
      "step 9, train_loss 3.8729e-02, test_loss 4.1972e-02\n",
      "step 10, train_loss 3.2624e-02, test_loss 4.2785e-02\n",
      "step 11, train_loss 3.2715e-02, test_loss 4.1267e-02\n",
      "step 12, train_loss 2.8916e-02, test_loss 4.7376e-02\n",
      "step 13, train_loss 2.4936e-02, test_loss 5.3146e-02\n",
      "step 14, train_loss 3.5932e-02, test_loss 5.1131e-02\n",
      "step 15, train_loss 3.8108e-02, test_loss 3.3600e-02\n",
      "step 16, train_loss 2.5291e-02, test_loss 7.6313e-02\n",
      "step 17, train_loss 3.2043e-02, test_loss 3.3928e-02\n",
      "step 18, train_loss 3.7193e-02, test_loss 3.5814e-02\n",
      "step 19, train_loss 3.1328e-02, test_loss 4.9030e-02\n",
      "step 20, train_loss 2.7809e-02, test_loss 3.0292e-02\n",
      "step 21, train_loss 3.0325e-02, test_loss 3.6827e-02\n",
      "step 22, train_loss 3.3430e-02, test_loss 5.2905e-02\n",
      "step 23, train_loss 3.9212e-02, test_loss 4.9554e-02\n",
      "step 24, train_loss 2.8840e-02, test_loss 4.4146e-02\n",
      "step 25, train_loss 3.7311e-02, test_loss 3.8761e-02\n",
      "step 26, train_loss 2.2158e-02, test_loss 3.4049e-02\n",
      "step 27, train_loss 2.9668e-02, test_loss 4.8489e-02\n",
      "step 28, train_loss 3.8645e-02, test_loss 3.2356e-02\n",
      "step 29, train_loss 3.0822e-02, test_loss 5.3852e-02\n",
      "step 30, train_loss 4.8679e-02, test_loss 5.5162e-02\n",
      "step 31, train_loss 3.0031e-02, test_loss 3.8738e-02\n",
      "step 32, train_loss 3.4109e-02, test_loss 3.5293e-02\n",
      "step 33, train_loss 3.8534e-02, test_loss 4.7485e-02\n",
      "step 34, train_loss 2.6799e-02, test_loss 4.6454e-02\n",
      "step 35, train_loss 2.8677e-02, test_loss 4.0440e-02\n",
      "step 36, train_loss 3.0779e-02, test_loss 4.3521e-02\n",
      "step 37, train_loss 2.9306e-02, test_loss 5.8835e-02\n",
      "step 38, train_loss 2.7839e-02, test_loss 3.3974e-01\n",
      "step 39, train_loss 3.8499e-02, test_loss 1.1831e-01\n",
      "step 40, train_loss 4.1001e-02, test_loss 3.9074e-02\n",
      "step 41, train_loss 3.3581e-02, test_loss 2.0641e-01\n",
      "step 42, train_loss 2.9926e-02, test_loss 4.7522e-01\n",
      "step 43, train_loss 3.2153e-02, test_loss 6.3852e-02\n",
      "step 44, train_loss 4.5172e-02, test_loss 4.5959e-02\n",
      "step 45, train_loss 2.8431e-02, test_loss 1.5336e-01\n",
      "step 46, train_loss 3.0970e-02, test_loss 4.0950e-02\n",
      "step 47, train_loss 3.1490e-02, test_loss 6.5445e-02\n",
      "step 48, train_loss 3.7117e-02, test_loss 3.7093e-02\n",
      "step 49, train_loss 3.6304e-02, test_loss 5.6071e-02\n",
      "step 50, train_loss 4.0411e-02, test_loss 3.2715e-02\n",
      "step 51, train_loss 2.9941e-02, test_loss 4.6419e-02\n",
      "step 52, train_loss 3.4185e-02, test_loss 4.8986e-02\n",
      "step 53, train_loss 3.1431e-02, test_loss 6.8788e-02\n",
      "step 54, train_loss 2.9926e-02, test_loss 3.7213e-02\n",
      "step 55, train_loss 3.1003e-02, test_loss 5.2926e-02\n",
      "step 56, train_loss 3.1956e-02, test_loss 3.7459e-02\n",
      "step 57, train_loss 3.2566e-02, test_loss 3.7549e-02\n",
      "step 58, train_loss 1.8135e-02, test_loss 3.4306e-02\n",
      "step 59, train_loss 3.7110e-02, test_loss 4.9572e-02\n",
      "step 60, train_loss 3.0334e-02, test_loss 5.1858e-02\n",
      "step 61, train_loss 3.5320e-02, test_loss 3.6455e-02\n",
      "step 62, train_loss 4.1008e-02, test_loss 4.9577e-02\n",
      "step 63, train_loss 3.8739e-02, test_loss 4.5545e-02\n",
      "step 64, train_loss 2.5961e-02, test_loss 4.7851e-02\n",
      "step 65, train_loss 2.9841e-02, test_loss 3.8129e-02\n",
      "step 66, train_loss 3.2037e-02, test_loss 4.4407e-02\n",
      "step 67, train_loss 3.2105e-02, test_loss 5.5008e-02\n",
      "step 68, train_loss 3.3066e-02, test_loss 3.8804e-02\n",
      "step 69, train_loss 2.4235e-02, test_loss 3.5186e-02\n",
      "step 70, train_loss 3.8386e-02, test_loss 4.4103e-02\n",
      "step 71, train_loss 3.6016e-02, test_loss 5.9999e-02\n",
      "step 72, train_loss 3.0420e-02, test_loss 3.7547e-02\n",
      "step 73, train_loss 3.4172e-02, test_loss 7.6041e-02\n",
      "step 74, train_loss 3.1635e-02, test_loss 4.0937e-02\n",
      "step 75, train_loss 3.7323e-02, test_loss 4.0533e-02\n",
      "step 76, train_loss 3.4505e-02, test_loss 9.6356e-02\n",
      "step 77, train_loss 3.5940e-02, test_loss 4.2247e-02\n",
      "step 78, train_loss 2.4261e-02, test_loss 3.2098e-02\n",
      "step 79, train_loss 3.8497e-02, test_loss 5.7391e-02\n",
      "step 80, train_loss 2.9363e-02, test_loss 3.1969e-02\n",
      "step 81, train_loss 3.5316e-02, test_loss 4.0936e-02\n",
      "step 82, train_loss 3.3486e-02, test_loss 3.7654e-02\n",
      "step 83, train_loss 3.4010e-02, test_loss 3.3528e-02\n",
      "step 84, train_loss 3.2464e-02, test_loss 3.6499e-02\n",
      "step 85, train_loss 3.4583e-02, test_loss 4.8473e-02\n",
      "step 86, train_loss 2.6605e-02, test_loss 3.6481e-02\n",
      "step 87, train_loss 2.7754e-02, test_loss 7.3512e-02\n",
      "step 88, train_loss 3.8242e-02, test_loss 2.8230e-01\n",
      "step 89, train_loss 3.0091e-02, test_loss 4.0689e-02\n",
      "step 90, train_loss 3.6984e-02, test_loss 4.4478e-02\n",
      "step 91, train_loss 3.2191e-02, test_loss 8.4421e-02\n",
      "step 92, train_loss 4.1235e-02, test_loss 3.6540e-02\n",
      "step 93, train_loss 3.2971e-02, test_loss 3.6488e-02\n",
      "step 94, train_loss 2.9469e-02, test_loss 3.5299e-02\n",
      "step 95, train_loss 3.6361e-02, test_loss 5.6674e-02\n",
      "step 96, train_loss 3.3150e-02, test_loss 4.9715e-02\n",
      "step 97, train_loss 3.3287e-02, test_loss 3.2843e-02\n",
      "step 98, train_loss 3.2479e-02, test_loss 3.3158e-02\n",
      "step 99, train_loss 3.6307e-02, test_loss 5.0991e-02\n",
      "step 100, train_loss 4.0168e-02, test_loss 4.2443e-02\n",
      "step 101, train_loss 3.1513e-02, test_loss 3.6265e-02\n",
      "step 102, train_loss 2.8072e-02, test_loss 5.1669e-02\n",
      "step 103, train_loss 2.9484e-02, test_loss 4.5603e-02\n",
      "step 104, train_loss 3.2014e-02, test_loss 3.3892e-02\n",
      "step 105, train_loss 2.3393e-02, test_loss 4.3300e-02\n",
      "step 106, train_loss 2.8050e-02, test_loss 8.6473e-02\n",
      "step 107, train_loss 3.0775e-02, test_loss 3.7781e-02\n",
      "step 108, train_loss 3.4698e-02, test_loss 3.7032e-02\n",
      "step 109, train_loss 1.9650e-02, test_loss 3.9058e-02\n",
      "step 110, train_loss 2.7717e-02, test_loss 5.0295e-02\n",
      "step 111, train_loss 2.9699e-02, test_loss 4.1372e-02\n",
      "step 112, train_loss 2.7913e-02, test_loss 3.3737e-02\n",
      "step 113, train_loss 3.0558e-02, test_loss 8.0960e-02\n",
      "step 114, train_loss 2.7471e-02, test_loss 4.3847e-02\n",
      "step 115, train_loss 3.4484e-02, test_loss 5.0610e-02\n",
      "step 116, train_loss 3.2003e-02, test_loss 4.6232e-02\n",
      "step 117, train_loss 2.2545e-02, test_loss 4.0713e-02\n",
      "step 118, train_loss 3.0813e-02, test_loss 7.1283e-02\n",
      "step 119, train_loss 2.8486e-02, test_loss 3.8160e-02\n",
      "step 120, train_loss 3.6082e-02, test_loss 5.0236e-02\n",
      "step 121, train_loss 4.2209e-02, test_loss 6.2124e-01\n",
      "step 122, train_loss 2.9044e-02, test_loss 3.8930e+01\n",
      "step 123, train_loss 1.4306e+00, test_loss 3.8813e+01\n",
      "step 124, train_loss 3.8488e-02, test_loss 1.0911e-01\n",
      "step 125, train_loss 2.5210e-02, test_loss 6.9605e-02\n",
      "step 126, train_loss 2.6873e-02, test_loss 4.1529e-02\n",
      "step 127, train_loss 3.3742e-02, test_loss 9.8727e-02\n",
      "step 128, train_loss 4.5054e-02, test_loss 6.9102e-01\n",
      "step 129, train_loss 3.9496e-02, test_loss 1.7480e+00\n",
      "step 130, train_loss 3.7068e-02, test_loss 3.8003e-02\n",
      "step 131, train_loss 2.7855e-02, test_loss 3.4991e-02\n",
      "step 132, train_loss 3.8237e-02, test_loss 3.6463e-02\n",
      "step 133, train_loss 2.9700e-02, test_loss 4.5877e-02\n",
      "step 134, train_loss 3.3072e-02, test_loss 4.3202e-02\n",
      "step 135, train_loss 2.7206e-02, test_loss 3.7361e-02\n",
      "step 136, train_loss 3.8133e-02, test_loss 5.5725e-02\n",
      "step 137, train_loss 2.7603e-02, test_loss 3.3087e-02\n",
      "step 138, train_loss 2.8791e-02, test_loss 4.0024e-02\n",
      "step 139, train_loss 2.4782e-02, test_loss 4.4397e-02\n",
      "step 140, train_loss 3.8751e-02, test_loss 3.2372e-02\n",
      "step 141, train_loss 2.7367e-02, test_loss 1.0304e-01\n",
      "step 142, train_loss 2.9700e-02, test_loss 4.2124e-02\n",
      "step 143, train_loss 3.5492e-02, test_loss 4.8106e-02\n",
      "step 144, train_loss 3.2123e-02, test_loss 4.0795e-02\n",
      "step 145, train_loss 3.7702e-02, test_loss 4.0656e-02\n",
      "step 146, train_loss 3.4268e-02, test_loss 4.7983e-02\n",
      "step 147, train_loss 3.3232e-02, test_loss 4.6352e-02\n",
      "step 148, train_loss 3.1044e-02, test_loss 3.7439e-02\n",
      "step 149, train_loss 2.7886e-02, test_loss 5.1507e-02\n",
      "step 150, train_loss 3.1028e-02, test_loss 3.6194e-02\n",
      "step 151, train_loss 3.0126e-02, test_loss 5.7963e+00\n",
      "step 152, train_loss 4.1479e-02, test_loss 3.8709e+01\n",
      "step 153, train_loss 2.8027e-02, test_loss 3.1213e-02\n",
      "step 154, train_loss 3.4988e-02, test_loss 4.0464e-02\n",
      "step 155, train_loss 3.0128e-02, test_loss 4.7547e-02\n",
      "step 156, train_loss 3.3527e-02, test_loss 4.0937e-02\n",
      "step 157, train_loss 3.0841e-02, test_loss 3.6572e-02\n",
      "step 158, train_loss 3.6290e-02, test_loss 3.4129e-02\n",
      "step 159, train_loss 2.9037e-02, test_loss 4.5233e-02\n",
      "step 160, train_loss 3.0325e-02, test_loss 4.3132e-02\n",
      "step 161, train_loss 3.7838e-02, test_loss 3.8145e-02\n",
      "step 162, train_loss 2.6465e-02, test_loss 5.1288e-02\n",
      "step 163, train_loss 3.2416e-02, test_loss 3.3806e-02\n",
      "step 164, train_loss 2.5785e-02, test_loss 4.8202e-02\n",
      "step 165, train_loss 2.7321e-02, test_loss 4.8466e-02\n",
      "step 166, train_loss 3.1288e-02, test_loss 4.4970e-02\n",
      "step 167, train_loss 2.6385e-02, test_loss 4.7401e-02\n",
      "step 168, train_loss 2.2576e-02, test_loss 3.7635e-02\n",
      "step 169, train_loss 3.5187e-02, test_loss 2.8611e-02\n",
      "Final train loss 3.5187e-02 +/- 7.7025e-03\n",
      "Final test loss 2.8611e-02 +/- 5.5889e-03\n",
      "best test loss at step 169, train_loss 3.5187e-02, test_loss 2.8611e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# initialize KAN with G=3\n",
    "model = KARHNN(input_dim=2, width=[2, 2, 2], grid=2, k=5, seed=1, device=device)\n",
    "results = model.fit(dataset, opt=\"LBFGS\", steps=170, log=1,batch=50)\n",
    "print_results(results, 1)\n",
    "print_best(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KARHNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
